{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":52446,"databundleVersionId":5643367,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Solution to Chess Competition\n\n* **Competition Link**: https://www.kaggle.com/competitions/train-an-ai-to-play-chess\n* **Competition Dataset**: https://www.kaggle.com/competitions/train-an-ai-to-play-chess/data\n* **Competition Codes**: https://www.kaggle.com/competitions/train-an-ai-to-play-chess/code\n\n* **Credits & Resources**:\n   \n   * [Chess-Rules](https://www.chess.com/learn-how-to-play-chess)\n   * [Codes](https://www.kaggle.com/competitions/train-an-ai-to-play-chess/code)\n   * [Youtube Video 1](https://www.youtube.com/live/l0bv8IgELfU?si=ijpiOcrPoyq-yrhW)\n   * [Youtube video 2](https://www.youtube.com/live/mphW24i12_Y?si=2wVWspP6nI8lctJI)","metadata":{}},{"cell_type":"markdown","source":"# My DRL Projects\n\n**Github repos(Give a star if found useful)**:\n\n* https://github.com/hishamcse/Advanced-DRL-Renegades-Game-Bots\n* https://github.com/hishamcse/DRL-Renegades-Game-Bots\n\n**Kaggle Notebooks**:\n\n* https://www.kaggle.com/syedjarullahhisham/code?tags=13313","metadata":{}},{"cell_type":"markdown","source":"# Part I : FEN & Python-Chess","metadata":{}},{"cell_type":"code","source":"!pip install python-chess","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T07:06:48.879191Z","iopub.status.idle":"2024-07-29T07:06:48.879523Z","shell.execute_reply.started":"2024-07-29T07:06:48.879337Z","shell.execute_reply":"2024-07-29T07:06:48.879350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Chess","metadata":{}},{"cell_type":"code","source":"import chess\nboard = chess.Board()\nprint(board)\nboard","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.880772Z","iopub.status.idle":"2024-07-29T07:06:48.881098Z","shell.execute_reply.started":"2024-07-29T07:06:48.880934Z","shell.execute_reply":"2024-07-29T07:06:48.880948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Legal Moves Initially ","metadata":{}},{"cell_type":"code","source":"# use board.legal_moves to see all allowed next moves:\nfor move in board.legal_moves:\n    print(move)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.882887Z","iopub.status.idle":"2024-07-29T07:06:48.883334Z","shell.execute_reply.started":"2024-07-29T07:06:48.883099Z","shell.execute_reply":"2024-07-29T07:06:48.883119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make A Move ","metadata":{}},{"cell_type":"markdown","source":"Every move is 4 characters long, and is broken up into two parts, the from square (where we're moving a piece from), and the to square (where we're moving a piece to).\n\nThis is called [Algebraic Notation](https://en.wikipedia.org/wiki/Algebraic_notation_(chess)).\n\nFor example c2c3 means \"move the pawn from square c2 to square c3\". We can find square c2 by looking for the column labeled c (this is also called the \"c file\"), and then looking for the row labeled 2 (this is also called the \"2 rank\"). c3 is the square directly above c2, and this a legal move for a pawn to make! Let's do it!","metadata":{}},{"cell_type":"code","source":"board.push_san('c2c3')\nboard","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.884571Z","iopub.status.idle":"2024-07-29T07:06:48.885274Z","shell.execute_reply.started":"2024-07-29T07:06:48.885031Z","shell.execute_reply":"2024-07-29T07:06:48.885052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Updated Legal Moves\nfor move in board.legal_moves:\n    print(move)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.886748Z","iopub.status.idle":"2024-07-29T07:06:48.887079Z","shell.execute_reply.started":"2024-07-29T07:06:48.886919Z","shell.execute_reply":"2024-07-29T07:06:48.886934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another Legal Move\nboard.push_san('g7g5')\nboard","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.888559Z","iopub.status.idle":"2024-07-29T07:06:48.888863Z","shell.execute_reply.started":"2024-07-29T07:06:48.888711Z","shell.execute_reply":"2024-07-29T07:06:48.888724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Game State(Win/Lose/None) ","metadata":{}},{"cell_type":"code","source":"# One last thing we can look at doing is checking if we've won or lost:\nprint(board.outcome())","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.889879Z","iopub.status.idle":"2024-07-29T07:06:48.890177Z","shell.execute_reply.started":"2024-07-29T07:06:48.890027Z","shell.execute_reply":"2024-07-29T07:06:48.890040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FEN","metadata":{}},{"cell_type":"markdown","source":"For storing all the data on chess moves we need to to train our AI there's a better way--it's called [Forsyth–Edwards Notation](https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation), or FEN","metadata":{}},{"cell_type":"code","source":"board.fen()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.891334Z","iopub.status.idle":"2024-07-29T07:06:48.891674Z","shell.execute_reply.started":"2024-07-29T07:06:48.891514Z","shell.execute_reply":"2024-07-29T07:06:48.891529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's unpack this!\n\nThe first part of FEN just shows us what's on the chess board. Every row of our chess board is separated with a slash, so we could rewrite this part as:\n\n\n    rnbqkbnr\n    pppppp1p\n    8\n    6p1\n    8\n    2P5\n    PP1PPPPP\n    RNBQKBNR\n\n\nIn order to keep things compact FEN doesn't show repeated spaces, it just replaces them with a number. So for example, the 8 on the 3rd line from the top means \"8 blank space\". We could replace all the numbers with that number of dots, just to make this clearer (this is the format python-chess gives us when we just print out the board):","metadata":{}},{"cell_type":"code","source":"print(board)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.893346Z","iopub.status.idle":"2024-07-29T07:06:48.893809Z","shell.execute_reply.started":"2024-07-29T07:06:48.893567Z","shell.execute_reply":"2024-07-29T07:06:48.893587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next part of FEN will always be a w or a b, showing who's turn it is. So in our FEN from above\n\n    rnbqkbnr/pppppp1p/8/6p1/8/2P5/PP1PPPPP/RNBQKBNR w KQkq - 0 2\n\nthe **w** means it's **white's turn** to go.\n\nAfter that we have a few fields for special rules we won't talk about too much: castling, en passant, and the fifty-move rule. For details, see - [Chess-Special-Rules](https://www.thesprucecrafts.com/castling-promotion-and-en-passant-611548)\n\n- $KQkq$ means that both black and white can castle king-side and queen-side.\n- '-' means there are no available en passant takes.\n- 0 means there have been 0 moves since a take or a pawn advancement.\n\nThe final field is the turn counter. You can see our turn counter is at 2, which makes sense because white took 1 turn, and black took 1 turn, for a total of 2!\n\nAnd that's it for FEN!","metadata":{}},{"cell_type":"markdown","source":"# Part II : Build Chess playing model","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.895338Z","iopub.status.idle":"2024-07-29T07:06:48.895803Z","shell.execute_reply.started":"2024-07-29T07:06:48.895569Z","shell.execute_reply":"2024-07-29T07:06:48.895589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Play\n\nTakes FEN as input and output a random move (SAN)","metadata":{}},{"cell_type":"code","source":"def play_random(fen):\n    # We can create a python-chess board instance from the FEN string like this:\n    board = chess.Board(fen=fen)\n\n    # And then randomly pick a legal move:\n    move = random.choice(list(board.legal_moves))\n\n    # Now we turn our move into a string and return it!\n    return str(move)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.897053Z","iopub.status.idle":"2024-07-29T07:06:48.897536Z","shell.execute_reply.started":"2024-07-29T07:06:48.897263Z","shell.execute_reply":"2024-07-29T07:06:48.897282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To make it easy to code up we'll always play as white.\nfrom IPython.display import SVG, display\n\n# Our play function accepts whatever strategy our AI is using, like play_random from above\ndef play_game(ai_function):\n    board = chess.Board()\n\n    while board.outcome() is None:\n        # We print out the board as an SVG\n        display(SVG(board._repr_svg_()))\n\n        # If it's white's turn, we have the user play\n        if board.turn == chess.WHITE:\n            user_move = input('Your move: ')\n            if user_move == 'quit':\n                break\n            # The move a user puts in isn't a valid move, we keep prompting them for a valid move\n            while user_move not in [str(move) for move in board.legal_moves]:\n                print('That wasn\\'t a valid move. Please enter a move in Standard Algebraic Notation')\n                user_move = input('Your move: ')\n            board.push_san(user_move)\n\n        # If it's black's turn, we have the AI play\n        elif board.turn == chess.BLACK:\n            ai_move = ai_function(board.fen())\n            print(f'AI move: {ai_move}')\n            board.push_san(ai_move)\n    print(board.outcome())\n        \nplay_game(play_random)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.906747Z","iopub.status.idle":"2024-07-29T07:06:48.907084Z","shell.execute_reply.started":"2024-07-29T07:06:48.906922Z","shell.execute_reply":"2024-07-29T07:06:48.906937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Why RL","metadata":{}},{"cell_type":"markdown","source":"There are two ways we can think about building our model that come from Reinforcement Learning:\n\n*     A Policy\n*     A Value Function\n    \nIn RL **a policy** is a function that goes from \"world states\" (everything our AI knows about the world) to actions. It's a pretty natural fit for chess, where our \"world state\" is our FEN string (the board) and actions are the legal chess moves our AI could make.\n\nThere's one catch: while our world state is relatively simple, there are a lot of potential moves our model needs to be able to put out. There are 64 possible starting square and 64 possible ending squares--so that's technically $64^2 = 4096$ possible moves.\n\nWhats more, on any given turn, most of those 4096 possible turns won't even be legal moves, so our model will have to try real hard just to output a move it's allowed to make. But we already know what moves are legal, python-chess gives that to us for free!\n\nSo another way we can think about this is to implement a value function. **A value function** basically just tells our AI how good a certain state of the world is.\n\nFor example, a board where we have all our pieces, and our opponent only has a king and 1 pawn is great for us, and our value function would put out a really high number. If this was reversed, we'd be doing terribly, and our value function would put out a really low number.\n\nSo instead of training our model to take in the board state and output a move (this would be treating our model as a policy) we could train our model to take in the board state and output a value (treating our model as a value function). Then we can just loop through all possible moves, rate all the possible board states after making those moves, and then pick the move with the highest board state.","metadata":{}},{"cell_type":"markdown","source":"# Prepare Data","metadata":{}},{"cell_type":"markdown","source":"Before we feed our input into a neural network for training, we need to turn it all into numbers.\n\nOnce we replace the numbers with periods, our FEN notation is pretty close--it's an 8x8 grid of characters.\n\n    r n b q k b n r\n    p p p p p p p p\n    . . . . . . . .\n    . . . . . . . .\n    . . . . . . . .\n    . . . . . . . .\n    P P P P P P P P\n    R N B Q K B N R\n    \nOne common strategy in machine learning is to **one hot encode** our input. There are **13** different characters on our board right now: **6 upper case (white)** pieces, **6 lower case (black)** pieces, and . for **empty** spaces. So we could one-hot encode our input with a list of 13 elements, one for each piece type:\n\nThis could be the one hot encoding for a **white Bishop**:\n\n     r n b q k p R N B Q K P .\n    [0 0 0 0 0 0 0 0 1 0 0 0 0]\n    \nAnd this could be the one hot encoding for an **empty space**:\n\n     r n b q k p R N B Q K P .\n    [0 0 0 0 0 0 0 0 0 0 0 0 1]\n    \nNotice in both examples we only have 1 1, and all the rest are zeros.","metadata":{}},{"cell_type":"markdown","source":"## Encode Chess Board ","metadata":{}},{"cell_type":"code","source":"def one_hot_encode_piece(piece):\n    pieces = list('rnbqkpRNBQKP.')\n    arr = np.zeros(len(pieces))\n    piece_to_index = {p: i for i, p in enumerate(pieces)}\n    index = piece_to_index[piece]\n    arr[index] = 1\n    return arr\n\n# Let's test on a black bishop\none_hot_encode_piece('b')","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.908293Z","iopub.status.idle":"2024-07-29T07:06:48.908630Z","shell.execute_reply.started":"2024-07-29T07:06:48.908463Z","shell.execute_reply":"2024-07-29T07:06:48.908483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_board(board):\n    # first lets turn the board into a string\n    board_str = str(board)\n    # then lets remove all the spaces\n    board_str = board_str.replace(' ', '')\n    board_list = []\n    for row in board_str.split('\\n'):\n        row_list = []\n        for piece in row:\n            row_list.append(one_hot_encode_piece(piece))\n        board_list.append(row_list)\n    return np.array(board_list)\n\n# Let's test on the starting board\nencode_board(chess.Board())","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T07:06:48.909812Z","iopub.status.idle":"2024-07-29T07:06:48.910138Z","shell.execute_reply.started":"2024-07-29T07:06:48.909975Z","shell.execute_reply":"2024-07-29T07:06:48.909989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encode the FEN representation of chess board","metadata":{}},{"cell_type":"code","source":"def encode_fen_string(fen_str):\n    board = chess.Board(fen=fen_str)\n    return encode_board(board)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.911368Z","iopub.status.idle":"2024-07-29T07:06:48.911739Z","shell.execute_reply.started":"2024-07-29T07:06:48.911571Z","shell.execute_reply":"2024-07-29T07:06:48.911586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Training Data ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/train-an-ai-to-play-chess/train.csv', index_col='id')\ntrain_df.head()\n\n# We'll also grab the last 10000 examples as a validation set\nval_df = train_df[-10000:]\nval_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:48:17.413636Z","iopub.execute_input":"2024-07-29T07:48:17.414220Z","iopub.status.idle":"2024-07-29T07:48:17.506865Z","shell.execute_reply.started":"2024-07-29T07:48:17.414189Z","shell.execute_reply":"2024-07-29T07:48:17.505956Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"                                                   board  black_score  \\\nid                                                                      \n81216                 8/5r2/3K4/8/4k3/8/8/8 w - - 20 138        455.0   \n38079  6k1/pp5p/8/3p1p2/3Rb1p1/bP1NP1P1/P1r2P1P/3R2K1...       -246.0   \n62373               8/3B4/3b4/p7/2K5/8/1k6/8 w - - 13 62          0.0   \n45874  8/1r6/2k2p2/p2b1p2/2p2P2/1P2K3/P1RN2P1/8 w - -...       -109.0   \n71079                8/8/5K2/2k3n1/8/8/2B5/8 w - - 49 80          0.0   \n\n      best_move  \nid               \n81216      d6c6  \n38079      d4a4  \n62373      d7a4  \n45874      d2c4  \n71079      c2b3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>board</th>\n      <th>black_score</th>\n      <th>best_move</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>81216</th>\n      <td>8/5r2/3K4/8/4k3/8/8/8 w - - 20 138</td>\n      <td>455.0</td>\n      <td>d6c6</td>\n    </tr>\n    <tr>\n      <th>38079</th>\n      <td>6k1/pp5p/8/3p1p2/3Rb1p1/bP1NP1P1/P1r2P1P/3R2K1...</td>\n      <td>-246.0</td>\n      <td>d4a4</td>\n    </tr>\n    <tr>\n      <th>62373</th>\n      <td>8/3B4/3b4/p7/2K5/8/1k6/8 w - - 13 62</td>\n      <td>0.0</td>\n      <td>d7a4</td>\n    </tr>\n    <tr>\n      <th>45874</th>\n      <td>8/1r6/2k2p2/p2b1p2/2p2P2/1P2K3/P1RN2P1/8 w - -...</td>\n      <td>-109.0</td>\n      <td>d2c4</td>\n    </tr>\n    <tr>\n      <th>71079</th>\n      <td>8/8/5K2/2k3n1/8/8/2B5/8 w - - 49 80</td>\n      <td>0.0</td>\n      <td>c2b3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# We'll use all except last 10000 examples as a training set\ntrain_df = train_df[:-10000]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:48:20.364955Z","iopub.execute_input":"2024-07-29T07:48:20.365308Z","iopub.status.idle":"2024-07-29T07:48:20.377466Z","shell.execute_reply.started":"2024-07-29T07:48:20.365279Z","shell.execute_reply":"2024-07-29T07:48:20.376414Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"                                                   board  black_score  \\\nid                                                                      \n80091               6R1/8/5K2/8/5k2/8/8/2r5 w - - 89 118          0.0   \n18578  r1bn1rk1/1p2b1p1/1q2p2p/p2p1p1n/P2P3P/2PB1N2/1...       -131.0   \n11580  r2qkb1r/2p2pp1/p1n2nP1/1p1p3p/P7/1Q5b/1PP1PPB1...       -490.0   \n72805                  8/4kp2/R6p/8/4K3/8/8/8 b - - 7 85       -574.0   \n74310                 8/8/k7/4R3/8/6K1/8/1r6 w - - 99 90          0.0   \n\n      best_move  \nid               \n80091      g8d8  \n18578      f3e5  \n11580      g6f7  \n72805      h6h5  \n74310      e5e6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>board</th>\n      <th>black_score</th>\n      <th>best_move</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>80091</th>\n      <td>6R1/8/5K2/8/5k2/8/8/2r5 w - - 89 118</td>\n      <td>0.0</td>\n      <td>g8d8</td>\n    </tr>\n    <tr>\n      <th>18578</th>\n      <td>r1bn1rk1/1p2b1p1/1q2p2p/p2p1p1n/P2P3P/2PB1N2/1...</td>\n      <td>-131.0</td>\n      <td>f3e5</td>\n    </tr>\n    <tr>\n      <th>11580</th>\n      <td>r2qkb1r/2p2pp1/p1n2nP1/1p1p3p/P7/1Q5b/1PP1PPB1...</td>\n      <td>-490.0</td>\n      <td>g6f7</td>\n    </tr>\n    <tr>\n      <th>72805</th>\n      <td>8/4kp2/R6p/8/4K3/8/8/8 b - - 7 85</td>\n      <td>-574.0</td>\n      <td>h6h5</td>\n    </tr>\n    <tr>\n      <th>74310</th>\n      <td>8/8/k7/4R3/8/6K1/8/1r6 w - - 99 90</td>\n      <td>0.0</td>\n      <td>e5e6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train = np.stack(train_df['board'].apply(encode_fen_string))\ny_train = train_df['black_score']","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:48:24.473296Z","iopub.execute_input":"2024-07-29T07:48:24.473971Z","iopub.status.idle":"2024-07-29T07:48:49.979773Z","shell.execute_reply.started":"2024-07-29T07:48:24.473921Z","shell.execute_reply":"2024-07-29T07:48:49.978844Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"X_val = np.stack(val_df['board'].apply(encode_fen_string))\ny_val = val_df['black_score']","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:48:49.981505Z","iopub.execute_input":"2024-07-29T07:48:49.981838Z","iopub.status.idle":"2024-07-29T07:48:55.114069Z","shell.execute_reply.started":"2024-07-29T07:48:49.981809Z","shell.execute_reply":"2024-07-29T07:48:55.113275Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"# Train & Evaluate RL Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras import callbacks\n\n# With the Keras Sequential model we can stack neural network layers together\nmodel = Sequential([\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.2),\n    Dense(1),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='mean_squared_error')","metadata":{"execution":{"iopub.status.busy":"2024-07-29T10:18:27.965384Z","iopub.execute_input":"2024-07-29T10:18:27.965754Z","iopub.status.idle":"2024-07-29T10:18:27.982623Z","shell.execute_reply.started":"2024-07-29T10:18:27.965729Z","shell.execute_reply":"2024-07-29T10:18:27.981731Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"training_1/chess.weights.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# # if already trained(so trained from last checkpoint)\n# model.load_weights(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 save_best_only=True,\n                                                 verbose=1) ","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:35:06.616347Z","iopub.execute_input":"2024-07-29T09:35:06.617035Z","iopub.status.idle":"2024-07-29T09:35:06.621986Z","shell.execute_reply.started":"2024-07-29T09:35:06.617004Z","shell.execute_reply":"2024-07-29T09:35:06.620929Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    X_train,\n    y_train,\n    epochs=100,\n    validation_data=(X_val, y_val),\n    callbacks=[cp_callback])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T09:35:09.371148Z","iopub.execute_input":"2024-07-29T09:35:09.371539Z","iopub.status.idle":"2024-07-29T09:39:12.801105Z","shell.execute_reply.started":"2024-07-29T09:35:09.371502Z","shell.execute_reply":"2024-07-29T09:39:12.800135Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153008.4062\nEpoch 1: val_loss improved from inf to 141444.15625, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 153006.1719 - val_loss: 141444.1562\nEpoch 2/100\n\u001b[1m1506/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 135611.9531\nEpoch 2: val_loss improved from 141444.15625 to 129390.79688, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 135546.4844 - val_loss: 129390.7969\nEpoch 3/100\n\u001b[1m1503/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120667.4922\nEpoch 3: val_loss improved from 129390.79688 to 123570.98438, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 120684.2812 - val_loss: 123570.9844\nEpoch 4/100\n\u001b[1m1494/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116821.1094\nEpoch 4: val_loss improved from 123570.98438 to 120418.25000, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 116825.1797 - val_loss: 120418.2500\nEpoch 5/100\n\u001b[1m1487/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111151.8125\nEpoch 5: val_loss improved from 120418.25000 to 117436.90625, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 111211.8125 - val_loss: 117436.9062\nEpoch 6/100\n\u001b[1m1503/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111692.0625\nEpoch 6: val_loss improved from 117436.90625 to 116007.31250, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 111684.8281 - val_loss: 116007.3125\nEpoch 7/100\n\u001b[1m1496/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106214.2969\nEpoch 7: val_loss improved from 116007.31250 to 114052.42969, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 106272.2422 - val_loss: 114052.4297\nEpoch 8/100\n\u001b[1m1491/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110694.5078\nEpoch 8: val_loss improved from 114052.42969 to 112213.60938, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 110620.4141 - val_loss: 112213.6094\nEpoch 9/100\n\u001b[1m1505/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103563.1953\nEpoch 9: val_loss improved from 112213.60938 to 110687.62500, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 103591.2812 - val_loss: 110687.6250\nEpoch 10/100\n\u001b[1m1496/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101444.0703\nEpoch 10: val_loss improved from 110687.62500 to 108554.36719, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 101489.3672 - val_loss: 108554.3672\nEpoch 11/100\n\u001b[1m1496/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106455.4688\nEpoch 11: val_loss improved from 108554.36719 to 106495.81250, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 106360.9219 - val_loss: 106495.8125\nEpoch 12/100\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101243.3594\nEpoch 12: val_loss improved from 106495.81250 to 105050.71875, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 101242.2734 - val_loss: 105050.7188\nEpoch 13/100\n\u001b[1m1490/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93754.4844\nEpoch 13: val_loss improved from 105050.71875 to 102720.76562, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 93836.7812 - val_loss: 102720.7656\nEpoch 14/100\n\u001b[1m1492/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93755.7891\nEpoch 14: val_loss improved from 102720.76562 to 100261.30469, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 93789.8594 - val_loss: 100261.3047\nEpoch 15/100\n\u001b[1m1495/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93487.7734\nEpoch 15: val_loss improved from 100261.30469 to 98127.41406, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 93479.0781 - val_loss: 98127.4141\nEpoch 16/100\n\u001b[1m1487/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88195.8672\nEpoch 16: val_loss improved from 98127.41406 to 96015.90625, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 88252.5156 - val_loss: 96015.9062\nEpoch 17/100\n\u001b[1m1516/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85211.8984\nEpoch 17: val_loss improved from 96015.90625 to 93944.98438, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 85230.5859 - val_loss: 93944.9844\nEpoch 18/100\n\u001b[1m1489/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87721.1875\nEpoch 18: val_loss improved from 93944.98438 to 91779.21094, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 87664.4531 - val_loss: 91779.2109\nEpoch 19/100\n\u001b[1m1501/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77425.6094\nEpoch 19: val_loss improved from 91779.21094 to 89618.66406, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 77521.3438 - val_loss: 89618.6641\nEpoch 20/100\n\u001b[1m1517/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80310.1641\nEpoch 20: val_loss did not improve from 89618.66406\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 80313.2031 - val_loss: 90360.3047\nEpoch 21/100\n\u001b[1m1511/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81647.2031\nEpoch 21: val_loss improved from 89618.66406 to 85467.48438, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 81616.2969 - val_loss: 85467.4844\nEpoch 22/100\n\u001b[1m1488/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76457.6172\nEpoch 22: val_loss improved from 85467.48438 to 84075.96875, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 76454.3906 - val_loss: 84075.9688\nEpoch 23/100\n\u001b[1m1512/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76834.2109\nEpoch 23: val_loss improved from 84075.96875 to 81636.82812, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 76808.9141 - val_loss: 81636.8281\nEpoch 24/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69755.0859\nEpoch 24: val_loss improved from 81636.82812 to 78411.56250, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 69778.5312 - val_loss: 78411.5625\nEpoch 25/100\n\u001b[1m1516/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73234.1797\nEpoch 25: val_loss improved from 78411.56250 to 77074.78125, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 73211.4062 - val_loss: 77074.7812\nEpoch 26/100\n\u001b[1m1495/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65991.0078\nEpoch 26: val_loss improved from 77074.78125 to 74759.12500, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 66012.9297 - val_loss: 74759.1250\nEpoch 27/100\n\u001b[1m1493/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66043.1172\nEpoch 27: val_loss improved from 74759.12500 to 73069.38281, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 66036.7109 - val_loss: 73069.3828\nEpoch 28/100\n\u001b[1m1507/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70875.6953\nEpoch 28: val_loss improved from 73069.38281 to 71940.86719, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 70792.5078 - val_loss: 71940.8672\nEpoch 29/100\n\u001b[1m1521/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62271.5664\nEpoch 29: val_loss improved from 71940.86719 to 69678.21875, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 62271.7344 - val_loss: 69678.2188\nEpoch 30/100\n\u001b[1m1518/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61304.1758\nEpoch 30: val_loss improved from 69678.21875 to 68007.73438, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 61300.7227 - val_loss: 68007.7344\nEpoch 31/100\n\u001b[1m1485/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57685.9219\nEpoch 31: val_loss improved from 68007.73438 to 67399.03906, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 57725.7305 - val_loss: 67399.0391\nEpoch 32/100\n\u001b[1m1507/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53053.8242\nEpoch 32: val_loss improved from 67399.03906 to 65112.19141, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 53110.5781 - val_loss: 65112.1914\nEpoch 33/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57168.7852\nEpoch 33: val_loss improved from 65112.19141 to 63971.62109, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 57155.9062 - val_loss: 63971.6211\nEpoch 34/100\n\u001b[1m1514/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55284.1758\nEpoch 34: val_loss improved from 63971.62109 to 62448.28125, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 55279.4180 - val_loss: 62448.2812\nEpoch 35/100\n\u001b[1m1504/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50344.1641\nEpoch 35: val_loss improved from 62448.28125 to 61933.97656, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 50385.0430 - val_loss: 61933.9766\nEpoch 36/100\n\u001b[1m1502/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51835.0742\nEpoch 36: val_loss improved from 61933.97656 to 61512.76953, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 51835.3984 - val_loss: 61512.7695\nEpoch 37/100\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52086.4570\nEpoch 37: val_loss improved from 61512.76953 to 59468.51172, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 52085.5273 - val_loss: 59468.5117\nEpoch 38/100\n\u001b[1m1516/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49272.7852\nEpoch 38: val_loss improved from 59468.51172 to 58630.32422, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 49276.2266 - val_loss: 58630.3242\nEpoch 39/100\n\u001b[1m1487/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50775.8242\nEpoch 39: val_loss improved from 58630.32422 to 57577.46484, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 50720.2617 - val_loss: 57577.4648\nEpoch 40/100\n\u001b[1m1511/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46283.8594\nEpoch 40: val_loss improved from 57577.46484 to 56984.41406, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 46296.7422 - val_loss: 56984.4141\nEpoch 41/100\n\u001b[1m1516/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46173.8086\nEpoch 41: val_loss improved from 56984.41406 to 56667.03516, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 46176.1875 - val_loss: 56667.0352\nEpoch 42/100\n\u001b[1m1501/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44189.3438\nEpoch 42: val_loss improved from 56667.03516 to 56008.48828, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 44212.1250 - val_loss: 56008.4883\nEpoch 43/100\n\u001b[1m1506/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44155.2773\nEpoch 43: val_loss improved from 56008.48828 to 54629.86719, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 44161.5508 - val_loss: 54629.8672\nEpoch 44/100\n\u001b[1m1504/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44535.9766\nEpoch 44: val_loss improved from 54629.86719 to 53806.51562, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 44525.0469 - val_loss: 53806.5156\nEpoch 45/100\n\u001b[1m1519/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41812.0273\nEpoch 45: val_loss improved from 53806.51562 to 52894.03125, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 41816.7227 - val_loss: 52894.0312\nEpoch 46/100\n\u001b[1m1505/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42080.4883\nEpoch 46: val_loss did not improve from 52894.03125\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 42079.8711 - val_loss: 52947.6133\nEpoch 47/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43050.9648\nEpoch 47: val_loss improved from 52894.03125 to 52102.34375, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 43033.2266 - val_loss: 52102.3438\nEpoch 48/100\n\u001b[1m1506/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38819.0547\nEpoch 48: val_loss improved from 52102.34375 to 51819.34375, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 38844.5625 - val_loss: 51819.3438\nEpoch 49/100\n\u001b[1m1507/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37074.6328\nEpoch 49: val_loss improved from 51819.34375 to 50821.54688, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 37110.8047 - val_loss: 50821.5469\nEpoch 50/100\n\u001b[1m1501/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37482.3242\nEpoch 50: val_loss did not improve from 50821.54688\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 37511.9883 - val_loss: 51485.3477\nEpoch 51/100\n\u001b[1m1519/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39092.6680\nEpoch 51: val_loss improved from 50821.54688 to 50244.97266, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 39091.2734 - val_loss: 50244.9727\nEpoch 52/100\n\u001b[1m1487/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35043.8164\nEpoch 52: val_loss improved from 50244.97266 to 49907.00000, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 35125.2891 - val_loss: 49907.0000\nEpoch 53/100\n\u001b[1m1511/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35242.4180\nEpoch 53: val_loss improved from 49907.00000 to 49529.01562, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 35266.7500 - val_loss: 49529.0156\nEpoch 54/100\n\u001b[1m1515/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41520.1836\nEpoch 54: val_loss improved from 49529.01562 to 48974.71094, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 41487.3555 - val_loss: 48974.7109\nEpoch 55/100\n\u001b[1m1493/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38771.1133\nEpoch 55: val_loss did not improve from 48974.71094\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 38717.3438 - val_loss: 49450.6289\nEpoch 56/100\n\u001b[1m1516/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34337.6055\nEpoch 56: val_loss improved from 48974.71094 to 48279.75000, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 34348.1953 - val_loss: 48279.7500\nEpoch 57/100\n\u001b[1m1521/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42086.3008\nEpoch 57: val_loss improved from 48279.75000 to 47881.62500, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 42065.0430 - val_loss: 47881.6250\nEpoch 58/100\n\u001b[1m1519/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37711.9102\nEpoch 58: val_loss did not improve from 47881.62500\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 37698.2930 - val_loss: 48719.5117\nEpoch 59/100\n\u001b[1m1494/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36633.8477\nEpoch 59: val_loss did not improve from 47881.62500\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 36590.0469 - val_loss: 48249.2578\nEpoch 60/100\n\u001b[1m1500/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35330.0312\nEpoch 60: val_loss improved from 47881.62500 to 47856.90234, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 35305.6641 - val_loss: 47856.9023\nEpoch 61/100\n\u001b[1m1522/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31067.0312\nEpoch 61: val_loss improved from 47856.90234 to 47195.65625, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 31073.5996 - val_loss: 47195.6562\nEpoch 62/100\n\u001b[1m1508/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32403.4043\nEpoch 62: val_loss improved from 47195.65625 to 46343.94922, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 32412.2441 - val_loss: 46343.9492\nEpoch 63/100\n\u001b[1m1520/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35378.8594\nEpoch 63: val_loss did not improve from 46343.94922\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 35368.4922 - val_loss: 47320.1055\nEpoch 64/100\n\u001b[1m1500/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30034.2891\nEpoch 64: val_loss improved from 46343.94922 to 46009.28516, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 30072.6719 - val_loss: 46009.2852\nEpoch 65/100\n\u001b[1m1516/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31380.4062\nEpoch 65: val_loss improved from 46009.28516 to 45963.87109, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 31386.3281 - val_loss: 45963.8711\nEpoch 66/100\n\u001b[1m1512/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30043.6504\nEpoch 66: val_loss improved from 45963.87109 to 45604.26562, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 30055.7676 - val_loss: 45604.2656\nEpoch 67/100\n\u001b[1m1512/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32157.5527\nEpoch 67: val_loss improved from 45604.26562 to 45199.93750, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 32145.8730 - val_loss: 45199.9375\nEpoch 68/100\n\u001b[1m1517/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31085.5312\nEpoch 68: val_loss improved from 45199.93750 to 45106.81641, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 31083.1758 - val_loss: 45106.8164\nEpoch 69/100\n\u001b[1m1498/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28631.9902\nEpoch 69: val_loss did not improve from 45106.81641\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 28663.8262 - val_loss: 46630.8828\nEpoch 70/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27758.5000\nEpoch 70: val_loss improved from 45106.81641 to 44671.91016, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 27783.1953 - val_loss: 44671.9102\nEpoch 71/100\n\u001b[1m1492/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31386.1270\nEpoch 71: val_loss improved from 44671.91016 to 44453.72266, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 31351.4746 - val_loss: 44453.7227\nEpoch 72/100\n\u001b[1m1518/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29321.0898\nEpoch 72: val_loss did not improve from 44453.72266\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 29322.7461 - val_loss: 45007.9336\nEpoch 73/100\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27838.4688\nEpoch 73: val_loss improved from 44453.72266 to 44210.17969, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 27839.2539 - val_loss: 44210.1797\nEpoch 74/100\n\u001b[1m1498/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27493.3535\nEpoch 74: val_loss improved from 44210.17969 to 44164.12500, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 27520.7773 - val_loss: 44164.1250\nEpoch 75/100\n\u001b[1m1517/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28299.1035\nEpoch 75: val_loss did not improve from 44164.12500\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 28302.0801 - val_loss: 44735.7109\nEpoch 76/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26546.1855\nEpoch 76: val_loss improved from 44164.12500 to 44076.38281, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26565.4570 - val_loss: 44076.3828\nEpoch 77/100\n\u001b[1m1488/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29326.6113\nEpoch 77: val_loss improved from 44076.38281 to 43946.37109, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 29296.6152 - val_loss: 43946.3711\nEpoch 78/100\n\u001b[1m1514/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26325.3184\nEpoch 78: val_loss improved from 43946.37109 to 43424.82031, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26335.5938 - val_loss: 43424.8203\nEpoch 79/100\n\u001b[1m1512/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26477.3125\nEpoch 79: val_loss did not improve from 43424.82031\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26487.1934 - val_loss: 43454.3281\nEpoch 80/100\n\u001b[1m1498/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25210.4434\nEpoch 80: val_loss improved from 43424.82031 to 43373.71094, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 25248.7363 - val_loss: 43373.7109\nEpoch 81/100\n\u001b[1m1520/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27299.4277\nEpoch 81: val_loss did not improve from 43373.71094\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 27297.9316 - val_loss: 48458.4688\nEpoch 82/100\n\u001b[1m1503/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23468.4102\nEpoch 82: val_loss improved from 43373.71094 to 43134.30469, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 23517.1895 - val_loss: 43134.3047\nEpoch 83/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25098.6484\nEpoch 83: val_loss improved from 43134.30469 to 43121.29297, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 25115.0762 - val_loss: 43121.2930\nEpoch 84/100\n\u001b[1m1513/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23940.0332\nEpoch 84: val_loss improved from 43121.29297 to 42901.55469, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 23960.0332 - val_loss: 42901.5547\nEpoch 85/100\n\u001b[1m1500/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23560.2852\nEpoch 85: val_loss improved from 42901.55469 to 42447.41016, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 23603.7637 - val_loss: 42447.4102\nEpoch 86/100\n\u001b[1m1515/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24319.0703\nEpoch 86: val_loss improved from 42447.41016 to 42382.34766, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 24330.8809 - val_loss: 42382.3477\nEpoch 87/100\n\u001b[1m1488/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26511.6152\nEpoch 87: val_loss did not improve from 42382.34766\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26489.4980 - val_loss: 42397.4844\nEpoch 88/100\n\u001b[1m1497/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25085.5879\nEpoch 88: val_loss improved from 42382.34766 to 42087.21875, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 25087.5957 - val_loss: 42087.2188\nEpoch 89/100\n\u001b[1m1502/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23017.7227\nEpoch 89: val_loss did not improve from 42087.21875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 23051.9043 - val_loss: 42522.0430\nEpoch 90/100\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24356.0371\nEpoch 90: val_loss did not improve from 42087.21875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 24356.3262 - val_loss: 42120.0039\nEpoch 91/100\n\u001b[1m1511/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26271.0215\nEpoch 91: val_loss improved from 42087.21875 to 42067.89062, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26256.8027 - val_loss: 42067.8906\nEpoch 92/100\n\u001b[1m1498/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22261.5605\nEpoch 92: val_loss did not improve from 42067.89062\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 22305.2578 - val_loss: 43053.5078\nEpoch 93/100\n\u001b[1m1518/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26480.8926\nEpoch 93: val_loss improved from 42067.89062 to 41878.46875, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26470.0918 - val_loss: 41878.4688\nEpoch 94/100\n\u001b[1m1507/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22952.1191\nEpoch 94: val_loss did not improve from 41878.46875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 22967.4473 - val_loss: 42113.1367\nEpoch 95/100\n\u001b[1m1505/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24177.6445\nEpoch 95: val_loss did not improve from 41878.46875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 24177.8750 - val_loss: 42425.4570\nEpoch 96/100\n\u001b[1m1508/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23047.3926\nEpoch 96: val_loss did not improve from 41878.46875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 23055.9336 - val_loss: 41986.2656\nEpoch 97/100\n\u001b[1m1503/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21162.0117\nEpoch 97: val_loss did not improve from 41878.46875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 21198.4902 - val_loss: 42301.2461\nEpoch 98/100\n\u001b[1m1514/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21713.7051\nEpoch 98: val_loss did not improve from 41878.46875\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 21727.2148 - val_loss: 42026.7461\nEpoch 99/100\n\u001b[1m1510/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22770.5781\nEpoch 99: val_loss improved from 41878.46875 to 41695.49219, saving model to training_1/chess.weights.h5\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 22776.3906 - val_loss: 41695.4922\nEpoch 100/100\n\u001b[1m1523/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26183.4395\nEpoch 100: val_loss did not improve from 41695.49219\n\u001b[1m1525/1525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26177.4336 - val_loss: 42307.6758\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualize Trained Model ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Lets plot the history of our training session to see how things progressed over time\nplt.style.use('ggplot')\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.title('Loss During Training')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:39:12.803053Z","iopub.execute_input":"2024-07-29T09:39:12.803342Z","iopub.status.idle":"2024-07-29T09:39:13.094343Z","shell.execute_reply.started":"2024-07-29T09:39:12.803317Z","shell.execute_reply":"2024-07-29T09:39:13.093480Z"},"trusted":true},"execution_count":161,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAG0CAYAAADehEiZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACICElEQVR4nOzdd3hUVfrA8e+Zkt4baUBCQghgCIiA0kFXqgjCKis2UNRF1174KXZFkFWxrCuroLKuCiJFEFABkSrSO4QAIZ0kkEJ6JnN/f4wZHQkQYDKT8n6eJw/Mveeee+5LIC/nnqI0TdMQQgghhGiGdM5ugBBCCCGEs0giJIQQQohmSxIhIYQQQjRbkggJIYQQotmSREgIIYQQzZYkQkIIIYRotiQREkIIIUSzJYmQEEIIIZotSYSEEEII0WxJIiSEaBJefPFFlFKsXbvW2U1pEJRS9O/f/7Lr6d+/P0qpy2+QEA2UJEJCOJhSqkn8YImKirI+i1IKo9FIYGAgCQkJ3H777Xz99ddUVlY6u5lO88fY1OXr008/dXaThWiWlOw1JoRj1SRBjf2vXlRUFCdOnODhhx/Gz88Ps9lMUVERhw8fZv369ZSUlNC2bVs+//xzunfvXu/tycvLIy8vj1atWuHh4VHv97uQF1988axjM2fOpLCw0BqzPxo5ciSdO3e22/0PHTqEh4cHrVq1uqx6UlNTKS0tJT4+3k4tE6JhkURICAdraonQ8ePHiYqKsjlXWFjIc889x3vvvYevry+//PKL/CDl/DETQjiHvBoTogGrqKhg2rRpJCQk4OHhgY+PD3369GH+/Pm1lv/222+59tprCQsLw9XVlfDwcPr168cHH3xgU+7YsWPce++9xMbG4u7uTkBAAAkJCdx///2cOnXqstvt6+vLu+++yx133EFhYSGTJ0+2OX++cSeffvppra+KoqKiiIqKoqioiMcee4yoqCiMRqO15+VcY4Rqxsrk5eVx7733WmPTsWNHPvnkk1rbUFFRwYsvvkibNm1wdXUlOjqaKVOmUFFRYbexN39UE4/Kykpefvll2rVrh6urK3fddRdgSSxnzJjBwIEDiYyMxMXFheDgYEaMGMHmzZtrrbO2dv4xRgsWLKB79+54eHgQEBDA2LFjycjIOGfb/mjt2rUopXjxxRfZtWsXw4YNw8/PDw8PD/r168emTZtqbVNWVhbjx48nJCQEd3d3OnfuzGeffWZTnxCOZnB2A4QQtausrGTQoEH8/PPPxMfH88ADD1BaWsqCBQu45ZZb2LVrF1OnTrWW/89//sN9991HaGgoN9xwA0FBQeTk5LBnzx4++eQTJk2aBFh+GHXr1o2ioiKGDh3K6NGjKS8v5/jx4/z3v//lwQcfJDAw0C7P8PzzzzN37lyWLVtGUVERPj4+l1VfZWUlAwcO5PTp01x//fX4+PgQHR19wesKCgro1asXLi4ujBkzhoqKCr7++msmTJiATqfjzjvvtJbVNI3Ro0fz3Xff0bZtWx588EGqqqr49NNP2b9//2W1/0JGjx7N1q1bGTJkCCNHjiQkJASAgwcP8uyzz9K3b1+GDRuGv78/qampfPvtt6xYsYKlS5cyePDgOt/ngw8+4Ntvv2XEiBH069ePLVu2MG/ePHbv3s2uXbtwdXWtUz3btm3jjTfe4JprruGee+4hNTWVb775hmuvvZZdu3bRrl07a9mcnByuueYaTpw4Qd++fenZsyfZ2dlMmjSJ66+//uICJYQ9aUIIhwK0uvzVmzp1qgZoQ4YM0aqqqqzHT548qbVu3VoDtI0bN1qPX3nllZqLi4t28uTJs+rKzc21/v7dd9/VAG3mzJlnlSsuLtZKS0vr9Bw1bTh+/Ph5y0VGRmqAtmbNGuuxfv36nTMGn3zyiQZon3zySa33u/baa7Xi4uKzrnvhhRc0QPvpp59sjtfE++6779ZMJpP1+P79+zW9Xq+1b9/epvzcuXM1QOvTp49WUVFhPZ6fn6+1a9dOA7R+/fqd95nP5Vwxq4lHQkKCzZ9VjYKCglqPp6WlaWFhYVp8fPxZ52prZ02MvL29tT179tic+9vf/qYB2rx582pt2x/99NNP1rj++c/pww8/1ADt73//u83xCRMmaID21FNP2RzftWuX5uLiogHaCy+8cNZzCFHf5NWYEA3UnDlzUErx1ltvYTD83nkbEhLCc889B8DHH39sc43BYMBoNJ5VV1BQ0FnH3N3dzzrm6elZ6/HLERERAUBubq5d6nvzzTfx9PS8qGs8PDx466230Ov11mMdOnSgV69eHDx4kOLiYuvxzz77DIBXX30VFxcX63E/Pz9r3OvLK6+8Uuufla+vb63HIyMjGTNmDIcOHSI1NbXO93nooYdISEiwOTZx4kQAfv311zrX06tXL+vruxoTJkzAYDDY1FNZWcmXX36Jr68vU6ZMsSmfmJjIHXfcUed7CmFvkggJ0QCdOXOG5ORkwsPDax1kPHDgQAB27txpPTZu3DhKS0vp0KEDjz76KIsXL641+RgxYgReXl488MADjB49mv/85z/s37+/3gZv19RrjyUD3Nzc6NSp00Vf17Zt21pfy7Vs2RKA/Px867GdO3ei0+no2bPnWeV79+590fe+GOebXbdx40ZuvvlmWrZsiaurq3Xa/XvvvQdQ6/iec7nqqqvOOlZbLC6lHqPRSIsWLWzqOXz4MGVlZXTq1Alvb++zrqnvuApxPjJGSIgGqLCwEICwsLBaz9ccLygosB577LHHCAoK4oMPPuDdd99l5syZKKXo168fM2bMsP7Qat26Nb/++isvvvgiK1euZOHChYDlB+ETTzzBQw89ZNdnyczMBCA4OPiy6woJCbmkhOrPU9Vr1PS0VVdXW48VFhYSEBBg0wtXo0WLFhd974sRGhpa6/FFixYxZswY3Nzc+Mtf/kJMTAyenp7odDrWrl3Lzz//TEVFRZ3vU1s8aovFpdRTU9efYwrnjl99x1WI85FESIgGyNfXF4Ds7Oxaz2dlZdmUq3HHHXdwxx13UFBQwKZNm1i0aBFz5sxh0KBBHDp0yJqMtG/fnnnz5mEymdi9ezerVq3ivffe4+GHH8bT05O7777bLs+RnJxMeno6BoOBrl27Wo/rdJbOaJPJdFbC8cfk7s8csRClj48Pp0+frrVtJ0+erNd7n+v5nnvuOVxcXNi2bRvt27e3OXfffffx888/12u7LldNb9y54lffcRXifOTVmBANkLe3NzExMWRkZHDkyJGzzv/0008AXHnllbVe7+fnx9ChQ/noo4+46667OH36NOvWrTurXE2C8vTTT/Pll18CsHjxYrs9x8svvwzADTfcYPNKxN/fH4C0tLSzrtm2bZvd7n8punTpgtlsrnUK+IYNG5zQIktC2aFDh7OSILPZ7LQ2XYz4+Hjc3d3Zs2cPZ86cOet8Y3gG0XRJIiREAzVhwgQ0TePJJ5+0ec2Ql5fHK6+8Yi1T46effqp1nE9OTg6AdbXl7du3W19V/FHN/8rtsSpzUVERDz30EP/973/x8/Nj2rRpNudrxsJ89NFHNsdXr15tTcicpWbg7pQpU2y2CCksLLTG3dGioqI4cuSI9TUjWMZevfjiixw4cMApbboYLi4u3HLLLRQWFvLqq6/anNu9ezdz5851UsuEkFdjQjjNn2fb/NEHH3zAE088wYoVK1iyZAmJiYkMHTqU0tJSvv76a3JycnjqqadsBpmOGjUKLy8vrr76aqKiotA0jfXr17N161a6du3KddddB8B///tfZs2aRe/evYmJicHf35+jR4+ydOlSXF1deeSRRy7qOWbOnImfnx+aplm32Fi3bh0lJSXExcXx+eefExcXZ3PN+PHjmTFjBq+//jq7d++mQ4cOJCUlsWLFCkaNGsU333xzUW2wpzvuuIOvvvqKlStXcsUVVzBixAiqqqr45ptv6NatG4cPH7a+2nOURx99lPvvv58uXbowevRojEYjGzdu5MCBA9xwww0sXbrUoe25FNOmTWPNmjW88cYbbNmyhZ49e5KVlcX8+fMZOnQoixcvdnhchQBJhIRwmppp2rWZOXMmHh4e/Pjjj7z11lt88cUXvPfeexgMBhITE5k5cyZ/+9vfbK6ZNm0a33//PTt27GD58uW4ubnRunVrpk+fzt///nfrtPq//e1vVFRUsGnTJrZv305ZWRkRERGMHTuWxx9/nCuuuOKinuOdd94BLK/ZvL29iYiIYNSoUdx4442MGDHCZgp6jZCQEH7++WeefPJJ1q1bx88//8xVV13Fjz/+yPHjx52aCCmlWLRoEVOnTuW///0v7733HmFhYdx5551MmjSJxYsXX/bCkBfrvvvuw9XVlZkzZ/LZZ5/h7u5Onz59+OSTT/jmm28aRSLUokULNm3axDPPPMPy5cvZsmUL7dq144MPPsDT09MpcRUCZK8xIYSosx9//JHrr7+eyZMn8/rrrzu7OU3Gs88+y9SpU1m5ciWDBg1ydnNEMyOJkBBC/ElmZibh4eE2x06dOsX111/Pjh072LJly3nX/BG1qy2ue/fupWfPnri4uJCRkYGbm5uTWieaK3k1JoQQf/LYY4+xe/duevbsSXBwMOnp6axYsYLTp09z3333SRJ0ia666ipiY2O54oor8PT05MiRI3z33XeYzWZmzZolSZBwCkmEhBDiT2666SZOnjzJ0qVLKSgowM3NjY4dO3L33XfbbY2l5ui+++5j8eLFfPnll5w5cwY/Pz8GDRrEE088Qf/+/Z3dPNFMyasxIYQQQjRbMldRCCGEEM2WJEJCCCGEaLYkERJCCCFEsyWJkBBCCCGaLZk1Vgf5+fmYTCa71xscHExubq7d6xVnk1g7jsTacSTWjiOxdhx7xNpgMFg3d75g2cu6UzNhMpmoqqqya51KKWvdMnGvfkmsHUdi7TgSa8eRWDuOM2Itr8aEEEII0WxJIiSEEEKIZksSISGEEEI0W5IICSGEEKLZksHSQgghmq2KigoqKiouWK6srIzKykoHtEjUNdZKKby8vKwDrC+VJEJCCCGapZKSEpRSeHt7X/CHqdFotPvsYVG7usa6srKS4uJivL29L+t+8mpMCCFEs2QymfDw8LjsHgXhHC4uLnaZYi+JkBBCiGZJEiABkggJIYQQohmTREgIIYQQzZYkQkIIIUQz1aNHDz766COn1+FMMmtMCCGEaCTGjBlDhw4dePnll+1S3/Lly/Hw8LBLXY2VJEJOoOWfwrxmGQWenjDkr85ujhBCiCZE0zSqq6sxGC78Iz4wMNABLWrY5NWYM5SXoa38huIV3zi7JUIIIbAkD1pFuXO+6jgF/JFHHmHz5s3Mnj2biIgIIiIiSEtLY9OmTURERLBmzRoGDx5MdHQ0v/76KykpKYwfP57ExETatm3L0KFDWbdunU2df36tFRERwRdffMHdd99NTEwMvXr14ocffrioWGZkZDB+/Hjatm1Lu3btuO+++8jNzbWe379/P2PGjCEuLo527doxePBgdu/eDUB6ejq33XYbHTp0IDY2lgEDBrB69eqLuv/Fkh4hZ/DxA0ArLUGrqgSD0bntEUKI5q6yAvODN5/z9IXXnr50uvfng6vbBcu9/PLLHDt2jPj4eJ544gnA0qOTlpYGwNSpU3n++edp1aoVvr6+ZGZmMnDgQJ5++mlcXFxYsGAB48ePZ926dURERJzzPm+99RZTpkxhypQpfPLJJzz44INs2bIFf3//C7bRbDYzfvx4PD09+eabbzCZTDz77LP8/e9/Z8GCBQD84x//oGPHjkybNg2dTsf+/futvVfPPPMMJpOJb775Bg8PD5KSkvD09LzgfS+HJELO4OEJBgOYTFBUAAHBzm6REEKIBs7HxwcXFxfc3NwICQk56/yTTz5J3759rZ/9/f3p2LGj9fNTTz3FypUr+eGHHxg/fvw573PzzTczcuRIACZPnszs2bPZtWsXAwYMuGAbN2zYwKFDh9i8ebM12XrnnXcYMGAAu3btonPnzmRkZHD//fcTGxsLQJs2bazXZ2ZmMnz4cNq3bw9A69atL3jPyyWJkBMopSy9QqfzoLBAEiEhhHA2F1dLz8w51OsWGy6udqmmU6dONp9LSkp48803Wb16NTk5OZhMJsrLy8nIyDhvPTVJCICHhwfe3t7k5eXVqQ1HjhwhPDzcpscpLi4OX19fjhw5QufOnbn33nt58skn+eabb+jTpw/Dhw8nKioKgAkTJvB///d//PTTT/Tp04ehQ4fSoUOHOkbg0sgYIWepeT1WVODUZgghhLD8B1W5ujnny04rXP959tfLL7/MypUrmTx5MgsXLuSHH34gPj7+ghuaGo22wzWUUpjNZru0EeDxxx9nzZo1XHvttWzcuJEBAwawYsUKAG699Va2bt3K6NGjOXToEEOHDmXOnDl2u3dtJBFyEvVbIkRRvlPbIYQQovEwGo11Tkq2bdvGX//6V4YMGUL79u0JCQkhPT29XtvXtm1bMjMzbXqdkpKSKCwsJC4uznosJiaGe++9ly+//JIhQ4Ywb94867mIiAjuuOMOPv74Y+677z6++OKLem2zJELO4vPboDPpERJCCFFHLVu2ZOfOnaSlpXH69OnzJkXR0dGsWLGCffv2sX//fh544AG79uzUpk+fPsTHx/OPf/yDvXv3snPnTh5++GGuueYaEhMTKSsr49lnn2XTpk2kp6ezdetWdu/eTdu2bQF4/vnnWbNmDampqezdu5eNGzdaxxLVF0mEnEVejQkhhLhI9913Hzqdjv79+5OQkHDe8T4vvPACvr6+3Hjjjdx1113Wa+qTUopPPvkEX19fbrrpJsaOHUurVq3497//DYBeryc/P5+HH36YPn36cP/99zNgwAAef/xxwDLrbPLkyfTv359x48bRpk0bpk6dWr9t1uyxh30Tl5uba/dBctrqpZi/+gh1VW909z1l17qFLaUUYWFhZGVl1Xm9DnFpJNaOI7G+fEVFRfj4+NSpbL0OlhY2LibW5/ozNBqNBAfXbSKS9Ag5i/QICSGEEE4niZCzyGBpIYQQwukkEXKS32eNFTizGUIIIUSzJomQs9QkQqUlaPLeWQghhHAKSYScxcPLss0GwJkCpzZFCCGEaK4kEXISpdOh9w2wfJDXY0IIIYRTSCLkRDo/SYSEEEIIZ5JEyIn0/pZESKbQCyGEEM4hiZAT6fwCLb+RREgIIYRwCkmEnEgvr8aEEEI4WI8ePfjoo4/Oef6RRx5hwoQJDmyRc0ki5ESSCAkhhBDOJYmQM/32akzGCAkhhBDOIYmQE6Tkl3Pv4mTGH3S1HJBESAghnErTNMpN5nN/VZ3n3GV+1XXT3M8//5wrr7wSs9lsc3z8+PE89thjAKSkpDB+/HgSExNp27YtQ4cOZd26dZcVm4qKCp577jk6depEmzZtGDlyJLt27bKeLygo4MEHHyQhIYGYmBh69erFvHnzAKisrOTZZ5+lS5cutGnThu7du/Pee+9dVnvszXCxFxw4cIBvv/2W48ePk5+fzxNPPEH37t1rLfuf//yHVatWceeddzJs2DDr8eLiYubMmcP27dtRStGjRw/Gjx+Pm5ubtcyJEyeYPXs2R48excfHh8GDB3PjjTfa1L9582bmzZtHbm4uoaGhjBs3jiuvvNJ6XtM05s+fz+rVqykpKSE+Pp577rmHsLCwi31su/Jy1ZNdXIVeQbXSoZdESAghnKqiWuOWeUlOufe8W+JwM6gLlhs+fDjPPfccGzdupE+fPgDk5+ezdu1a5s6dC0BJSQkDBw7k6aefxsXFhQULFjB+/HjWrVtHRETEJbXvtddeY/ny5cycOZPIyEg++OADxo0bx4YNG/D392fGjBkkJSXx+eefExAQwPHjxykvLwdgzpw5/PDDD3z44YdERESQmZlJZmbmJbWjvlx0j1BFRQVRUVHcfffd5y3366+/cuTIEfz9/c869+6775KWlsaUKVOYPHkyBw8eZNasWdbzpaWlvPrqqwQFBTFt2jRuu+02vv76a1atWmUtc/jwYd555x0GDhzI9OnT6datGzNmzCA1NdVaZsmSJaxYsYKJEycydepUXF1dee2116isrLzYx7arAHcDLnpFtQa5rn5QcgbNZHJqm4QQQjRsfn5+DBgwgMWLF1uPfffddwQEBNCrVy8AOnbsyO233058fDxt2rThqaeeonXr1vzwww+XdM/S0lLmzp3LlClTGDhwIHFxccyYMQM3Nze++uorADIyMrjiiitITEykZcuW9O3bl+uvv956Ljo6mu7duxMZGUn37t0ZOXLkZcXB3i66R6hLly506dLlvGVOnz7NnDlzePbZZ5k2bZrNufT0dHbt2sXrr79OTEwMABMmTOD111/n9ttvJyAggA0bNmAymZg0aRIGg4GWLVuSkpLCsmXLuO666wBYvnw5nTt3ZsSIEQCMHTuWvXv3snLlSu699140TWP58uXcdNNNdOvWDYAHH3yQiRMnsnXrVus3jTPolCLM24UTBRVkeoYQWn4azhSCf6DT2iSEEM2Zq14x75a4c543GoxUmepnX0hX/YV7g2qMGjWKp556yvqf+0WLFjFixAh0Oku/RklJCW+++SarV68mJycHk8lEeXk5GRkZl9S2lJQUqqqqrD9HAYxGI507d+bIkSMA3HHHHUycOJG9e/fSr18/Bg0aZC1/8803M3bsWPr06cOAAQO47rrr6Nev3yW1pb5cdCJ0IWazmffee48RI0bQsmXLs84nJSXh6elpTYIAEhISUEqRnJxM9+7dSUpKon379hgMvzcvMTGRJUuWUFxcjJeXF0lJSQwfPtym7sTERLZu3QpATk4OBQUFdOrUyXrew8OD2NhYkpKSak2EqqqqqPrDBqhKKdzd3a2/t6eaRCjbLxJOHUKdKUAFBNn1HsKi5s/O3n+G4mwSa8eRWNuXUuq8r6eMRh36BjCs9i9/+QuaprF69WoSExPZsmULL774ovX8yy+/zPr163nuueeIiorCzc2Ne++9t17fhAwcOJBff/2V1atXs379esaOHcudd97J888/T0JCAr/88gtr1qxhw4YN3H///fTu3fu80/cv1uX+HbB7IrRkyRL0ej1Dhgyp9XxBQQE+Pj42x/R6PV5eXhQUFFjLhISE2JTx8/Oznqsp6+vra1PG19fXpo6aY+cq82eLFi1iwYIF1s/R0dFMnz6d4ODgcz3uJYsNLeGXtDPk+IYD4G/Q4e7ksUtNXWhoqLOb0GxIrB1HYn3pysrKMBqNdS5/MWXri9FoZNiwYSxevJjU1FRiY2NtxsZu376dsWPHWt+WFBcXk56ejl6vt7ZfKWXz+c90Oh1KKYxGI7Gxsbi4uLBjxw6io6MBS6fB7t27uffee6111IzTHTduHJ999hkvvfQSr7zyCgABAQGMGTOGMWPGMGLECMaOHUtxcXGtQ2f++Jx14eLictnjfu2aCB07dozly5czffr0Rvm/lFGjRtn0MtU8Q25uLiY7j+Hx1Vl6njLcLGsJnU45hi6ijV3vISyUUoSGhpKdnV3n2Rni0kisHUdiffkqKytt3gKcj9ForHPZ+nbjjTdy1113cejQIW666SabdkVFRbFs2TIGDhyIUooZM2ZgNpuprq62ltM0zebzn5nNlplsVVVVuLi4cPvtt/PSSy/h7e1NREQEH3zwAWVlZdx8881UVVUxY8YMOnXqRFxcHJWVlXz//fe0bduWqqoqZs2aRYsWLbjiiitQSrFkyRJCQkLw8PA45/0vJtaVlZVkZWWdddxgMNS5E8OuidDBgwcpKipi0qRJ1mNms5m5c+eyfPly/vWvf+Hn50dRUZHNddXV1RQXF1t7ffz8/M7qtan5/McyhYWFNmUKCwttztcc+2PWWVhYSFRUVK3tNxqN58xC7f0PTai35T5ZBkuPlVZYIP+Y1TNN0yTGDiKxdhyJdfPTu3dv/Pz8OHr0KKNGjbI598ILL/DYY49x4403EhAQwAMPPEBxcfFl3e+ZZ55B0zQeeughSkpK6NSpE//73/+sP2eNRiOvv/46aWlpuLm50aNHDz744AMAvLy8+OCDDzh+/Dh6vZ7ExET++9//Wsc02cPlfv/bNRHq27cvCQkJNsdee+01+vbty4ABAwCIi4ujpKSEY8eO0aaNpQdk3759aJpGbGystcyXX36JyWSyjhPas2cP4eHheHl5Wcvs3bvXZlr+nj17aNu2LQAhISH4+fmxd+9ea+JTWlpKcnKydTS7M4V7uwBwUudOtdJhkCn0Qggh6kCn07Fjx45az7Vs2ZKvv/7a5thdd91l83nLli3nrX/mzJk2n93c3HjllVesr7r+7JFHHuGRRx6p9VzN67KG7KJTsvLyclJSUkhJSQEsg5JTUlLIy8vD29ubVq1a2XwZDAb8/PwID7eMhYmMjKRz587MmjWL5ORkDh06xJw5c+jZsycBAZbXRL1798ZgMPDhhx+SlpbGpk2bWLFihc1rq6FDh7J7926WLl1KRkYG8+fP5+jRowwePBiwdBsPHTqUhQsXsm3bNlJTU3n//ffx9/e3Gf3uLIEeBlz0OqrRWabQSyIkhBBCONxF9wgdPXqUl156yfq5ZhGnfv368cADD9SpjoceeojZs2fz8ssvWxdU/OMGbx4eHkyZMoXZs2czefJkvL29GT16tHXqPEC7du146KGH+Oqrr/jyyy8JCwvjySefpFWrVtYyN954IxUVFcyaNYvS0lLi4+N55plncHFxudjHtjudUkT4uXP8VAnZ7oGEFuU7u0lCCCFEs6M0ebl8Qbm5uXYfJKeU4s1fcvk5OY+JSYsYQgb6l9636z2EhVKKsLAwsrKyZCxFPZNYO47E+vIVFRWdNYv5XBrSYOmm7mJifa4/Q6PRWOfB0s5fFKEZi/SzrFGU5R4kr8aEEEIIJ5BEyIla+XsAkOURZNlmo7rayS0SQgghmhdJhJwo0t/SI5TtHgiaZtlmQwghhMP8eSd30XjY65WwJEJOVNMjdNItkGqlk9djQgjhQB4eHpw5c0aSoUaqtLQUV1fXy67H7ltsiLoL8XbFqFNUoSfP1ZcwSYSEEMJhDAYDnp6edVpw0MXFpV736xK/q0usNU3DYDBIItTY6ZQi1NtIWmElWe5BhBYV0Pg2JhFCiMbLYDBccOaYzNBzHGfEWl6NOVnYbytMZ7kHwZkC5zZGCCGEaGYkEXKymkQo2z1QxggJIYQQDiaJkJOF/7FHqFBWlxZCCCEcSRIhJ/v91VggmvQICSGEEA4liZCTWXehdw+kukjWERJCCCEcSRIhJwv0MGBQYNIZOFUua1kIIYQQjiSJkJPpdYpQTz0AWWY3NLNssyGEEEI4iiRCDUCYjxsAWe4BUFzk5NYIIYQQzYckQg1AmM8fZo7JgGkhhBDCYSQRagBsptBLIiSEEEI4jCRCDcAfF1WUKfRCCCGE40gi1ACEeRsBSyJUXVDg3MYIIYQQzYgkQg1AkIcRA2bLFPqTec5ujhBCCNFsSCLUAOh1ihYull12s3IKnNsYIYQQohmRRKiBCPNxBSCrpBrNVOXk1gghhBDNgyRCDUSrEB8ADnm3hMxUJ7dGCCGEaB4kEWoguoZ7AbAzoB2mE8ec3BohhBCieZBEqIGID3bHAxNFLl4cSc11dnOEEEKIZkESoQbCoFNc6WUCYHuh/LEIIYQQjiA/cRuQri0t44S261vI5qtCCCGEA0gi1IB0bR+J0swc9woj70SGs5sjhBBCNHmSCDUgvu4uxFVaxgdtP5Lt5NYIIYQQTZ8kQg1MV9cSALblmZzcEiGEEKLpk0Sogbkq1B2APdU+VFabndwaIYQQommTRKiBiY5tSWB5ARU6A3uzS53dHCGEEKJJk0SogVERremafxiAbUdlPSEhhBCiPkki1MAog5Gu6jQA27JL0TTNyS0SQgghmi5JhBqgToEuGM1V5FTpSSusdHZzhBBCiCZLEqEGyK11FAn5RwHYllHs5NYIIYQQTZckQg2QatmGrqcOArAtUxIhIYQQor5IItQQtYym62nLgOmDOWVkFsnrMSGEEKI+SCLUAClXN0L8PLjy1CHMwOe7ZfaYEEIIUR8kEWqgVKsYbju2HIXGxtQzJOWVObtJQgghRJMjiVBD1aoNUSXZ9K9MA+CznTkylV4IIYSwM0mEGijVqg0Afzu+EqNOsS+njO2ZJU5ulRBCCNG0SCLUULWKASAoK5nhrd0AS69QtVl6hYQQQgh7MVzsBQcOHODbb7/l+PHj5Ofn88QTT9C9e3cATCYTX331FTt37iQnJwcPDw8SEhK49dZbCQgIsNZRXFzMnDlz2L59O0opevTowfjx43Fzc7OWOXHiBLNnz+bo0aP4+PgwePBgbrzxRpu2bN68mXnz5pGbm0toaCjjxo3jyiuvtJ7XNI358+ezevVqSkpKiI+P55577iEsLOyiA+VoytMLYjtA8gFuKtrFjy7tSS2s5KfjhVwX4+fs5gkhhBBNwkX3CFVUVBAVFcXdd9991rnKykqOHz/O6NGjmT59Oo8//jiZmZm88cYbNuXeffdd0tLSmDJlCpMnT+bgwYPMmjXLer60tJRXX32VoKAgpk2bxm233cbXX3/NqlWrrGUOHz7MO++8w8CBA5k+fTrdunVjxowZpKamWsssWbKEFStWMHHiRKZOnYqrqyuvvfYalZWNYzq66tEXAM+tP3HzFUEAfLE7jwqT7EovhBBC2MNFJ0JdunRh7Nix1l6gP/Lw8OC5556jZ8+ehIeHExcXx4QJEzh27Bh5eXkApKens2vXLu6//37atm1LfHw8EyZMYNOmTZw+bdlja8OGDZhMJiZNmkTLli3p1asXQ4YMYdmyZdZ7LV++nM6dOzNixAgiIyMZO3Ysbdq0YeXKlYClN2j58uXcdNNNdOvWjdatW/Pggw+Sn5/P1q1bLylYjqa69ga9HlKPMcSnmBBPA6fKTCw9lO/spgkhhBBNwkW/GrtYpaWlKKXw8PAAICkpCU9PT2JiYqxlEhISUEqRnJxM9+7dSUpKon379hgMvzcvMTGRJUuWUFxcjJeXF0lJSQwfPtzmXomJidYkJycnh4KCAjp16mQ97+HhQWxsLElJSfTq1eustlZVVVFVVWX9rJTC3d3d+nt7qqnvfPUqH1+0jl3Q9mzDsG09t3W+gbc2ZrJg/ymujfElwMNo1zY1VXWJtbAPibXjSKwdR2LtOM6Idb0mQpWVlfzvf/+jV69e1kSooKAAHx8fm3J6vR4vLy8KCgqsZUJCQmzK+Pn5Wc/VlPX19bUp4+vra1NHzbFzlfmzRYsWsWDBAuvn6Ohopk+fTnBwcF0f+aKFhoae93zJoJGc3rMN3bYN3Hzf4/xwrJh9WUUsSCrmhSEd6q1dTdGFYi3sR2LtOBJrx5FYO44jY11viZDJZOLtt98G4J577qmv29jVqFGjbHqZajLS3NxcTCaTXe+llCI0NJTs7Ozzrg+kRbUDVzeqszM4uXkddya24smsIpbty2ZASzfaBrrbtV1NUV1jLS6fxNpxJNaOI7F2HHvF2mAw1LkTo14SoZokKC8vj+eff97aGwSWnp2ioiKb8tXV1RQXF1t7ffz8/M7qtan5/McyhYWFNmUKCwttztcc8/f3tykTFRVVa7uNRiNGY+2vm+rrm1/TtPPX7eKK6twDbcvPmH9ZS9zf7qV/lA9rU4r4aOtJpl3fSrpr6+iCsRZ2I7F2HIm140isHceRsbb7OkI1SVB2djbPPfcc3t7eNufj4uIoKSnh2LFj1mP79u1D0zRiY2OtZQ4ePGjTC7Nnzx7Cw8Px8vKyltm7d69N3Xv27KFt27YAhISE4OfnZ1OmtLSU5ORk4uLi7PvQ9Uz16AeAtnU9WnU1d3QJxlWvOJRXxvoTZ5zcOiGEEKLxuuhEqLy8nJSUFFJSUgDLoOSUlBTy8vIwmUy89dZbHDt2jH/84x+YzWYKCgooKCiwJjWRkZF07tyZWbNmkZyczKFDh5gzZw49e/a0rjXUu3dvDAYDH374IWlpaWzatIkVK1bYvLYaOnQou3fvZunSpWRkZDB//nyOHj3K4MGDAUv32tChQ1m4cCHbtm0jNTWV999/H39/f7p163a5cXOs9p3BywfOFMLB3QR6GBndMRCAT3fmyHR6IYQQ4hIp7SL7nvbv389LL7101vF+/frx17/+lQcffLDW61544QU6duwIWBZUnD17ts2CihMmTDjngore3t4MHjyYkSNH2tS5efNmvvrqK3JzcwkLCzvngoqrVq2itLSU+Ph47r77bsLDwy/mkcnNzbWZTWYPSinCwsLIysqqU/ef+X8foq1djrpmALoJj1JhMvPA0mPklpr4W0IQYzsF2bV9TcnFxlpcOom140isHUdi7Tj2irXRaKzzGKGLToSao4aQCGnJBzBPnwyu7ujemotycWXDiSJmbMjERa94uk8EV0V42bWNTYX8I+Y4EmvHkVg7jsTacZyRCMleY41FTHsIDIGKMrTdlrWSerXy5qpwTyqrNV5dm86Sg6flL6kQQghxESQRaiSUUr8Pml6zFE3TUEoxuW8k18f6ogFzduTw/pZsqqolGRJCCCHqQhKhRkQNGAoGIyQfhIO7ADDqFZO6h3JP1xB0ClYdLeSFNakUldt33SMhhBCiKZJEqBFRfoGofpZZceZvv7S+BlNKcUN8AM/1j8TDqGN/ThnPr0mjtKramc0VQgghGjxJhBoZNXg0GF3g6CHYv8Pm3JXhXkwf1Bo/Nz3H8yt4Y30mJrO8JhNCCCHORRKhRkb5BaD6DQFse4VqtPJ1ZUr/SFz1ip1ZJfz7V1kSXgghhDgXSYQaITXkJnBxgeNJsG/7WefbBrrzZO8I65ih+ftOOaGVQgghRMMniVAjpHz8Uf2HAWBe8kWtPT7dIr24r1sLAL7Yk8eaY4VnlRFCCCGaO0mEGik1aBS4uMKJZNiztdYyg9v6M7qDZduS93/JYkdmsSObKIQQQjR4kgg1UsrHDzXQsvea+dsv0My17zd2W+dg+kX5UK3B6+syOJBT6shmCiGEEA2aJEKNmLp+FLi6Q+oxtFXf1lpGpxQPXRNmswL1sdPlDm6pEEII0TBJItSIKW8f1F/HA6AtnIt2IrnWcgad4qk+EXQIdqekysyLa9LIKKp0ZFOFEEKIBkkSoUZO9R0EV14D1SbM/5mBVl77qy9Xg44p/SNp4+9KYUU1L6xOJbfEvhvJCiGEEI2NJEKNnFIK3R0PQkAQ5GShfTHrnGU9XfS8MLAl4d4u5JaaeHZVKpnSMySEEKIZk0SoCVCe3ujufhyUDm3zT5h/+emcZf3cDLx8bUtCvYycLK7i6R9OcDivzIGtFUIIIRoOSYSaCBXXETX8FgC0zz9Ey8k6Z9lgTyPTr29NbIAbRRXVTFmVytZ0mVovhBCi+ZFEqAlRw2+GuI5QUYb539PQys/d0+PnbuDV61rR9bfZZFPXpfNDcoHjGiuEEEI0AJIINSFKp7e8IvP2hfTjmD9555zrCwG4G3U80y+S62J8MWvwry3ZrDpa4LgGCyGEEE4miVATowKC0E36P9AbYMcmtGVfnbe8Qad4sEcoN/22AvW/fz0pY4aEEEI0G5IINUEqtgPqtr8DoC39Cm3bhvOXV4rbOwdzdUsvTGaNaesyOF1mckRThRBCCKeSRKiJ0vX+C+q6EQCYP5mJlnr0/OWV4uFrwmjp68LpMhPT1mVQVX3u12pCCCFEUyCJUBOmxoyHDl2gshLzv15DO5173vIeRj3P9I3E06jjcF4ZH23LcVBLhRBCCOeQRKgJU3o9unufhBYRcDoP8xv/h5abfd5rwn1ceLxXOAr4PrmAlUfyHdNYIYQQwgkkEWrilKcXusdehpAwOJVjSYay0s97TdcIL27rHAzAf7aeZO/JEkc0VQghhHA4SYSaARUQjO7J1yGsJRScwjzj/9DSU857zegOAfRu7U21BtPXZZB1RrbiEEII0fRIItRMKL8AdE9OhZbRcKYQ8z+fPedu9WCZSfbQ1WHEBrhxptLMq2vTKamsdmCLhRBCiPoniVAzorx90T3+GkTHQckZzG+/gJZx4pzlXQ06nukXQYC7gfSiSt7cmEm1WXNgi4UQQoj6JYlQM6M8vdA9+rJtMnSeAdSBHkae6ReBi16xPbOET3fKTDIhhBBNhyRCzZBy90D38AsQ0RoKT2N++3m0gtPnLN820J1HrgkD4NtD+czbm4emSc+QEEKIxk8SoWZKeXqje+QlCA6F3GzMM19AKzlzzvK9WvswLjEIgC/25DFzU5YsuCiEEKLRk0SoGVN+AZbXZH4BkHEC8zsvnXfH+puvCOL+bi3QKVibUsRzq9MoLJetOIQQQjRekgg1cyo4FN0jL4OnNxxPwvzhNDRT1TnLD4nz54UBLfE06jiYW8aT358gtaDCgS0WQggh7EcSIYGKaGUZM+TiCvt3on32Hpr53K+9Ood58sag1oR6GTlZXMUzP54gt+TcyZMQQgjRUEkiJABQ0XHo7p8Mej3aL2vRFn523vKRvq7MGBxFTIArZyrNMrVeCCFEoySJkLBSCV1Rd/wDAO37RZh/XHLe8j6uep7qHYHHb6/JvtyT54hmCiGEEHYjiZCwoes5EHXTnQBo82dj3vLzecuHerswqXsoAAv2n2J3tuxLJoQQovGQREicRQ2+CXXtDQBon76DduTAecv3ifLh+lhfNODtjZkUlMlMMiGEEI2DJELiLEop1M13w5U9wWTC/MFraDlZ573mnq4taOXrQn55NTM3Z2GWBReFEEI0ApIIiVopnQ7dhEchqi0Un8H83stoJcXnLO9q0PFkb8tWHDuzSlhy8NwrVQshhBANhSRC4pyUqyu6B56FgCDIzvhtjaFzv/Zq5efKxKtaAPD57lyO55c7qqlCCCHEJZFESJyX8gtA9+Bz4OoOh/agffHhefcZ+0uML90jvTCZ4e2NWVTKNhxCCCEaMEmExAWpltHoJj4BSoe2/ge0Hxefu6xSPNAjFF83PScKK/jfbplSL4QQouEyXOwFBw4c4Ntvv+X48ePk5+fzxBNP0L17d+t5TdOYP38+q1evpqSkhPj4eO655x7CwsKsZYqLi5kzZw7bt29HKUWPHj0YP348bm5u1jInTpxg9uzZHD16FB8fHwYPHsyNN95o05bNmzczb948cnNzCQ0NZdy4cVx55ZUX1RZRNyqxG+rmCWjzPkZb8Clai0hUYrday/q5GfhHjzBe/TmdJQdP0zXck06hng5usRBCCHFhF90jVFFRQVRUFHfffXet55csWcKKFSuYOHEiU6dOxdXVlddee43KykprmXfffZe0tDSmTJnC5MmTOXjwILNmzbKeLy0t5dVXXyUoKIhp06Zx22238fXXX7Nq1SprmcOHD/POO+8wcOBApk+fTrdu3ZgxYwapqakX1RZRd+raG1B9B4OmYf7on2jpx89ZtlukF4Ni/dCAdzZnUVxZ7biGCiGEEHV00YlQly5dGDt2rE0vUA1N01i+fDk33XQT3bp1o3Xr1jz44IPk5+ezdetWANLT09m1axf3338/bdu2JT4+ngkTJrBp0yZOn7bMNNqwYQMmk4lJkybRsmVLevXqxZAhQ1i2bJn1XsuXL6dz586MGDGCyMhIxo4dS5s2bVi5cmWd2yIujlIK9bd7Ib4TVJRhfu9VtKL8c5Yff2UIYd5G8kpN/GfrSQe2VAghhKgbu44RysnJoaCggE6dOlmPeXh4EBsbS1JSEgBJSUl4enoSExNjLZOQkIBSiuTkZGuZ9u3bYzD8/uYuMTGRzMxMiouLrWUSEhJs7p+YmMiRI0fq3JY/q6qqorS01PpVVlZmPaeUsvtXfdVbn186oxH9/ZOhRTiczsX8wetgqqq1rIeLnkd7RqBT8HNKEd8nFzit3Y0x1o31S2ItsW6KXxLrxhXri3HRY4TOp6CgAABfX1+b476+vtZzBQUF+Pj42JzX6/V4eXnZlAkJCbEp4+fnZz1XU/ZC97lQW/5s0aJFLFiwwPo5Ojqa6dOnExwcfK5HvmyhoaH1Vnf9CaPqlffIeWw85qOHcJ33MQFPvFzrN19YGNxfquOD9cf4z9aTXBkTQWKEby111r/GGevGSWLtOBJrx5FYO44jY23XRKixGzVqFMOHD7d+rvnBnpubi+k86+dcCqUUoaGhZGdnn3c6eoOlc4H7noKZL1C6dgXloZHorhtRa9FBrVzY1cqbTalneHLhLt4aGk2gh9FhTW30sW5EJNaOI7F2HIm149gr1gaDoc6dGHZNhGp6bQoLC/H397ceLywsJCoqylqmqKjI5rrq6mqKi4ut1/v5+Z3Va1Pz+Y9lCgsLbcoUFhbanL9QW/7MaDRiNNb+A7q+vvk1TWu0f7FUfCfUXyegffUR5q/nQOsYVGyHWss+dHUYGUWVnCio4PWf05n6l1YY9Y5dvaExx7qxkVg7jsTacSTWjuPIWNv1J1FISAh+fn7s3bvXeqy0tJTk5GTi4uIAiIuLo6SkhGPHjlnL7Nu3D03TiI2NtZY5ePCgTS/Mnj17CA8Px8vLy1rmj/epKdO2bds6t0VcPjVwOKpbH6iuxjzrjXMOnnY36vi/vhF4uehIOlXOh1tPyj8oQgghnO6iE6Hy8nJSUlJISUkBLIOSU1JSyMvLQynF0KFDWbhwIdu2bSM1NZX3338ff39/unWzrDkTGRlJ586dmTVrFsnJyRw6dIg5c+bQs2dPAgICAOjduzcGg4EPP/yQtLQ0Nm3axIoVK2xeWw0dOpTdu3ezdOlSMjIymD9/PkePHmXw4MEAdWqLuHxKKdQdD0JYSyg4jfk//0Srrn2qfJi3C0/0tgyeXnW0kOVJBY5trBBCCPEnSrvI/5bv37+fl1566azj/fr144EHHrAuYrhq1SpKS0uJj4/n7rvvJjw83Fq2uLiY2bNn2yyoOGHChHMuqOjt7c3gwYMZOXKkzT03b97MV199RW5uLmFhYedcUPF8bamL3NxcqqqqLuqaC1FKERYWRlZWVpPoGdGy0jG/9jhUlKEG3YRuzF3nLLvwwCk+25mLXsHL17biihYe9dq2phbrhkxi7TgSa8eRWDuOvWJtNBrrPEboohOh5kgSobrRtm/E/OF0AHR/n4y6smft5TSNtzZmse5EET6uet4cHEWIV/0Nnm6KsW6oJNaOI7F2HIm14zgjEZK9xoTdqK69UH+xbINinvMOWmZq7eWU4sGrQ4kJcKWoopqp69IpN8nmrEIIIRxPEiFhV+qmO6FdgmXl6X9NRSstrrWcq0HH//WNxNdNz/H8Ct7dLP/TEkII4XiSCAm7UgYDuvuegoBgyMnE/PFbaObae3uCPY083ScCvYKNqWf4Zv9pB7dWCCFEcyeJkLA75e2LbtIzYHSBvdvQvv3inGU7hnhwb7cWAHy+O5df0884qplCCCGEJEKifqjWMag7HgBA+24+2o7N5yw7uK0/g9tadqp/c2MWJwoqHNRKIYQQzZ0kQqLe6K4egPpt2w3znJlo2ennLDvxqhZc0cKDcpOZV9emU1hu3y1NhBBCiNpIIiTqlRp9F8RdYRk8/eF0tIrae3sMOsXTfSII9TKSU1LF9PUZVFXL4GkhhBD1SxIhUa+UwYBu4hPg4wcZJ9C++s85y/q46nm2fyTuBh37c8qYtVU2OBRCCFG/JBES9U75BaC753FQCm3Dj5g3/3TOsq18XXmidzgK+PFoIcsO1753mRBCCGEPkggJh1DtE1HDxwKgff7BORdbBLgqwou7rrSsCDpnRw57T5Y4pI1CCCGaH0mEhMOo4TdD+0SorPhtvFD5OcveGB9AvygfzBrMWJ9JXql9tzgRQgghQBIh4UBKp0d3z2Pg6w9ZaWjzPj53WaV4oEco0f6uFFZUM21dBlXVsg2HEEII+5JESDiU8vG3jBcCtPU/oB3ac86yrgYdk/tE4OWi48ipcv6z7aSjmimEEKKZkERIOJyK74TqPwQA83//hVZ57gUUQ71deLyXZfD0D8mF/JBc4JA2CiGEaB4kERJOoUbdAX6BkJOFtvSr85a9MtyLcYlBAMzaepLDeWWOaKIQQohmQBIh4RTKwxPduPsB0H5YhJZ69Lzlx3QM5OqWXpjMGtPXZVBQJitPCyGEuHySCAmnUZ17oK7qDWYz5s/eR6uuPndZpXj4mjAifVw4VWZi+voMTGZZbFEIIcTlkURIOJX620Tw8ILUo2irlpy3rIdRz//1i8DdoONAbhmf7Mg5q0y1WZPeIiGEEHUmiZBwKuXjj7p5AgDaki/Qss69MStApI8rj/YMA2DZ4XzWHi8EoLiymsUHT3H/t8e4c2EyG04U1W/DhRBCNAmSCAmnUz2vhQ6doaoS84fTzrvQIkCPlt7cfEUgAP/aks17v2Rx96JkPtmRS06JZeHF72RrDiGEEHUgiZBwOqUUugmPWhZazExF+9+/L7jZ6tiEILqGe1JZrbHqaCHlJo3Wvq7c1SUYBRzILSO3RFajFkIIcX6SCIkGQfn6W3apVzq0zT+hbfjxvOX1OsVjPcPpGu7JNS29eOXalrwzLIpRHQLpGOIOwPoUeT0mhBDi/CQREg2GapeAGjkOAO3L/6ClHT9veS9XPc8PaMnkvpF0CvVEKQVA3yhfANbJOCEhhBAXIImQaFDU4NGQcNXv44VKL37n+WtaeaNXcDy/gtTCc69aLYQQQkgiJBoUpdOhm/AIBARbVp3+/IOLrsPHVc+V4Z6AvB4TQghxfpIIiQZHefmgu+8p0OnQtq5H27H5ouuwvh5LKbrgwGshhBDNlyRCokFSbdpZXpMB5i8+RCs5c1HXd4/0wlWvyC6u4sip80/HF0II0XxJIiQaLDX8FgiNhMJ8tHmzL+paN4OOHi29Afg5pbA+mieEEKIJkERINFjK6ILurodAKbTNa9D2bb+o6/u29gFgQ0oR1bIvmRBCiFpIIiQaNBUTj7r2BgDM//0XWllpna/tHOaJt4uO/PJqtqfJStNCCCHOJomQaPDUyNsgOBRO56Et/KzO1xn1ip6tLL1C3x88WV/NE0II0YhJIiQaPOXqhu6OBwHQ1q5A27+zztf2i7IkQj8cOsnOzOJ6aZ8QQojGSxIh0Sio+E6o/kMAMH/8T7RTOXW6rn2IOwktPCivMvPST2ksOXhaptMLIYSwkkRINBrq5ruhdSwUn8H872loVZUXvEanFC8MbMkNV4Rh1mDOjhxmbsqiwmR2QIuFEEI0dJIIiUZDGV3Q/X0yeHrDiWS0L/9Tp+tc9DqeGxzPvVe1QKdgbUoRz/yYyukyUz23WAghREMniZBoVFRgyG+71Cu09T9gXv9D3a5TiuHxAbw0sCXeLjqST5fzxvoMmVYvhBDNnCRCotFRHbugbvxtl/ovZqGdSK7ztZ1CPZk+KAp3g46DuWUsPHCqvpophBCiEZBESDRKasgYSOwOpirLeKGL2KU+wseFe7u1AODLPXkcOVVWX80UQgjRwEkiJBol6y71QS3gVA7aFx9e1PUDon3o1cqbag3e2phFuQyeFkKIZkkSIdFoKQ8vdPc8btmlfsvPmH9ZW/drleLv3UMJcDeQeaaST3fUbTq+EEKIpkUSIdGoqZh41PCxAGj/+zdabnadr/V21fPwNWEArDhSwLYMWXBRCCGaG0mERKOnhv4VYttDeRnm2W+hVVfX+drOYZ6MiPcH4N1fsiiuqPu1QgghGj9JhESjp/R6dHc/Bu4ecPQQ2nfzL+r62zsHE+njQmF5NYsOnq6nVgohhGiIDPau0Gw2M3/+fNavX09BQQEBAQH069eP0aNHo5QCQNM05s+fz+rVqykpKSE+Pp577rmHsLAwaz3FxcXMmTOH7du3o5SiR48ejB8/Hjc3N2uZEydOMHv2bI4ePYqPjw+DBw/mxhtvtGnP5s2bmTdvHrm5uYSGhjJu3DiuvPJKez+2cDIV1AI17u9oH7+JtmweWodEVGyHOl3rotdxR5dgpv6cwbeHTjOsnT8B7nb/qyGEEKIBsnuP0OLFi/nxxx+5++67efvttxk3bhzffvstK1assJZZsmQJK1asYOLEiUydOhVXV1dee+01Kit/3zLh3XffJS0tjSlTpjB58mQOHjzIrFmzrOdLS0t59dVXCQoKYtq0adx22218/fXXrFq1ylrm8OHDvPPOOwwcOJDp06fTrVs3ZsyYQWpqqr0fWzQAuh79UD36gWbG/J9/ohUX1fna7hFetAtyp7JaY/7evHpspRBCiIbE7v/tTUpK4qqrrrL2uoSEhLBhwwaSky2L3mmaxvLly7npppvo1q0bAA8++CATJ05k69at9OrVi/T0dHbt2sXrr79OTEwMABMmTOD111/n9ttvJyAggA0bNmAymZg0aRIGg4GWLVuSkpLCsmXLuO666wBYvnw5nTt3ZsSIEQCMHTuWvXv3snLlSu69996z2l5VVUVVVZX1s1IKd3d36+/tqaY+e9fb3Olun0R1yhE4mYn2yUzUg8+hdJZ8/3yxVkpxZ5cQnvnxBD8kF3Bjh0DCvV0c1ewmQ76vHUdi7TgSa8dxRqztngjFxcWxevVqMjMzCQ8PJyUlhcOHD3PHHXcAkJOTQ0FBAZ06dbJe4+HhQWxsLElJSfTq1YukpCQ8PT2tSRBAQkICSimSk5Pp3r07SUlJtG/fHoPh90dITExkyZIlFBcX4+XlRVJSEsOHD7dpX2JiIlu3bq217YsWLWLBggXWz9HR0UyfPp3g4GC7xKY2oaGh9VZ3c1X57AxOPj4ebc82vH5Zg8/o24ELxzosDJYlF7Pp+CkWJRXz6vCOjmhukyTf144jsXYcibXjODLWdk+ERo4cSVlZGY8++ig6nQ6z2czYsWPp06cPAAUFBQD4+vraXOfr62s9V1BQgI+Pj815vV6Pl5eXTZmQkBCbMn5+ftZzNWXPd58/GzVqlE3iVJOR5ubmYjLZd4NOpRShoaFkZ2ejabLflV15+KAbew/m/35A4afvUdwikvDeA+oU65vb+7Dp+Cm+P3iSIdEetAlwO295YUu+rx1HYu04EmvHsVesDQZDnTsx7J4Ibd68mQ0bNvDQQw9ZX1d9+umn+Pv7079/f3vfzq6MRiNGo7HWc/X1za9pmvzFqg99BqEO7UXbup7qWdOp7tSlTrGO9nelb2sf1p0o4r+7cnh+QEsHNbhpke9rx5FYO47E2nEcGWu7D5b+/PPPufHGG+nVqxetWrWib9++DBs2jMWLFwO/99oUFhbaXFdYWGg95+fnR1GR7UDX6upqiouLbcr8uWen5vMfy5zvPqLpUkqhbn8AQsLgdB6n336pzn+pbk0MQq9ge2YJe0/WfQ8zIYQQjY/dE6GKigp0OttqdTqd9YdQSEgIfn5+7N2713q+tLSU5ORk4uLiAMs4o5KSEo4dO2Yts2/fPjRNIzY21lrm4MGDNq+s9uzZQ3h4OF5eXtYyf7xPTZm2bdva8YlFQ6XcPdDd9zQYjJT/uh5t9dI6XRfm7cL1sX4ATFuXIStOCyFEE2b3RKhr164sXLiQHTt2kJOTw6+//sqyZcusM8SUUgwdOpSFCxeybds2UlNTef/99/H397eWiYyMpHPnzsyaNYvk5GQOHTrEnDlz6NmzJwEBAQD07t0bg8HAhx9+SFpaGps2bWLFihU2Y3yGDh3K7t27Wbp0KRkZGcyfP5+jR48yePBgez+2aKBUqzbobr4bAPPXn6CdOFqn68YlBtM20I3iSjOvrk3nyz25mKVLXAghmhyl2fklXFlZGfPmzePXX3+lsLCQgIAAevXqxZgxY6wzvGoWVFy1ahWlpaXEx8dz9913Ex4ebq2nuLiY2bNn2yyoOGHChHMuqOjt7c3gwYMZOXKkTXs2b97MV199RW5uLmFhYZe0oGJubq7NtHp7UEoRFhZGVlaWvHN2AJc5b1G2eS2EhKN77i2Um8cFr6mqNjN7ew4rjhQA0DXck0d7huPtqq/fxjZi8n3tOBJrx5FYO469Ym00Gus8WNruiVBTJIlQ46aUIsTLg8y/3wL5eahrBqCb8Gidr19zrJB//5pNZbVGCy8jr/+lFYEetQ+qb+7k+9pxJNaOI7F2HGckQrLXmGgW9N6+6Cc+AUqHtvknzJt/qvO1A9v48sag1rTwMnKyuIq3NmZSbZZ/DIUQoimQREg0GyquI+qGsQBo//s3WnZGna+N9nfjhQEtcTMo9uWUMX+fbMMhhBBNgSRCollRw/4KcVdARTnmD6ehVZTX+doIHxf+3t2y2un8fadkar0QQjQBkgiJZkXp9OgmPg4+fpBxAu2z9y7qPXT/aF+ubeOLWYM3N2ZRWG7fFceFEEI4liRCotlRfoGW9YX0erSt69FWfXtR19/brQWRPi7kl5mYuSlLptULIUQjJomQaJZUXEfUXy3rC2kLPkE7tKfO17oZdDzVJwIXvWJHVgnf7D9VX80UQghRzyQREs2WGjgMdfUAMJsx/2cG2uncOl/b2s+ViVe1AODz3XksOXi6vpophBCiHkkiJJotpRTqtknQMhrOFGL+9zS0qso6X/+XGF/+2jEQgDk7clh4QHqGhBCisZFESDRrytUV3aRnwNMbUo6gzX2/zoOnlVKMSwxibIIlGfpsZy4L9kkyJIQQjYkkQqLZU0Et0N33FOh0aL+sRVu5sO7XKsXfOgVza6cgAP67O5d5e2WNISGEaCwkERICUO0TUWPvBUBbNBdt968Xdf0tCUHcnmhZzv2LPXlMW5dBQZlMrRdCiIZOEiEhfqMbMBTVfwhoGuaP3kTLOHFR14+5IpC7u4agV7A57QwPLjvG2uOFsjeREEI0YJIICfEH6paJ0C4BKsowv/cK2pmii7p+RHwA/xwcRRt/V85Umnl7Uxav/ZzOqVL7btorhBDCPiQREuIPlMGA7v6nITgUTuVgnjUdrbr6oupoE+DGjMFRjEsMwqBTbM0o4envT1BUcXH1CCGEqH+SCAnxJ8rLB90DU8DVDQ7vRVv8+UXXYdApbr4iiLeHRBHqZSS31MTMTZmyCrUQQjQwkggJUQsV0Qp150MAaCu/Qdv5yyXV08rPlcl9IzDqFNszS1h4QBZeFEKIhkQSISHOQdetN+q6EQCYP5mJdjLzkuqJ9nfj3m6WVaj/tzuXfSdL7dZGIYQQl0cSISHOQ42+C2I7QFkp5n+/jlZRfkn1/CXGl/7RPpg1+OfGTJlaL4QQDYQkQkKchzIYLIst+vpDxgm0//7rkqbDK6X4e/dQWvpadq1/c1Mm1WYZLySEEM4miZAQF6D8AtDd+9vK01t+Rlv+9SXVU7NrvatesSe7lA+3ZsvgaSGEcDJJhISoAxXXETV2IgDa4s8xb1pzSfW08nXloWvC0Cn4IbmQ937Jlp4hIYRwIkmEhKgj3YBhqEGjANDmvoe2f+cl1dO7tQ+P/JYMrTlWyMzNWZIMCSGEk0giJMRFUDfdiereF6qrMf97GlrqsUuqp1+0L0/0DkevYF1KEW9uzMQkyZAQQjicJEJCXASl06Huevj3bTjefQntVM4l1dWrlQ9P94nAoIONqWd4YXUqG1OLqKw227nVQgghzkUSISEukjIa0U16BiJaQ2E+5ndfRiu/tLWBerT05pm+kRh1in05ZbyxPpM7v0nm3c1Z7MkukQ1bhRCinkkiJMQlUB6e6B5+EXwDIDMV85yZaOZL68npGuHFO8OiualDAEEeBkqrzKw+Vshzq9P4ZMel9TYJIYSoG0mEhLhEyj8Q3aT/A4MBdv6CtmzeJdcV4ePCnV1C+GhkDFOva8VfYnwBWHIon81pZ+zVZCGEEH8iiZAQl0G1aYe6bRIA2tIvL3lPsho6pejYwoMHrw5jZPsAAN7bnMXJ4srLbqsQQoizSSIkxGXS9boONXA4AObZb6NlpNql3ts7B9MuyI2SKjMzNmRSVS3jhYQQwt4kERLCDtRfJ/w+k+yD19CKCi67ToNO8WTvCLxcdBw5Vc5nO2W8kBBC2JskQkLYgWVPsqchMARysjC//iRaVtpl1xvsaeTha8IAWHpYxgsJIYS9SSIkhJ0obx90j7wEwaGQdxLz60+hHdx92fV2j/S2jheauSmLVUcLZFq9EELYiSRCQtiRCo1A938zICYeykowv/Mi5o2rLrve2zsH0ynUg3KTmfd+yeaVtenklVbZocVCCNG8SSIkhJ0pb190j7+K6tYHqqvRPn0X87dfXladBp3ixQEtubNzMEadYntmCf9Ydlx6h4QQ4jJJIiREPVBGF9Q9j6OG3QxYptabVy25rDr1OsVNHQN5e2gUbQPdKK2y9A79c2OmbMshhBCXSBIhIeqJ0unQjbwNddMdAGjzZmP+dd1l19vS15Xp17fmzi7BGHSw4cQZXlyTRnFF9WXXLYQQzY0kQkLUMzV4NOraGwDQ5sxEO7DrsuvU6xQ3dQjk+QEtcTfo2J9Txv/9eILcEhk3JIQQF0MSISHqmVIKdfPdqKt6Q7UJ8wevo504ape6E0M9ef36VgS4G0gtrOTp70+Qkl9ul7qFEKI5kERICAdQOh1qwqMQ38my6OI7L6KdzLRL3dH+brwxqDWRPi6cKjPx5PcneO3ndH5ILiC/zGSXewghRFMliZAQDqKMRnSTnoGW0XCmEPOMZ9Cy0u1Sd7CnkenXtyahhQeV1Rq/phfzry3Z3LUwmSdWpvD5rlx2ZZVQbpJB1UII8UcGZzdAiOZEuXuge+QlzG89BxknMP/zGXSPvYqKaHXZdXu56nnl2pYcz69ga0YxWzOKOXKq3Pr19f5T6BXEBrpxZbgXo9oH4GqQ/wsJIZo3+VdQCAdTPn7oHn/N0jNUVID5n8+gpR23T91K0SbAjVsSgvjn4Cg+uSmWf1wdSv9oH4I9DFRrcDivnC/35PHO5izMsgaREKKZq5ceodOnT/P555+za9cuKioqCA0NZdKkScTExACgaRrz589n9erVlJSUEB8fzz333ENYWJi1juLiYubMmcP27dtRStGjRw/Gjx+Pm5ubtcyJEyeYPXs2R48excfHh8GDB3PjjTfatGXz5s3MmzeP3NxcQkNDGTduHFdeeWV9PLYQdaa8fdA9/irmt1+AE8mY//ksusdeRrWOtet9AtwNXBfjx3UxfgCcLK5kR2YJH28/ycbUM0TuzePWTsF2vacQQjQmdu8RKi4u5rnnnsNgMPDMM8/w9ttvc8cdd+Dp6Wkts2TJElasWMHEiROZOnUqrq6uvPbaa1RWVlrLvPvuu6SlpTFlyhQmT57MwYMHmTVrlvV8aWkpr776KkFBQUybNo3bbruNr7/+mlWrft/O4PDhw7zzzjsMHDiQ6dOn061bN2bMmEFqaqq9H1uIi6Y8vdE99gq0aQelxZjfnIJ2eF+93rOFlwtD4vyZ1D0UgHl7T7Eupahe7ymEEA2Z3ROhJUuWEBgYyKRJk4iNjSUkJITExERCQy3/8GqaxvLly7npppvo1q0brVu35sEHHyQ/P5+tW7cCkJ6ezq5du7j//vtp27Yt8fHxTJgwgU2bNnH69GkANmzYgMlkYtKkSbRs2ZJevXoxZMgQli1bZm3L8uXL6dy5MyNGjCAyMpKxY8fSpk0bVq5cae/HFuKSKA9PdI++BHFXQFkp5pkvoO3YVO/3vTbGj1G/beT67uYsDueV1fs9hRCiIbL7q7Ft27aRmJjIW2+9xYEDBwgICOD666/nuuuuAyAnJ4eCggI6depkvcbDw4PY2FiSkpLo1asXSUlJeHp6Wl+lASQkJKCUIjk5me7du5OUlET79u0xGH5/hMTERJYsWUJxcTFeXl4kJSUxfPhwm/YlJiZaE64/q6qqoqrq9wXplFK4u7tbf29PNfXZu15xtoYea+XuiXr0Jcz/+Sfazs2YP5yObtzf0fUfUq/3vaNLCBlnKvk1vZipP6fz5pBogj2Nl1VnQ491UyKxdhyJteM4I9Z2T4RycnL48ccfGTZsGKNGjeLo0aN88sknGAwG+vfvT0FBAQC+vr421/n6+lrPFRQU4OPjY3Ner9fj5eVlUyYkJMSmjJ+fn/VcTdnz3efPFi1axIIFC6yfo6OjmT59OsHB9TeGoqanTNS/hh5r7aWZ5P97OiUrFmL+/AO8zFX43Hpvvf6DMGN0CPd8sYMjucU8/UMqd/ZozchO4bgZ9ZdVb0OPdVMisXYcibXjODLWdk+EzGYzMTEx3HrrrYAlmUhNTeXHH3+kf//+9r6dXY0aNcqmB6nmB1Bubi4mk30XplNKERoaSnZ2tuweXs8aU6y1m+5CZ3TD/O0XFH3xEWfSU9GN+ztKf3mJyflM7h3Ksz+eILu4kjfXHGH2pmOM6hDI4Lb+uBsv7u15Y4p1YyexdhyJtePYK9YGg6HOnRh2T4T8/f2JjIy0ORYZGcmWLVuA33ttCgsL8ff3t5YpLCwkKirKWqaoyHYAZ3V1NcXFxdbr/fz8zurZqfn8xzKFhYU2ZQoLC63n/8xoNGI01v5qoL6++TVNk79YDtJYYq1uGIvy9kX7Yhbauu+pLjiN7t4nUa5uF774EgR5GHh/eDSrjxXyzf5T5JSY+GRHDgv2n2JcpyAGtfVDd5G9Uo0l1k2BxNpxJNaO48hY232wdLt27cjMtN06IDMz05qZhYSE4Ofnx969e63nS0tLSU5OJi4uDoC4uDhKSko4duyYtcy+ffvQNI3Y2FhrmYMHD9r01OzZs4fw8HC8vLysZf54n5oybdu2teMTC2F/uv5D0P19MhhdYM9Wy4yyM4UXvvASGfU6Brf1598jYvjH1aGEehk5U1HNh1tP8tT3Jzh2WvYvE0I0TXZPhIYNG8aRI0dYuHAh2dnZbNiwgdWrVzNo0CDA0u01dOhQFi5cyLZt20hNTeX999/H39+fbt26AZYepM6dOzNr1iySk5M5dOgQc+bMoWfPngQEWGa69O7dG4PBwIcffkhaWhqbNm1ixYoVNq+2hg4dyu7du1m6dCkZGRnMnz+fo0ePMnjwYHs/thB2p7pcje6xl8HDC44nYZ72NFpudr3e06BTXBfjxwc3tOGeriG4G3QcOVXO4ytT+HjbSUqrquv1/kII4WhKq4e+p+3bt/PFF1+QnZ1NSEgIw4YNs84ag98XVFy1ahWlpaXEx8dz9913Ex4ebi1TXFzM7NmzbRZUnDBhwjkXVPT29mbw4MGMHDnSpi2bN2/mq6++Ijc3l7CwsEtaUDE3N9dmNpk9KKUICwsjKytLulrrWWOPtZaVhvmdl+BUDvj4oXv0ZVRklEPufaq0itnbc9iYegYAD6OOq1t60ae1D51CPTHobF+ZNfZYNyYSa8eRWDuOvWJtNBrrPEaoXhKhpkYSocatKcRaKzhtSYbSj4OnN7pHXkRFOe4V747MYj7adpLMM7//PfBx1dOzlTftg91p4+9GhI8LBr2u0ce6sWgK39eNhcTacSQRaqAkEWrcmkqstZJizO+8CMeTwN0D3UPPo2I7OOz+Zk3jYG4Z61OK2Jh6hqIK29dkRp2itZ8rXaOC6N7CQIy/q6y7Uo+ayvd1YyCxdhxJhBooSYQat6YUa628FPN7r0DSfnBxRffgFFT7RIe3o9qssedkKb+mn+F4fgXH8ysoN5ltykT5uXJdjC/9onzwcauXbQ2btab0fd3QSawdRxKhBkoSocatqcVaq6jA/MFUOLATjC7o7nkMdWVPp7bJrGmcLK7iWH4Fu/NMrDmcQ5XZEmuDTnFThwDGJgSh10kPkb00te/rhkxi7TjOSITsPmtMCFG/lKulJ4jE7lBVifnf0zB/MQutqvLCF9cTnVKEebvQu7UPrw7vyKej23LvVS2ICXDFZNaYv+8Ur/2cTnGlzDoTQjQskggJ0QgpoxHd/ZNR148CQPvpO8xTn0TLTndyyyy8XfUMa+fPW0OiebRnGC56xfbMEp5cmUJqYYWzmyeEEFaSCAnRSCmDAd1fx6N76AXw9oX045hfeRTzxtXObpqN/tG+TLu+NcEeBjLPVPHkyhNsTjvj7GYJIQQgiZAQjZ5K6Iru+XcgvhNUVqB9+g7mrz9BM5svfLGDxAS48eaQKK5o4UG5ycy0dRk8uyqVXVklMuZCCOFUkggJ0QQovwB0j76EGmHZ7Fj7YRHax286ddzQn/m6GXhpYEtGtg/AoIN9J0t5YU0aT35/gi3pZzBLQiSEcAJJhIRoIpROj+6Gsai7HwW9AW3reswzX0AraTivoQw6xfgrQ/hwRAzD2vnjolccOVXO1J8zeHxFCjsyi6WHSAjhUJIICdHE6K4egO7hF8DdA5L2Y54+GS3vpLObZSPY08i9V7Xgo5ExjO4QgLtBx7H8Cl76KZ0pq9M4nFfm7CYKIZoJWUeoDmQdocatucZaS0+xbMtRcAq8fNDd+2S9L754qbEuKjexYP8pvksqwPTb+kMJLTzwMOqorNaoqjZTZdaICXBjVPtAQryM9fUIjUZz/b52Bom148g6QkIIu1GRUej+bwa0agPFRZjffgHzym8a5D/kPm4GJnRtwYcj2nBtG190CvaeLGVLejE7s0rYl1PG4bxylicVcP+3R3n/lyxOFjec8U9CiMZL1r0XoglTAUHonp6O9r8P0TatRvvmM7TjSejuehjl7uHs5p0l2NPIQ9eEcVOHAHZnl2LQKYx6hYteYdbgx6MF7Mku5cejhaw+Vki/KB+uaOFBS19XWvq64GHUO/sRhBCNjCRCQjRxysUV7noI2rRD+/I/sGMz5sxUdPc8gWod4+zm1SrS15VIX9ezjveN8uFgTinz9p1iZ1YJPx0v4qfjRdbzQR4GEkM9uTUxiCAPeX0mhLgwSYSEaAaUUqh+g9FaRmP+cDpkZ2Ce+jhqyBjUsFtQxsaTNLQP8eDFgR4czitjXUoRqYUVpBVWkl9mIq/UxOpjhWw4UcSYKwIZ2T4AF71lBEC5yczGE0WsOVaIBvy9eygta0m2hBDNiyRCQjQjqk07dM/NRPtyFtrW9WjfzUfbtQXd+IdRrWOd3byL0i7InXZB7tbPxRXVHM0v54vdeRzKK+N/u/NYdbSQMR0DOXKqjPUpZygz/b7I5GMrUph4VQv+EuOLUrIZrBDNlQyWFqKZUd6WGWS6+5+2bM2RcQLz1Ccwfz0H7UzRhStooLxc9SSGejLt+lY81jOMQHcDJ4ur+NeWbH5ILqTMZCbUy8htiUEkhnpQWa3xry3ZvLEhk+IK2QxWiOZKeoSEaKZU117o4hJ+7x36YTHaz9+jBg5DXT8S5eXj7CZeEqUU/aJ96R7pzTf7T7E57QyxAW78JdaPjiHuKKUY3VFj8cHTfL4rl02pZ0jKK2NYnD9tAtyICXDD21UGXQvRXMg6QnUg6wg1bhLrC9P2bsO8+H+QetRywM0dde0NljFErm51rqexxfrIqTL+uSGT7GLbv98hnkZiA91oF+RGuyB3YgLcrGONGorGFuvGTGLtOM5YR0h6hIQQqISr0F3RFXZvwbzkS0g/bhk/tPMXdH+fjAqNdHYT60XbQHfeHhrFD8kFHM4r59jpcrKLq8gpsXxtSrVsT2LQQbS/G51DPenZyptof1ebcUWappFWWMmB3FJa+7nSPrjhLU0ghKidJEJCCMDyPzE6X42uU3fY+QvmL2dBZirmVx9Hd9c/UFf1dnYT64WHUc/I9oHWzzWDro+cKicpr4xDeWUUlldz5JTl2Nf7T9HCy8g1Lb2J8nNlX04pOzNLOFVmstYxpK0fd3YJwd3YsHqRhBBnk0RICGFD6XTQtSe6mHjMH82w7Fc26w1U8kHUmLtQhsYz1f5S1Ay6Tgz1BCy9PTklVRzIKWNL+hm2Z5ZwsriKxQdP21znoldE+7tyOK+cFUcK2JlVwsPXhNEh5Py9Q8dOl7Mto5hIXxc6tfDES8YnCeFQkggJIWql/ALQPfYq2uLP0VZ+g7Z6KdqRA+j+Oh4V38nZzXMYpRQtvFxo4eXCgDa+lJvM7MwsYVPaGbLOVNIh2J0u4V50CHbH1aBjd3YJ727OIru4imd+TOXG9gFcF+NLhI8Luj+8Tjtyqox5e0+xNaPYekynoG2gG53DLIlYbIAbrgbpVXK2H47ks23DSR68KlAG0jdBMli6DmSwdOMmsb582q4tmOfMhLISy4EOXdDddPtZaw9JrC1KKquZvT2H1ccKrce8XXTEB1vWPtqfU8bOLEssdQq6hHlysriK9CLb/dMMOmjj70b7YHfaB3uQGOZh3UZEYu0YJrPGnd8cobjSzJ1dQripQ4Czm9SkyWBpIUSDpDr3QPfKB5YB1Ou+hwM7MR/YieraCzX6TlRwqLOb2KB4uuh56Jowrm7pxZJD+STllXGm0szWjBK2ZvyeAPWP9mFMxyAifFwAyC2pYldWCTuzStifU0pBeTVJp8pJOlXOkkP5uBkUvVr58JcYX9pf4JWbsI892SUUV1oW4tycViSJUBMkPUJ1ID1CjZvE2r603Gy0b79E27IWNA2MLqihf0UNugmdi4vEuhYms8ax0+UczC3jcF4Zfm56RsQHEOrtcs5rNE3jZHEVB3MtA7Z3Z5eQdeb3f4cifVwYfWUrrmmhw72W12fFFdV8vf8UR0+Xc2eXYNoGup9VRlzYO5uzWPOHnr3Zo2JkH7t65IweIUmE6kASocZNYl0/tPQUzPNnw8HdlgMtItCNu5+Ia4dIrOuBpmkczC3jx6OFbDxRREW1Jb7ernpGxgcwtJ0fHkY91WaNlUcK+HJvHmd+WzHboFPc3TWEIW396nU7EU3TmtR2JVXVltdiJVVmfN2NFJZVMfGqEIa3k16h+iKJUAMliVDjJrGuP5qmof26Du3rOVCYD4B7379QOfxW8A+8wNXiUpVWVbP+xBmWJRWSml8GWMYg/SXWj60ZxaQVWsYatfR1IcTTyPZMy+u4vq19mNQjtF6m9a86WsDnu3IZ2s6fm68Isnv9zrAto5hX1qYT4G7g9h5RvLM2mStaePDada2c3bQmS8YICSEaFaUUqkc/tISr0Jb8D+2n5ZSt+xG2rLe8LvvLyEa1s31j4WHUM7itP7f3jmf+5iTm7c0j80wlCw9YpvR7u+q5tVMQg2L90Cn49lA+n+7MYd2JIo7ll/PXKwJxNegw6hRGvcLdoKOVnytulzBDTdM05u07xZd78gD43+48fFwt7Wvs1p+w7L3Xs5U318YF887aZA7klFJYbsLXTX58NhXyJymEuGzKwxP1t3uh93Xov55D5cE9aIv+i7ZxFbpb7kF16ubsJjZJBp2OAW186dPamw0nilh5pIC4IHf+2jHQZj2iG9sH0DbQjRkbMkkvquTtTVln1aVT0MrXldhAN+IC3WkX5EYrP1ebKf9/Vm3W+HCrZVNbgPbB7hzMLWPW1pMEeRi5KsLL/g/tIJXVZn5Ntyxt0Lu1D2G+7sQGuJF8upwt6cVcH+vn3AYKu5FESAhhN6pVDCEzZpO56EvMCz6FnCzM770C7RPRjbodFR3n7CY2SXqdZaPZftG+5yzTIcSDt4dG8fmuXLKKqzBVa1SZNUzVGkWV1eSXmUgpqCCloIJVRy2JjafRMuW/Q7AH7YLd8Hcz4G7U4WHUoxT8c0MGWzNKUMC93VowpK0f7/6SzZpjhczYkMFr17UmNrDue9U1JDuzSiitMhPobiA+2DLQ/OpW3iSfLmdz6hlJhJoQSYSEEHallEJ3zQDo3B1t2Xy0Vd/Cwd2YD+6GxO7oRo5DRUY7u5nNkp+bgQevDqv13KnSKus2IkmnykjKK6ekysz2zBLrGKPauOgVj/UK55qW3gA80COU06VV7Mou5ZW1abwxqDUtvM6eHadpGicKKticdob8smr6R/tccBVuR9pwwrLPXK/W3tZesZ4tvfl8Vy57TpZQXFmNl4ssrtgUSCIkhKgXys0DNeYutP5D0JZ+hbb5J9j9K+Y9W1FX9Ubd8DdUWNPczLUxCvQwEuhh5OrfEppqs0ZKQQUHcko5kFvG0dPllFRWU1plxvzbGFZfNz3/1yfCZk0jg07xdN8I/u+HVFIKKvi/H1PpGOJBiKeRFl5G/N0MHMgtZXPaGZvlAL5PLiA+yJ2bOgbQLcKr1ldymqaRdKqcjSeK2JJejLtRx4BoX/pF++BnxzE7FSbb12I1In1daenrQlphJdsyiul/nh440XhIIiSEqFcqqAVq/MNog0ejffsF2rYNaFvXo23biOrRFzV8LKpFuLObKf5Er1PEBLgRE+DGDfG/H9c0jYpqjZLKanxcDRj1ZycsHkY9zw2I5KnvT3Cq1MS6lKJa7+GiV3QJ88TLRc/PKUUcyitj6s8ZtPR1oXOoJ0a9wvDbgO6i8mo2p50hr9RkU8fx/Bw+25lDt0gvBraxbGXi42rAy0V33vFN57Mjs4Ryk5lgDwNxf3q1d01Lb9IKT7E57YwkQk2EJEJCCIdQYZGo+55CGzIG89IvYdcWtF/Wom1Zh7q6P+qGsbJCdSOglMLNoC44wyzIw8i7w6LZnVXCyZIqcoqryCmpIq/URKSPCz1bedM13Ms6lf+2zsEsPXSalUcKSCustC4B8GduBh3dI73o2cqbwnITq44WcuRUOb+kFfNLmu2+bZ4uesK8jHSL8KJ7pBet/VzrtM7RhlRL4tartc9Z5a9p6c38faesydKlzLQTDYskQkIIh1Kt2qB/4Fm0E8mYv/0S9mxF27wG7dd1qP5DUMNuRnnL/7SbAi8XPb3+8GrpfALcDdzZJYQxHQNZe7yIU6VVmMyWAd1V1Rp6naX3qEuYp81GtIPb+pOSX87qY4VszSimsPz313dnKqo5U2HZpuR/e/II8TTQNdwLb1fLwpPVmuUVoFKWBMvdoMPVoGOr9bWY91ntjPZ3JdTLSHZxFTsyi+nZqm7PJxouWVCxDmRBxcZNYu04lxJr7XgS5sX/gwM7LQfc3FGDR6OuG4FybZwzjhxBvq/Prapao7iymqKKag7nlfFrejG7s0uorK57nFp4GZk1oo1lraw/xfqTHTksPniaFl5GIn1c0CnLn4dBpwj2MNDCy4UWXkZCvIyEeRkx6htGr1FKfjn7ckrpH+3bYAd6y4KKQohmR0XHoX/0JbQDuzB/8ymkHkNb/DnaT99ZkqG+g1Eens5upmhEjHqFv7sBf3cDrf1cuT7WjwqTmV3ZJew9WUq12dLDpFcKvQINKDeZKTeZKavSqKo2MyTO/5yv0Xq39mbxwdOcLK7iZPH5/5Psold0CPEgMdSDzqGeRPmff22muio3mXHRqzrVVVhu4n+78/jxaAFmDRYeOM1DV4fROUz+XoH0CNWJ9Ag1bhJrx7ncWGtms2Ug9eLPIe+k5aCbuyUZuvYGVEDT2LrBHuT72nFqi/X+k6WcLKnC/Ntns2aZbZZbUsXJkiprklRaZbapy9NFh4+rHle9Dhe9wtWgQ6/A/FsdmqahgFBvF6L8XGnt50qUvxsK2JdTyt6TpezLLuVEYQVeLjraB7vTPtiDDsHutAlww0WvrAlcVbXGd0mnmbf3lLUdPq56in7bg25onB93dgk5a5xTuclM6m9rSqXkl5NSUIFeKTq28CChhQdxge7WQfJlVWZSCspJya+gzGQmwseFlj6utPAyotedP0k7WVzJz8eLcDPqGBEfcM5YXwrZa8zOJBFq3CTWjmOvWGumKrQt69C+XwhZaZaDej2qWx/UwBtQ0W3t1OLGS76vHedSY61pGmmFlezOLmF3dgl7T5ZRbjJf+MLLoFNYt04xa1gToDb+rtzTtQUxgW58uiOHFUcKAAj3NjIg2peTJVVkn6kkq7iK06UmzveUrnrLjML8cpPNEgh/ZNApIrxdaO3vSkyAK2383Wjj74YZ2HiiiLXHLbMEwTI+7OORMeh1Z7+GvFSSCNmZJEKNm8Tacewda81shn3bMX+/CJL2/X6iTTvUwOGorj1Rhua5l5l8XzuOvWJtMmukF1p6TipMGhXVZipNGtWahk4pFJZEplqD9KIKUvIrOFFQQfZvr98ifVxIaOFBQqgH7YM9OFVaxYGcMg7mWtZ6KiyvPuuevm56bk8MZmAbX5semp1ZJby3OYtTZaazrqm5Lvq33qgoP1cqqs3syS5l38lSCits7+PvbqCNvyseRh3pRZVkFFWeczyWTmFdh0oBCaEe9IvyoX+0LwZJhBouSYQaN4m149RnrLXjR9DWLEPbuh6qf/vH29ff0kt0VW9LcmSHsReNhXxfO46zY11aVY3JbHmtdS6aplFSaabSbBnjVPXbFirh3i42s+z+qLiimm8OnOJ0mYkwLxdCvY2EerkQ5m0856aymqaRWljJ0dPlBLgbiPZ3PatstVkjt6SKtMJKjueXcyy/nGP5FdbxVG38XekX7UOf1j4Eetj+R6ZJJkKLFy/miy++YOjQodx1110AVFZWMnfuXDZt2kRVVRWJiYncc889+Pn5Wa/Ly8vjo48+Yv/+/bi5udGvXz9uvfVW9PrfvxH279/P3LlzSUtLIzAwkNGjR9O/f3+b+69cuZKlS5dSUFBA69atmTBhArGxsRf1DJIINW4Sa8dxRKy1ony0dd+jrV0Jhad/PxEYYlmx+poBqIjW9XLvhkS+rx1HYm0fxRXVlJnMBHueuxfXGYlQvc7pS05O5scff6R1a9t/lD777DO2b9/OY489xksvvUR+fj5vvvmm9bzZbOb111/HZDLx6quv8sADD7B27VrmzZtnLZOTk8O0adPo2LEjb7zxBsOGDePDDz9k165d1jKbNm1i7ty5jBkzhunTp9O6dWtee+01CgsL6/OxhRD1SPn4oxs+Ft20j9A98Cyqez9wdYNTOWjfL8T84j+ofus5tL3bLa/WhBANgper/rxJkLPUWyJUXl7Oe++9x3333Yen5+9T9EpLS1mzZg133nknV1xxBW3atGHSpEkcPnyYpKQkAHbv3k16ejr/+Mc/iIqKokuXLtxyyy18//33mEyWLvEffviBkJAQ7rjjDiIjIxk8eDBXX3013333nfVey5Yt49prr2XAgAFERkYyceJEXFxc+Omnn+rrsYUQDqIMRlTnHugmPo7uzf+iu/9p6HI1KJ1lk9d3X8L84j8wr/8BraLc2c0VQjRQ9baO0Mcff0yXLl3o1KkTCxcutB4/duwY1dXVJCQkWI9FREQQFBREUlIScXFxJCUl0apVK5tXZZ07d+bjjz8mLS2N6Ohojhw5YlMHQGJiIp9++ikAJpOJY8eOMXLkSOt5nU5HQkKCNeH6s6qqKptXYEop3N3drb+3p5r6mtOYBmeRWDuOs2Kt3Nzgqt7oruqNlncS8+plaOu/h6w0tLnvo82bbRlY3fNaVFxHlK5hLHB3OeT72nEk1o7jjFjXSyK0ceNGjh8/zuuvv37WuYKCAgwGg00vEYCvry8FBQXWMn9MgmrO15yr+bXm2B/LlJWVUVlZSXFxMWaz+ax6/Pz8yMzMrLXdixYtYsGCBdbP0dHRTJ8+vc7vGS9FaKjsreQoEmvHcWqsw8IgoTPmiY9Q8sNiziz7mursDLRNq9E2rUYfEoZ7/8F49ByIMTa+0f9wk+9rx5FYO44jY233RCgvL49PP/2UKVOm4OLiYu/q69WoUaMYPny49XPNP5C5ubnWV3L2opQiNDSU7OxsGXxXzyTWjtPgYn31tdBjIPrkA5g3rUHbtoHqnCzOzP+EM/M/gYAgVOerUVde81tPUcPcdqA2DS7WTZjE2nHsFWuDweC8LTaOHTtGYWEhTz/9tPWY2Wzm4MGDrFy5kmeffRaTyURJSYlNr1BhYaG198bPz4/k5GSbemsGOP+xzJ8HPRcWFuLu7o6Liws+Pj7odDprD1KN2nqbahiNRozG2gdy1dsMGE2Tv1gOIrF2nAYX69gO6GI7oI2diLZrC9r2TbBvO5zOs0zJX7Pst6n4fVFX94NWMY2mp6jBxboJk1g7jiNjbfdEKCEhgX/+8582x/79738THh7OjTfeSFBQEHq9nr1793L11VcDkJmZSV5eHnFxcQDExcWxcOFCCgsLra+/9uzZg7u7O5GRkQC0bduWnTt32txnz5491joMBgNt2rRh3759dO/eHbAkZPv27WPw4MH2fmwhRCOgXFxR3ftC975olRVwcDfazs1ou36Fwny0VUvQVi2B0EjLVPy27SEqTvY6E6IJs3si5O7uTqtWrWyOubq64u3tbT0+cOBA5s6di5eXFx4eHsyZM4e4uDhrEpOYmEhkZCTvv/8+48aNo6CggK+++opBgwZZe2yuv/56vv/+ez7//HMGDBjAvn372Lx5M5MnT7bed/jw4fzrX/+iTZs2xMbGsnz5cioqKs5aa0gI0fwoF1dI7I5K7I5mqoL9O9G2/Iy2awtkp6Mt+8qyzYBSENYSFROP6toLOnRuNL1FQogLc8ru83feeSdKKd58801MJpN1QcUaOp2OyZMn8/HHHzNlyhRcXV3p168ft9xyi7VMSEgIkydP5rPPPmP58uUEBgZy//3307lzZ2uZnj17UlRUxPz58ykoKCAqKopnnnnmnK/GhBDNkzIYf0+KykrRdmyGA7vQjh2ybP6amYqWmYq2/geIaotu+C3QqZskREI0AbLFRh3IytKNm8TacZpirLWifDiWhHZgJ9rGVVBZaTkRGY1u2F+h89Uog+P/T9kUY91QSawdxxkrSzulR0gIIRoL5eMPnXugOvdAGz4W7cclaD8th/TjmGe9AV4+qO59UdcMgNax0kskRCMjiZAQQtSR8vFDjb4TbdAotNVL0dZ9D0UFv888C2uJ6nI1qm0HiGmPcvdwdpOFEBcgiZAQQlwk5eWDunEc2vCxlrFEm9dYBllnpaFlpf02yFoHka1Rse0t0/FbRkN4K5Sxca2vJkRTJ4mQEEJcIqXXQ0JXVEJXtNIStJ2/wOE9aMkHITcb0o6jpR0HsCRHOp1lan6HLqhBI1F+gU5tvxBCEiEhhLAL5eGJ6nUt9LoWAK3gFCQfRDt6GC39OKQdh5Izv89A+3kFqt9g1ODRKF9/J7deiOZLEiEhhKgHyi8QruqNuqo38Nvq9PmnICUJ849LLEnSqm/R1q1E9R0CUbEoT2/w9AZPL/APlNdoQjiAJEJCCOEASikICIKAIHRdroEDuzAv+R8cT7KsZs1vr89quLpZVrfu/ReIafybwwrRUEkiJIQQDqaUgo5d0HXoDPt2WAZbFxVASTGUnoHiIqgoR9u4yrJ2UWgkqvd1qISrLL/X6Zz9CEI0GZIICSGEkyilrIOt/0jTNDhywJIIbdtg2fJjwadoCz4FD0+IjkMX257y7r3R/ILBxdU5DyBEEyCJkBBCNDBKKYjriIrriDZ2Itq2DWhbfobjSVBaAvt3Yt6/k9wlX4DeANFxqPgEVLsEaNPOso+aEKJOJBESQogGTLl7oPpcD32uR6uuhvQUtKMH4eghdMcOU513EpIPoCUfQFs2z5IYtY5BxXZAtW0PMR1Q3j7OfgwhGixJhIQQopFQer0lyWkdg7r2BkJDQ8nasxPzoT1weC/a4b1QcBqOHUY7dhjth0WWC4NaoKLaQnRby69BLcDd0zIgW8YbiWZOEiEhhGiklFKokDB0waGWHiNNg7yTlgUdkw+gHTkAWWmWY3knYdsG25lpSoGbB/j6ofoNsXwZjc56HCGcQhIhIYRoIpRSEByKCg6FawYAoJUWQ0oyWsoRtJQjcCIZCgug2gSaBmUlUFaCNu9jtFXfokbcirq6H0qnd+7DCOEgkggJIUQTpjy8oENnVIfO1mOapkFVJZSVWpKgw/vQln4Fp3LQPpmJ9v1C1JAxqISrUJ5ezmu8EA4giZAQQjQzSinLlHsXV/D1R4VGol09AG3NMrSVCyzbgMx+C03pLIs5droK1fFKCIuU1a5FkyOJkBBCCJSrK2rIaLS+gyxbf+zYBJmpv89IWzjXUtDbFwKCISAIFRIGLdugWkZDiwjLYG4hGhlJhIQQQlgpTy/UjbfCjbei5Z1E27sdbe82SNoPFWVwptDydSLZOvBaAzC6QERrVGgEBIdCSBgqOAxCwmX6vmjQJBESQghRKxXUAjVgKAwYahlXVFoMp3LhdC7aqVzLitdpxyA9BSrKoWZA9m+sM9S8fSG8FSqsJYS3RAW1AL9A8A8ET2/ZR004lSRCQgghLkgpBZ7elq9Wbfhj6qKZzZCbDenH0XKyIDf7t1+z4HSepQepZp0j/rS5rNHFss7RldegevRHhUU68rGEkERICCHE5VE6HbQIhxbh/LlvR6sot/QcZaRCVhpaVhqczrUs/Him0DJ7LSsN7bs0tO/mQ6sYVI++qKg4cHMDN3dwdQc3D5SrbB0i7E8SISGEEPVGubpB61hU69izzmlVVVBwyrIK9paf4cBOSD2KlnrUtteohqs7+PqDnz/KNwBCI1HtrrDsryaz2cQlkkRICCGEUyij8fcFIHv0QztThLZ9A9q2jZYeo/IyywDtinLL4o8VZZBTBjmZvw/UXgoYDJZkqG1HVGQUhEZaeqckORJ1IImQEEKIBkF5+6D6D4X+Q22Oa5pmSYoK86EwH63wNBScsqyYnbQfCk9D0n60pP2/9yQpZdlTrWU0Kj7RsqBkSJgMzBZnkURICCFEg6aUAncPy1dohO1AbU2Dk5loSfvg6CG07HTISrdsHZKbbRm4vWOzJUEKDEHFdwL/IMv4Ixc3y8azv81qIyBIEqVmSBIhIYQQjZZSypIchUZA30HAb8nRmQLISkdLPoh2YBccPWTZQmTjqrPqsPYiublb1kIKb2XpTfILRPlbpvmb/f0c9ETC0SQREkII0aQopcDHH3z8Ue0SYNjNltlrSfvRkg9Y1kOqKLccqyiH/FNwMsPy+u3oIbSjh6x11SRJGTqdJUmKibdsOxLT3rIOkt4gvUiNnCRCQgghmjzl6gYJXVEJXWs9r5mq4GQWWuYJyDgBp/PQCk5ZkqSCU5YkKe04WtpxWLvCdlabTgd6A7i6QVQsqiZRio5Dubk75PnEpZNESAghRLOnDEaIaIWKaAXd+tieU4oQFwPZm3+2vGo7eghSj4LJZClgNoO50rIm0r4daPt2WBIlpYOgEPDxA29flI+f5fc+/ihf/9+WAggA3wCUQX4cO4tEXgghhLgAfWAwuq690K7sCfzWg1RZAdXVUG2y/HqmEO3YYcvrteSDloUjfxuwDbYrap+1unbrWFRMO0tPUkw7lI+/w56tuZNESAghhLhIymAEg9H2YGAIKqotDBwOgJZ/Ck6dhKJCtKICKCqAMwVoBfmWKf+F+VCUb+lJSj6AlnwAjUWWukIjUHEJEJ+AaneFJEb1SBIhIYQQoh7UzDgDztp6pIZmNlsWiDx6GI4etPQoZaZCdgZadgasW2npPfLxs1xgNlu+0CAo1JJ4RcVafg2LtNxJM4NZs/zq4mrZAkWckyRCQgghhJMonc6yVUhoJPS6FgCtpBiO7Eer2ag2PcXSm/Rnv21Hwjpq35IEQK+3zKDzCwC/AJR/kGWT26AWENzC8ns3j3p6usZBEiEhhBCiAVGeXtC5B6pzDwC0kjNwKtcyO03pLL9qZstmtcePoJ1IhhPJUFZ6dmXV1ZCfZ/ni94TJJnHy9rWsuh0SDiFhlm1PDEZLN5bSWX719rNsiGv80+vAJkASISGEEKIBU57e4Ol99onwVqiuvYDfXrGVFv+eKOl0gLIc+20ZAK3wNJzOg7yTaHknIS8bis/AmULLQO9a1k+yYTBCVFtUbHtUTDvLCt0eXpYvd49G+wpOEiEhhBCikVM6HXj5nH3C1dUyTim69nFKWlkp5GahncyCnEzIyUI7lQPmastGt5pmGZOUmw3FRX8Y1P3nBijL/a2v3UItv/f2BXdP8Pjty9O7wa2tJImQEEII0Uwpdw/LK69WMectZ93T7ehBSD6IlpIMxYWWHqfKSkvCVNOzdDzp9+tqq8zd05Kc+QeiAoIhOAzdkNH2fbCLIImQEEIIIc7LZk+3XtfZnNOqqiwJUeHp31+75f72a8kZywa4pSWWMiaT5XNZCWSmWhKlFhEgiZAQQgghGiNlNFpWyfb1t/QunaesVl5q2bYkPw/tdJ7l966uDmtrbSQREkIIIYRDKDcPCPOAsJbnTZgcqXEO8RZCCCGEsANJhIQQQgjRbNn91diiRYv49ddfycjIwMXFhbi4OG677TbCw8OtZSorK5k7dy6bNm2iqqqKxMRE7rnnHvz8/Kxl8vLy+Oijj9i/fz9ubm7069ePW2+9Fb1eby2zf/9+5s6dS1paGoGBgYwePZr+/fvbtGflypUsXbqUgoICWrduzYQJE4iNjbX3YwshhBCiEbJ7j9CBAwcYNGgQr732GlOmTKG6uppXX32V8vJya5nPPvuM7du389hjj/HSSy+Rn5/Pm2++aT1vNpt5/fXXMZlMvPrqqzzwwAOsXbuWefPmWcvk5OQwbdo0OnbsyBtvvMGwYcP48MMP2bVrl7XMpk2bmDt3LmPGjGH69Om0bt2a1157jcLCQns/thBCCCEaIbsnQs8++yz9+/enZcuWREVF8cADD5CXl8exY8cAKC0tZc2aNdx5551cccUVtGnThkmTJnH48GGSkixrD+zevZv09HT+8Y9/EBUVRZcuXbjlllv4/vvvMZlMAPzwww+EhIRwxx13EBkZyeDBg7n66qv57rvvrG1ZtmwZ1157LQMGDCAyMpKJEyfi4uLCTz/9ZO/HFkIIIUQjVO+zxkpLLXufeHl5AXDs2DGqq6tJSEiwlomIiCAoKIikpCTi4uJISkqiVatWNq/KOnfuzMcff0xaWhrR0dEcOXLEpg6AxMREPv30UwBMJhPHjh1j5MiR1vM6nY6EhARrwvVnVVVVVFVVWT8rpXB3d7f+3p5q6rN3veJsEmvHkVg7jsTacSTWjuOMWNdrImQ2m/n0009p164drVq1AqCgoACDwYCnp6dNWV9fXwoKCqxl/pgE1ZyvOVfza82xP5YpKyujsrKS4uJizGbzWfX4+fmRmZlZa3sXLVrEggULrJ+jo6OZPn06wcHBF/PYFyU0NLTe6ha2JNaOI7F2HIm140isHceRsa7XRGj27NmkpaXx8ssv1+dt7GbUqFEMHz7c+rkmI83NzbW+krMXpRShoaFkZ2dbli4X9UZi7TgSa8eRWDuOxNpx7BVrg8FQ506MekuEZs+ezY4dO3jppZcIDAy0Hvfz88NkMlFSUmLTK1RYWGjtvfHz8yM5OdmmvpoBzn8s8+dBz4WFhbi7u+Pi4oKPjw86nc7ag1Sjtt6mGkajEaPRWOu5+vrm1zRN/mI5iMTacSTWjiOxdhyJteM4MtZ2HyytaRqzZ8/m119/5fnnnyckJMTmfJs2bdDr9ezdu9d6LDMzk7y8POLi4gCIi4sjNTXVJtHZs2cP7u7uREZGAtC2bVubOmrK1NRhMBho06YN+/bts543m83s27fPWkYIIYQQzZvdE6HZs2ezfv16Hn74Ydzd3SkoKKCgoIDKykoAPDw8GDhwIHPnzmXfvn0cO3aMDz74gLi4OGuCkpiYSGRkJO+//z4pKSns2rWLr776ikGDBll7bK6//npycnL4/PPPycjI4Pvvv2fz5s0MGzbM2pbhw4ezevVq1q5dS3p6Oh9//DEVFRVnrTUkhBBCiOZJaXbue7r55ptrPT5p0iRrAlKzoOLGjRsxmUy1LqiYm5vLxx9/zP79+3F1daVfv36MGzfurAUVP/vsM9LT08+7oOK3335LQUEBUVFRjB8/nrZt217UM+Xm5trMJrMHpRRhYWFkZWVJV2s9k1g7jsTacSTWjiOxdhx7xdpoNNZ5jJDdE6GmSBKhxk1i7TgSa8eRWDuOxNpxnJEIye7zdWAw1F+Y6rNuYUti7TgSa8eRWDuOxNpxLjfWF3O99AgJIYQQotmS3eedpKysjKeffpqysjJnN6XJk1g7jsTacSTWjiOxdhxnxFoSISfRNI3jx4/L+2YHkFg7jsTacSTWjiOxdhxnxFoSISGEEEI0W5IICSGEEKLZkkTISYxGI2PGjDnnlh7CfiTWjiOxdhyJteNIrB3HGbGWWWNCCCGEaLakR0gIIYQQzZYkQkIIIYRotiQREkIIIUSzJYmQEEIIIZotSYSEEEII0WzJDnJOsHLlSpYuXUpBQQGtW7dmwoQJxMbGOrtZjdqiRYv49ddfycjIwMXFhbi4OG677TbCw8OtZSorK5k7dy6bNm2iqqqKxMRE7rnnHvz8/JzX8CZg8eLFfPHFFwwdOpS77roLkFjb0+nTp/n888/ZtWsXFRUVhIaGMmnSJGJiYgDLSrzz589n9erVlJSUEB8fzz333ENYWJiTW964mM1m5s+fz/r16ykoKCAgIIB+/foxevRolFKAxPpyHDhwgG+//Zbjx4+Tn5/PE088Qffu3a3n6xLb4v9v725DmuzCOID/N4fmXLqZDaKla9rsyyKJCLRoRRC0oAInYhCY6YcCoT7Ym1ZGJr1KQYHg5hKJ+rJUIoXZt5korYhmoqw1WoiY0W7ZfIntPs+Hp24Y9vBoWxtu1w8E73PO8OIvzotz3x79fpjNZjgcDohEIuzYsQOVlZVYtWpVRLXRjlCMvXr1Ch0dHSgtLcWNGzeQl5eHpqYmcBwX79JWtA8fPmD//v1oampCfX09QqEQrl27hvn5eWHNo0eP4HA4cObMGTQ2NuL79++4c+dOHKte+VwuF2w2G/Ly8sLGKevo8Pv9aGhogEQiwYULF9DS0oJjx44hIyNDWNPd3Y3e3l5UV1fj+vXrSEtLQ1NTE378+BHHyleerq4u2Gw2VFVVoaWlBUePHkVPTw96e3uFNZT1n1tYWIBarUZVVdVv55eS7f379+H1elFfX49z585hdHQUra2tkRfHSEydP3+etbW1CdehUIjV1NSwZ8+exa+oBMRxHDMajWxkZIQxxlggEGDl5eVscHBQWPPlyxdmNBrZ2NhYvMpc0ebm5lhtbS179+4du3z5Mmtvb2eMUdbR1NnZyRoaGv5znud5Vl1dzbq7u4WxQCDAKioqmN1uj0WJCaO5uZk9fPgwbOzWrVvs3r17jDHKOpqMRiMbGhoSrpeSrdfrZUajkblcLmHN27dvWVlZGfv27VtE9dCOUAwFg0G43W7odDphTCwWQ6fTYXx8PI6VJZ7Z2VkAgEwmAwC43W6EQqGw7NevX4+cnBzK/g+1tbWhqKgIW7ZsCRunrKPn9evX0Gg0uHv3Lk6cOIG6ujr09/cL81NTU/D5fGHfA6lUioKCAsp6mbRaLZxOJyYmJgAAHo8HY2NjKCoqAkBZ/01LyXZ8fBwZGRnCLWEA0Ol0EIlEcLlcEX19ekYohmZmZsDz/KLnJORyufDDRyLH8zwsFgsKCwuRm5sLAPD5fJBIJGG3FAAgKysLPp8vDlWubAMDA/j06ROam5sXzVHW0TM1NQWbzQaDwYAjR47g48ePaG9vh0QigV6vF/LMysoKex1lvXyHDx/G3NwcTp8+DbFYDJ7nUV5ejl27dgEAZf0XLSVbn8+HzMzMsPmUlBTIZLKI86dGiCQck8kEr9eLq1evxruUhDQ9PQ2LxYL6+nqkpqbGu5yExvM88vPzUVFRAQDYuHEjPn/+DJvNBr1eH9/iEszg4CDsdjtqa2uxYcMGeDweWCwWKBQKyjrBUSMUQ5mZmRCLxYu6V5/PR39NEyUmkwlv3rxBY2Mj1qxZI4zL5XIEg0EEAoGwnQqO4yj7ZXK73eA4DmfPnhXGeJ7H6Ogo+vr6cPHiRco6ShQKBVQqVdiYSqXC0NAQAAh5chwHhUIhrOE4Dmq1OlZlJoTOzk4cOnQIJSUlAIDc3Fx8/foVXV1d0Ov1lPVftJRs5XI5ZmZmwl4XCoXg9/sjfl+hZ4RiSCKRQKPRwOl0CmM8z8PpdEKr1caxspWPMQaTyYTh4WFcunQJSqUybF6j0SAlJQXv378XxiYmJjA9PU3ZL5NOp8Pt27dx8+ZN4SM/Px87d+4UPqeso6OwsHDRbfOJiQmsXbsWAKBUKiGXy8Oynp2dhcvloqyXaWFhAWJx+K9EsVgM9vP/klPWf89SstVqtQgEAnC73cIap9MJxljEx8/QjlCMHTx4EA8ePIBGo0FBQQFevHiBhYUF2nqNkMlkgt1uR11dHdLT04VdN6lUitTUVEilUuzduxcdHR2QyWSQSqUwm83QarX0JrZM6enpwrNXv6SlpWH16tXCOGUdHQaDAQ0NDbBarSguLobL5cLLly9RU1MDABCJRDhw4ACsVivWrVsHpVKJJ0+eQKFQYPv27XGufmXZtm0brFYrcnJyoFKp4PF48Pz5c+zZswcAZR2p+fl5TE5OCtdTU1PweDyQyWTIycn532xVKhW2bt2K1tZWVFdXIxgMwmw2o7i4GNnZ2RHVJmK/2l0SM319fejp6YHP54NarUZlZSU2bdoU77JWtLKyst+Onzx5Umgyfx3yNzAwgGAwSIf8RdGVK1egVqsXHahIWUfO4XDg8ePHmJychFKphMFgwL59+4R59vMguv7+fszOzmLz5s2oqqoKO0yU/L+5uTk8ffoUw8PD4DgO2dnZKCkpQWlpKSSSf/cMKOs/NzIygsbGxkXju3fvxqlTp5aUrd/vh8lkCjtQ8fjx4xEfqEiNECGEEEKSFj0jRAghhJCkRY0QIYQQQpIWNUKEEEIISVrUCBFCCCEkaVEjRAghhJCkRY0QIYQQQpIWNUKEEEIISVrUCBFCCCEkaVEjRAghhJCkRY0QIYQQQpIWNUKEEEIISVr/AK+c2XHhFpf+AAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"markdown","source":"## Value Function to Create Policy ","metadata":{}},{"cell_type":"markdown","source":"So we have a decent value function now! We show it a board state, and it tells us how good that board is for black.\n\nBut if our AI is going to play chess, we need a way to turn that board state into a decision, or in other words, we need to use our value function to create a policy.\n\nOne simple way we can do this is to look at all the legal moves we can make, test our making each of them, and pick whatever move gives us the highest value to the resultant board state. Let's code that up!","metadata":{}},{"cell_type":"code","source":"# same as the youtube implementation\ndef play_nn_video(fen, show_move_evaluations=False, player='b'):\n    # We can create a python-chess board instance from the FEN string like this:\n    board = chess.Board(fen=fen)\n\n    # And then evaluate all legal moves\n    moves = []\n    input_vectors = []\n    for move in board.legal_moves:\n        # For each move, we'll make a copy of the board and try that move out\n        candidate_board = board.copy()\n        candidate_board.push(move)\n        moves.append(move)\n        input_vector = encode_board(str(candidate_board))\n        input_vectors.append(input_vector)\n    \n    input_vectors = np.stack(input_vectors)\n    # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n    scores = model.predict(input_vectors, verbose=0)\n    \n    if player == 'b':\n        idx_best = np.argmax(scores)\n    else:\n        idx_best = np.argmax(-scores)\n\n    if show_move_evaluations:\n        print(zip(moves, scores))\n    \n    # By default sorting our moves will put the lowest scores at the top.\n    # This would give us the right answer if we were playing as white,\n    # but if we're playing as black we want to reverse things (then grab the first move):\n    best_move = moves[idx_best]\n\n    # Now we turn our move into a string, return it and call it a day!\n    return str(best_move)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:39:13.257811Z","iopub.execute_input":"2024-07-29T07:39:13.258909Z","iopub.status.idle":"2024-07-29T07:39:13.266697Z","shell.execute_reply.started":"2024-07-29T07:39:13.258876Z","shell.execute_reply":"2024-07-29T07:39:13.265796Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"def play_nn(fen, show_move_evaluations=False, player='b'):\n    # We can create a python-chess board instance from the FEN string like this:\n    board = chess.Board(fen=fen)\n\n    # And then evaluate all legal moves\n    moves = []\n    for move in board.legal_moves:\n        # For each move, we'll make a copy of the board and try that move out\n        candidate_board = board.copy()\n        candidate_board.push(move)\n        input_vector = encode_board(str(candidate_board))\n        \n        # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n        score = model.predict(np.expand_dims(input_vector, axis=0), verbose=0)[0][0]\n        moves.append((score, move))\n        if show_move_evaluations:\n            print(f'{move}: {score}')\n    \n    # By default sorting our moves will put the lowest scores at the top.\n    # This would give us the right answer if we were playing as white,\n    # but if we're playing as black we want to reverse things (then grab the first move):\n    best_move = sorted(moves, reverse=player=='b')[0][1]\n\n    # Now we turn our move into a string, return it and call it a day!\n    return str(best_move)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:39:15.632966Z","iopub.execute_input":"2024-07-29T07:39:15.633839Z","iopub.status.idle":"2024-07-29T07:39:15.641029Z","shell.execute_reply.started":"2024-07-29T07:39:15.633807Z","shell.execute_reply":"2024-07-29T07:39:15.640022Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# Now that we have a policy, we can play against it!\n\nplay_game(play_nn)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T07:06:48.930286Z","iopub.status.idle":"2024-07-29T07:06:48.930744Z","shell.execute_reply.started":"2024-07-29T07:06:48.930508Z","shell.execute_reply":"2024-07-29T07:06:48.930528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part III : Make Prediction & Submit","metadata":{}},{"cell_type":"markdown","source":"### Import Test Set ","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/train-an-ai-to-play-chess/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:39:25.881190Z","iopub.execute_input":"2024-07-29T09:39:25.881819Z","iopub.status.idle":"2024-07-29T09:39:25.912211Z","shell.execute_reply.started":"2024-07-29T09:39:25.881789Z","shell.execute_reply":"2024-07-29T09:39:25.911329Z"},"trusted":true},"execution_count":162,"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"      id                                              board\n0   7937  r1bqk2r/pp2bpp1/2n1pn1p/2pp4/3P1B2/2P1PN2/PP1N...\n1  20035  2r2k1r/pp2pp1p/1q3npb/1B1N4/8/P4Q1P/1P3PP1/R2R...\n2  71263               3b4/8/5k2/5p2/8/4K3/8/5B2 b - - 2 80\n3  61997      5k2/R7/3r3p/2PP2pP/5pb1/P1K5/6B1/8 w - - 1 61\n4  26510  r3r1k1/pb3p1p/1p1q2p1/3P1p2/3Q1P2/5N2/PP4PP/3R...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>board</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7937</td>\n      <td>r1bqk2r/pp2bpp1/2n1pn1p/2pp4/3P1B2/2P1PN2/PP1N...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20035</td>\n      <td>2r2k1r/pp2pp1p/1q3npb/1B1N4/8/P4Q1P/1P3PP1/R2R...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71263</td>\n      <td>3b4/8/5k2/5p2/8/4K3/8/5B2 b - - 2 80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61997</td>\n      <td>5k2/R7/3r3p/2PP2pP/5pb1/P1K5/6B1/8 w - - 1 61</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26510</td>\n      <td>r3r1k1/pb3p1p/1p1q2p1/3P1p2/3Q1P2/5N2/PP4PP/3R...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Predict Moves\n\nMaking all of our predictions happens in this one line! We're basically saying \"run play_nn on all the boards in the test_df, and then keep the results as best_move\". Because this involves running our model a _ton_ this step will take a while.","metadata":{}},{"cell_type":"code","source":"test_df['best_move'] = test_df['board'].apply(play_nn_video)\ntest_df['best_move']","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:39:28.558735Z","iopub.execute_input":"2024-07-29T09:39:28.559346Z","iopub.status.idle":"2024-07-29T09:39:43.595619Z","shell.execute_reply.started":"2024-07-29T09:39:28.559316Z","shell.execute_reply":"2024-07-29T09:39:43.594498Z"},"trusted":true},"execution_count":163,"outputs":[{"execution_count":163,"output_type":"execute_result","data":{"text/plain":"0      c5d4\n1      d5c7\n2      d8e7\n3      a7f7\n4      e8e1\n       ... \n195    a5d5\n196    h7h6\n197    a8f8\n198    h5d5\n199    h8g8\nName: best_move, Length: 200, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## Submission ","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/train-an-ai-to-play-chess/sample_submission.csv', index_col='id')\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T07:06:48.935427Z","iopub.status.idle":"2024-07-29T07:06:48.935759Z","shell.execute_reply.started":"2024-07-29T07:06:48.935604Z","shell.execute_reply":"2024-07-29T07:06:48.935618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df[['id', 'best_move']]\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:39:43.598085Z","iopub.execute_input":"2024-07-29T09:39:43.598455Z","iopub.status.idle":"2024-07-29T09:39:43.610727Z","shell.execute_reply.started":"2024-07-29T09:39:43.598403Z","shell.execute_reply":"2024-07-29T09:39:43.609645Z"},"trusted":true},"execution_count":164,"outputs":[{"execution_count":164,"output_type":"execute_result","data":{"text/plain":"      id best_move\n0   7937      c5d4\n1  20035      d5c7\n2  71263      d8e7\n3  61997      a7f7\n4  26510      e8e1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>best_move</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7937</td>\n      <td>c5d4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20035</td>\n      <td>d5c7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71263</td>\n      <td>d8e7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61997</td>\n      <td>a7f7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26510</td>\n      <td>e8e1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:39:43.612269Z","iopub.execute_input":"2024-07-29T09:39:43.613173Z","iopub.status.idle":"2024-07-29T09:39:43.619357Z","shell.execute_reply.started":"2024-07-29T09:39:43.613139Z","shell.execute_reply":"2024-07-29T09:39:43.618465Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"markdown","source":"# Part IV : Ensemble Models","metadata":{}},{"cell_type":"markdown","source":"So far we've always used a single neural network to make all of our moves. This has worked okay, but it doesn't take advantage of the fact that there are a lot of different skills used at different points in a chess game.\n\nFor example, sometimes we'll break up a chess game into 3 parts:\n\n* The opening\n* The midgame\n* The endgame\n\nSome chess players might have lots of powerful openings memorized, but struggle to deliver checkmate in the endgame. Personally, I have a decent edgame (relative to my whole game being terrible) but my midgame is rough.\n\nThis fact that chess can be broken into different kinds of problems means that building an ensemble model could work well here. The general idea behind ensemble models is to create multpile models that are experts in different parts of your dataset, then use them together to create your final predictions.\n\nIn order to tell **what phase of the game we're in**, we can count the total \"points of material\" on the board. If there are lots of pieces left of the board, we're probably in the opening, and if we only have a few left, we're probably near the endgame.","metadata":{}},{"cell_type":"markdown","source":"## Material Counter Version 1 ","metadata":{}},{"cell_type":"code","source":"def count_material(fen):\n    total_material = 0\n    material_dict = {\n        'p': 1,\n        'b': 3,\n        'n': 3,\n        'r': 5,\n        'q': 9\n    }\n    \n    for char in fen.lower():\n        if char in material_dict:\n            total_material += material_dict[char]\n            \n    return total_material","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:10:38.183641Z","iopub.execute_input":"2024-07-29T12:10:38.184231Z","iopub.status.idle":"2024-07-29T12:10:38.190132Z","shell.execute_reply.started":"2024-07-29T12:10:38.184201Z","shell.execute_reply":"2024-07-29T12:10:38.189211Z"},"trusted":true},"execution_count":276,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/train-an-ai-to-play-chess/train.csv', index_col='id')\ntrain_df['total_material'] = train_df['board'].apply(count_material)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:10:40.247971Z","iopub.execute_input":"2024-07-29T12:10:40.248397Z","iopub.status.idle":"2024-07-29T12:10:40.701816Z","shell.execute_reply.started":"2024-07-29T12:10:40.248368Z","shell.execute_reply":"2024-07-29T12:10:40.700665Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"markdown","source":"### Plot Histogram ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.hist(train_df['total_material'])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:10:42.608303Z","iopub.execute_input":"2024-07-29T12:10:42.608642Z","iopub.status.idle":"2024-07-29T12:10:42.873665Z","shell.execute_reply.started":"2024-07-29T12:10:42.608616Z","shell.execute_reply":"2024-07-29T12:10:42.872803Z"},"trusted":true},"execution_count":278,"outputs":[{"execution_count":278,"output_type":"execute_result","data":{"text/plain":"(array([ 5973., 11022.,  8581.,  6077.,  4980.,  4993.,  4471.,  3682.,\n         2834.,  6172.]),\n array([  1.,  11.,  21.,  31.,  41.,  51.,  61.,  71.,  81.,  91., 101.]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Material Counter Encoder ","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/code/paritoshdahiya/ghw-chess-ai-custom-encoding/notebook","metadata":{}},{"cell_type":"markdown","source":"If you want modified encoding according to this notebook then make this true. This is not one-hot encoding. ","metadata":{}},{"cell_type":"code","source":"adv_enc = True","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:10:47.455795Z","iopub.execute_input":"2024-07-29T12:10:47.456145Z","iopub.status.idle":"2024-07-29T12:10:47.460761Z","shell.execute_reply.started":"2024-07-29T12:10:47.456117Z","shell.execute_reply":"2024-07-29T12:10:47.459622Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"code","source":"if adv_enc:\n    def encode_board(board):\n        # first lets turn the board into a string\n        board_str = str(board)\n        # then lets remove all the spaces\n        material_dict = {\n            'p': -1,\n            'b': -3.5,\n            'n': -3,\n            'r': -5,\n            'q': -9,\n            'k': -4,\n            'K': 4,\n            '.': 0,\n            'P': 1,\n            'B': 3.5,\n            'N': 3,\n            'R': 5,\n            'Q': 9,\n        }\n        board_str = board_str.replace(' ', '')\n        board_list = []\n        for row in board_str.split('\\n'):\n            row_list = []\n            for piece in row:\n                # print(piece)\n                row_list.append(material_dict.get(piece))\n            board_list.append(row_list)\n        return np.array(board_list)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:10:48.766714Z","iopub.execute_input":"2024-07-29T12:10:48.767123Z","iopub.status.idle":"2024-07-29T12:10:48.775044Z","shell.execute_reply.started":"2024-07-29T12:10:48.767093Z","shell.execute_reply":"2024-07-29T12:10:48.774074Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"if adv_enc:\n    def encode_fen_string(fen_str):\n        board = chess.Board(fen=fen_str)\n        return encode_board(board)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:10:51.695691Z","iopub.execute_input":"2024-07-29T12:10:51.696045Z","iopub.status.idle":"2024-07-29T12:10:51.701087Z","shell.execute_reply.started":"2024-07-29T12:10:51.696017Z","shell.execute_reply":"2024-07-29T12:10:51.700075Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"if adv_enc:\n    X_train = np.stack(train_df['board'].apply(encode_fen_string))\n    y_train = train_df['black_score']\n    X_val = np.stack(val_df['board'].apply(encode_fen_string))\n    y_val = val_df['black_score']","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:11:01.895235Z","iopub.execute_input":"2024-07-29T12:11:01.895956Z","iopub.status.idle":"2024-07-29T12:11:18.115075Z","shell.execute_reply.started":"2024-07-29T12:11:01.895925Z","shell.execute_reply":"2024-07-29T12:11:18.114275Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"markdown","source":"This histogram of all our boards total material is interesting!\nWe have a lot of boards with relatively few points, and only a few with more than 70.\nWe see an interesting spike around 100, which is probably due to promotion, when a pawn reaches the end of board and can turn into a queen. Promotion usually happens near the end of a game, so our hueristic isn't perfect (sometimes having a lot of points of material left means you're in the endgame).\nBut it should still work well enough!\nLet's say:\n* **Opening**: > 60 points of material\n* **Midgame**: between 30 and 60 points of material\n* **Endgame**: less than 30 points of material\n\nThe exact cutoff doesn't matter; the important part is that we're breaking our hard problem (all of chess) in to easier subproblems we can easily identify.","metadata":{}},{"cell_type":"markdown","source":"## Split Training Data ","metadata":{}},{"cell_type":"code","source":"endgame_df = train_df[train_df['total_material'] < 30]\nmidgame_df = train_df[(30 <= train_df['total_material']) & (train_df['total_material'] <= 65)]\nopening_df = train_df[65 < train_df['total_material']]","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:12:22.378746Z","iopub.execute_input":"2024-07-29T12:12:22.379191Z","iopub.status.idle":"2024-07-29T12:12:22.395036Z","shell.execute_reply.started":"2024-07-29T12:12:22.379142Z","shell.execute_reply":"2024-07-29T12:12:22.394041Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"markdown","source":"# Train & Evaluate Model","metadata":{}},{"cell_type":"code","source":"def gen_train_eval_model(data_to_train_on, idx):\n    val_df = data_to_train_on[-5000:]\n    train_df = data_to_train_on[:-5000]\n    \n    X_train = np.stack(train_df['board'].apply(encode_fen_string))\n    y_train = train_df['black_score']\n\n    X_val = np.stack(val_df['board'].apply(encode_fen_string))\n    y_val = val_df['black_score']\n    \n    model = Sequential([\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.2),\n        Dense(1),\n    ])\n    \n    model.compile(\n        optimizer='adam',\n        loss='mean_squared_error')\n    \n    checkpoint_path = f\"training_1/chess_{idx}.weights.h5\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n    \n    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n\n    model_checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                     save_weights_only=True,\n                                                     save_best_only=True,\n                                                     verbose=1) \n\n    history = model.fit(\n        X_train,\n        y_train,\n        epochs=300,\n        validation_data=(X_val, y_val),\n        callbacks=[early_stopping, model_checkpoint])\n\n    import matplotlib.pyplot as plt\n\n    # Lets plot the history of our training session to see how things progressed over time\n    plt.style.use('ggplot')\n    plt.plot(history.history['loss'], label='train loss')\n    plt.plot(history.history['val_loss'], label='val loss')\n    plt.legend()\n    plt.title('Loss During Training')\n    plt.show()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:12:26.192945Z","iopub.execute_input":"2024-07-29T12:12:26.193674Z","iopub.status.idle":"2024-07-29T12:12:26.203587Z","shell.execute_reply.started":"2024-07-29T12:12:26.193644Z","shell.execute_reply":"2024-07-29T12:12:26.202624Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"endgame_model = gen_train_eval_model(endgame_df, 1)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T12:12:29.403804Z","iopub.execute_input":"2024-07-29T12:12:29.404597Z","iopub.status.idle":"2024-07-29T12:18:04.061378Z","shell.execute_reply.started":"2024-07-29T12:12:29.404564Z","shell.execute_reply":"2024-07-29T12:18:04.060349Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":285,"outputs":[{"name":"stdout","text":"Epoch 1/300\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185413.6094\nEpoch 1: val_loss improved from inf to 178493.31250, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 185401.8125 - val_loss: 178493.3125\nEpoch 2/300\n\u001b[1m613/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 162306.9531\nEpoch 2: val_loss improved from 178493.31250 to 165183.18750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162293.7969 - val_loss: 165183.1875\nEpoch 3/300\n\u001b[1m627/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 155298.4688\nEpoch 3: val_loss improved from 165183.18750 to 158453.56250, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155272.9375 - val_loss: 158453.5625\nEpoch 4/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137089.7344\nEpoch 4: val_loss improved from 158453.56250 to 152540.68750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137376.0156 - val_loss: 152540.6875\nEpoch 5/300\n\u001b[1m596/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 151436.6875\nEpoch 5: val_loss improved from 152540.68750 to 146780.04688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150673.9844 - val_loss: 146780.0469\nEpoch 6/300\n\u001b[1m625/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129199.5312\nEpoch 6: val_loss improved from 146780.04688 to 141259.12500, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129219.7188 - val_loss: 141259.1250\nEpoch 7/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 132462.0781\nEpoch 7: val_loss improved from 141259.12500 to 136553.04688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132429.4688 - val_loss: 136553.0469\nEpoch 8/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 121141.3984\nEpoch 8: val_loss improved from 136553.04688 to 132056.71875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121104.8984 - val_loss: 132056.7188\nEpoch 9/300\n\u001b[1m596/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119082.4453\nEpoch 9: val_loss improved from 132056.71875 to 128489.72656, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118944.9062 - val_loss: 128489.7266\nEpoch 10/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104945.7891\nEpoch 10: val_loss improved from 128489.72656 to 125431.73438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105301.9766 - val_loss: 125431.7344\nEpoch 11/300\n\u001b[1m595/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 124564.1250\nEpoch 11: val_loss improved from 125431.73438 to 123245.25781, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123774.7500 - val_loss: 123245.2578\nEpoch 12/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111797.8359\nEpoch 12: val_loss improved from 123245.25781 to 121091.91406, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111620.6016 - val_loss: 121091.9141\nEpoch 13/300\n\u001b[1m613/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103377.7266\nEpoch 13: val_loss improved from 121091.91406 to 119609.00781, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103458.1406 - val_loss: 119609.0078\nEpoch 14/300\n\u001b[1m595/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120769.0547\nEpoch 14: val_loss improved from 119609.00781 to 118328.48438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119890.6953 - val_loss: 118328.4844\nEpoch 15/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114436.6406\nEpoch 15: val_loss improved from 118328.48438 to 117024.89844, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114113.8203 - val_loss: 117024.8984\nEpoch 16/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99415.8281\nEpoch 16: val_loss improved from 117024.89844 to 115887.09375, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99570.9141 - val_loss: 115887.0938\nEpoch 17/300\n\u001b[1m595/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90938.3203\nEpoch 17: val_loss improved from 115887.09375 to 114875.32812, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91543.0547 - val_loss: 114875.3281\nEpoch 18/300\n\u001b[1m615/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 102326.9844\nEpoch 18: val_loss improved from 114875.32812 to 114181.65625, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102283.5781 - val_loss: 114181.6562\nEpoch 19/300\n\u001b[1m615/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90375.3203\nEpoch 19: val_loss improved from 114181.65625 to 113244.01562, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90618.6641 - val_loss: 113244.0156\nEpoch 20/300\n\u001b[1m616/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108077.6719\nEpoch 20: val_loss improved from 113244.01562 to 112465.54688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107877.5234 - val_loss: 112465.5469\nEpoch 21/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92513.7031\nEpoch 21: val_loss improved from 112465.54688 to 111757.71875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92557.9609 - val_loss: 111757.7188\nEpoch 22/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 100337.1250\nEpoch 22: val_loss improved from 111757.71875 to 110948.15625, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100124.7969 - val_loss: 110948.1562\nEpoch 23/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98483.4297\nEpoch 23: val_loss improved from 110948.15625 to 110597.63281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98432.9922 - val_loss: 110597.6328\nEpoch 24/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92539.8203\nEpoch 24: val_loss improved from 110597.63281 to 109992.22656, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92596.4062 - val_loss: 109992.2266\nEpoch 25/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88846.7109\nEpoch 25: val_loss improved from 109992.22656 to 109338.94531, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89133.4141 - val_loss: 109338.9453\nEpoch 26/300\n\u001b[1m594/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103579.2031\nEpoch 26: val_loss improved from 109338.94531 to 108855.73438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103098.3359 - val_loss: 108855.7344\nEpoch 27/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98324.4688\nEpoch 27: val_loss improved from 108855.73438 to 108292.83594, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98282.1797 - val_loss: 108292.8359\nEpoch 28/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105316.5547\nEpoch 28: val_loss improved from 108292.83594 to 107743.20312, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104874.1875 - val_loss: 107743.2031\nEpoch 29/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92002.4453\nEpoch 29: val_loss improved from 107743.20312 to 107589.27344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92054.1406 - val_loss: 107589.2734\nEpoch 30/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92954.4062\nEpoch 30: val_loss improved from 107589.27344 to 106863.89844, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92968.1250 - val_loss: 106863.8984\nEpoch 31/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96397.8828\nEpoch 31: val_loss improved from 106863.89844 to 106287.34375, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96283.5156 - val_loss: 106287.3438\nEpoch 32/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93403.4453\nEpoch 32: val_loss improved from 106287.34375 to 105977.75781, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93335.1172 - val_loss: 105977.7578\nEpoch 33/300\n\u001b[1m627/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106056.8047\nEpoch 33: val_loss improved from 105977.75781 to 105584.08594, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105966.5234 - val_loss: 105584.0859\nEpoch 34/300\n\u001b[1m599/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90509.4062\nEpoch 34: val_loss improved from 105584.08594 to 105236.42188, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90557.4219 - val_loss: 105236.4219\nEpoch 35/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94499.4297\nEpoch 35: val_loss improved from 105236.42188 to 104790.14844, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94261.6797 - val_loss: 104790.1484\nEpoch 36/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94853.6250\nEpoch 36: val_loss improved from 104790.14844 to 104741.14062, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94831.7109 - val_loss: 104741.1406\nEpoch 37/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91148.7500\nEpoch 37: val_loss improved from 104741.14062 to 104425.71875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91135.3125 - val_loss: 104425.7188\nEpoch 38/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86145.2891\nEpoch 38: val_loss improved from 104425.71875 to 103751.29688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86299.0547 - val_loss: 103751.2969\nEpoch 39/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88617.7109\nEpoch 39: val_loss improved from 103751.29688 to 103444.38281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88577.6250 - val_loss: 103444.3828\nEpoch 40/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91245.8828\nEpoch 40: val_loss improved from 103444.38281 to 103150.79688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91128.3672 - val_loss: 103150.7969\nEpoch 41/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91937.6875\nEpoch 41: val_loss improved from 103150.79688 to 102980.85156, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91780.1641 - val_loss: 102980.8516\nEpoch 42/300\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82201.3125\nEpoch 42: val_loss improved from 102980.85156 to 102540.42188, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82211.0625 - val_loss: 102540.4219\nEpoch 43/300\n\u001b[1m627/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84782.5156\nEpoch 43: val_loss improved from 102540.42188 to 102472.29688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84803.0078 - val_loss: 102472.2969\nEpoch 44/300\n\u001b[1m622/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94319.1875\nEpoch 44: val_loss improved from 102472.29688 to 102014.58594, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94223.5391 - val_loss: 102014.5859\nEpoch 45/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82102.8906\nEpoch 45: val_loss improved from 102014.58594 to 101800.62500, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82194.2891 - val_loss: 101800.6250\nEpoch 46/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105747.4141\nEpoch 46: val_loss improved from 101800.62500 to 101478.77344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104978.9062 - val_loss: 101478.7734\nEpoch 47/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82495.9766\nEpoch 47: val_loss did not improve from 101478.77344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82707.6172 - val_loss: 101615.8594\nEpoch 48/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82975.7812\nEpoch 48: val_loss improved from 101478.77344 to 101110.41406, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83172.4375 - val_loss: 101110.4141\nEpoch 49/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80074.5391\nEpoch 49: val_loss improved from 101110.41406 to 100852.19531, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80326.0078 - val_loss: 100852.1953\nEpoch 50/300\n\u001b[1m599/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90821.4453\nEpoch 50: val_loss improved from 100852.19531 to 100588.07031, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90589.0469 - val_loss: 100588.0703\nEpoch 51/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96519.6016\nEpoch 51: val_loss improved from 100588.07031 to 100518.58594, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96083.1016 - val_loss: 100518.5859\nEpoch 52/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84949.5156\nEpoch 52: val_loss improved from 100518.58594 to 100253.99219, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85019.6484 - val_loss: 100253.9922\nEpoch 53/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82166.1250\nEpoch 53: val_loss improved from 100253.99219 to 100178.68750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82279.1328 - val_loss: 100178.6875\nEpoch 54/300\n\u001b[1m597/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88099.0781\nEpoch 54: val_loss improved from 100178.68750 to 99941.77344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87935.0781 - val_loss: 99941.7734\nEpoch 55/300\n\u001b[1m622/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91741.5703\nEpoch 55: val_loss improved from 99941.77344 to 99764.13281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91652.7578 - val_loss: 99764.1328\nEpoch 56/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77779.4844\nEpoch 56: val_loss did not improve from 99764.13281\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78068.7422 - val_loss: 99782.1797\nEpoch 57/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88910.0859\nEpoch 57: val_loss improved from 99764.13281 to 99461.10938, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88715.7734 - val_loss: 99461.1094\nEpoch 58/300\n\u001b[1m625/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93250.7578\nEpoch 58: val_loss improved from 99461.10938 to 99135.42188, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93166.6250 - val_loss: 99135.4219\nEpoch 59/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89716.6562\nEpoch 59: val_loss improved from 99135.42188 to 99072.18750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89483.7656 - val_loss: 99072.1875\nEpoch 60/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80147.5547\nEpoch 60: val_loss improved from 99072.18750 to 98932.30469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80226.3203 - val_loss: 98932.3047\nEpoch 61/300\n\u001b[1m622/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79935.8906\nEpoch 61: val_loss improved from 98932.30469 to 98838.90625, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79987.0625 - val_loss: 98838.9062\nEpoch 62/300\n\u001b[1m613/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89490.9766\nEpoch 62: val_loss improved from 98838.90625 to 98422.63281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89331.4297 - val_loss: 98422.6328\nEpoch 63/300\n\u001b[1m629/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83554.6250\nEpoch 63: val_loss did not improve from 98422.63281\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83553.5547 - val_loss: 98570.2344\nEpoch 64/300\n\u001b[1m627/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74261.6172\nEpoch 64: val_loss improved from 98422.63281 to 98235.45312, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74316.1406 - val_loss: 98235.4531\nEpoch 65/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77051.4844\nEpoch 65: val_loss improved from 98235.45312 to 98202.07031, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77142.9844 - val_loss: 98202.0703\nEpoch 66/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76692.8359\nEpoch 66: val_loss improved from 98202.07031 to 97865.18750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76721.8516 - val_loss: 97865.1875\nEpoch 67/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73807.9531\nEpoch 67: val_loss improved from 97865.18750 to 97854.10156, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73971.6953 - val_loss: 97854.1016\nEpoch 68/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86921.8906\nEpoch 68: val_loss improved from 97854.10156 to 97708.19531, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86874.9609 - val_loss: 97708.1953\nEpoch 69/300\n\u001b[1m622/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79408.5391\nEpoch 69: val_loss improved from 97708.19531 to 97675.86719, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79461.0547 - val_loss: 97675.8672\nEpoch 70/300\n\u001b[1m627/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76184.1719\nEpoch 70: val_loss improved from 97675.86719 to 97599.20312, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76222.5000 - val_loss: 97599.2031\nEpoch 71/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84368.7969\nEpoch 71: val_loss improved from 97599.20312 to 97108.67188, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84332.6016 - val_loss: 97108.6719\nEpoch 72/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83248.4688\nEpoch 72: val_loss improved from 97108.67188 to 96959.48438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83236.6328 - val_loss: 96959.4844\nEpoch 73/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78882.7109\nEpoch 73: val_loss did not improve from 96959.48438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79033.9062 - val_loss: 97018.4453\nEpoch 74/300\n\u001b[1m599/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81935.6562\nEpoch 74: val_loss improved from 96959.48438 to 96855.78906, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81938.1328 - val_loss: 96855.7891\nEpoch 75/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82083.8125\nEpoch 75: val_loss did not improve from 96855.78906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82080.9844 - val_loss: 96876.1875\nEpoch 76/300\n\u001b[1m618/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83048.6250\nEpoch 76: val_loss improved from 96855.78906 to 96411.46875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83008.6094 - val_loss: 96411.4688\nEpoch 77/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86821.8359\nEpoch 77: val_loss did not improve from 96411.46875\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86779.7969 - val_loss: 96578.3125\nEpoch 78/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82139.9688\nEpoch 78: val_loss improved from 96411.46875 to 96302.25000, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82134.1953 - val_loss: 96302.2500\nEpoch 79/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80155.8828\nEpoch 79: val_loss improved from 96302.25000 to 96162.78125, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80206.3750 - val_loss: 96162.7812\nEpoch 80/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75223.3359\nEpoch 80: val_loss improved from 96162.78125 to 96158.49219, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75448.6016 - val_loss: 96158.4922\nEpoch 81/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76200.0391\nEpoch 81: val_loss improved from 96158.49219 to 95810.76562, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76435.1094 - val_loss: 95810.7656\nEpoch 82/300\n\u001b[1m625/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79562.8516\nEpoch 82: val_loss did not improve from 95810.76562\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79572.4609 - val_loss: 95878.4844\nEpoch 83/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76991.2188\nEpoch 83: val_loss improved from 95810.76562 to 95771.04688, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77034.5000 - val_loss: 95771.0469\nEpoch 84/300\n\u001b[1m615/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79623.7109\nEpoch 84: val_loss improved from 95771.04688 to 95753.95312, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79644.8594 - val_loss: 95753.9531\nEpoch 85/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81215.2188\nEpoch 85: val_loss improved from 95753.95312 to 95739.84375, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81205.5469 - val_loss: 95739.8438\nEpoch 86/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80809.4219\nEpoch 86: val_loss improved from 95739.84375 to 95702.39062, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80802.3984 - val_loss: 95702.3906\nEpoch 87/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78183.6094\nEpoch 87: val_loss improved from 95702.39062 to 95547.69531, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78208.7500 - val_loss: 95547.6953\nEpoch 88/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77851.7969\nEpoch 88: val_loss improved from 95547.69531 to 95412.25781, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77882.5625 - val_loss: 95412.2578\nEpoch 89/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83182.2578\nEpoch 89: val_loss did not improve from 95412.25781\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83168.1953 - val_loss: 95567.4688\nEpoch 90/300\n\u001b[1m615/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76803.6016\nEpoch 90: val_loss improved from 95412.25781 to 95122.55469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76872.7422 - val_loss: 95122.5547\nEpoch 91/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89590.0703\nEpoch 91: val_loss did not improve from 95122.55469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89062.6719 - val_loss: 95283.8828\nEpoch 92/300\n\u001b[1m622/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81804.6719\nEpoch 92: val_loss improved from 95122.55469 to 95108.21094, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81768.6328 - val_loss: 95108.2109\nEpoch 93/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85685.2812\nEpoch 93: val_loss improved from 95108.21094 to 94829.43750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85372.3438 - val_loss: 94829.4375\nEpoch 94/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91149.2578\nEpoch 94: val_loss did not improve from 94829.43750\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90627.2266 - val_loss: 95008.8828\nEpoch 95/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81010.2422\nEpoch 95: val_loss improved from 94829.43750 to 94813.92969, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80922.0469 - val_loss: 94813.9297\nEpoch 96/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75863.3906\nEpoch 96: val_loss improved from 94813.92969 to 94650.27344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75943.7109 - val_loss: 94650.2734\nEpoch 97/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71689.5156\nEpoch 97: val_loss did not improve from 94650.27344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72022.2812 - val_loss: 94810.5312\nEpoch 98/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77085.8281\nEpoch 98: val_loss improved from 94650.27344 to 94487.27344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77162.6875 - val_loss: 94487.2734\nEpoch 99/300\n\u001b[1m597/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74957.4766\nEpoch 99: val_loss improved from 94487.27344 to 94309.50781, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75177.4375 - val_loss: 94309.5078\nEpoch 100/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72195.7266\nEpoch 100: val_loss did not improve from 94309.50781\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72518.7266 - val_loss: 94468.2031\nEpoch 101/300\n\u001b[1m623/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75151.5156\nEpoch 101: val_loss did not improve from 94309.50781\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75199.3438 - val_loss: 94313.0469\nEpoch 102/300\n\u001b[1m623/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72523.2344\nEpoch 102: val_loss improved from 94309.50781 to 94276.10156, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72604.6094 - val_loss: 94276.1016\nEpoch 103/300\n\u001b[1m613/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75366.4297\nEpoch 103: val_loss improved from 94276.10156 to 94063.60156, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75461.2891 - val_loss: 94063.6016\nEpoch 104/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77404.1484\nEpoch 104: val_loss did not improve from 94063.60156\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77436.8281 - val_loss: 94167.9688\nEpoch 105/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72234.6875\nEpoch 105: val_loss did not improve from 94063.60156\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72439.3438 - val_loss: 94112.4375\nEpoch 106/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79016.7812\nEpoch 106: val_loss improved from 94063.60156 to 93914.85156, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79004.1328 - val_loss: 93914.8516\nEpoch 107/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85480.5391\nEpoch 107: val_loss did not improve from 93914.85156\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85158.3906 - val_loss: 94044.1562\nEpoch 108/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75915.5859\nEpoch 108: val_loss did not improve from 93914.85156\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76013.8438 - val_loss: 94016.9375\nEpoch 109/300\n\u001b[1m599/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90128.4922\nEpoch 109: val_loss improved from 93914.85156 to 93739.74219, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89539.2188 - val_loss: 93739.7422\nEpoch 110/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75807.4141\nEpoch 110: val_loss did not improve from 93739.74219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75822.3672 - val_loss: 93792.9062\nEpoch 111/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71056.0938\nEpoch 111: val_loss improved from 93739.74219 to 93516.75781, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71330.6484 - val_loss: 93516.7578\nEpoch 112/300\n\u001b[1m613/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73659.0000\nEpoch 112: val_loss improved from 93516.75781 to 93441.00000, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73783.7969 - val_loss: 93441.0000\nEpoch 113/300\n\u001b[1m629/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70878.9922\nEpoch 113: val_loss did not improve from 93441.00000\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70899.4062 - val_loss: 93465.1172\nEpoch 114/300\n\u001b[1m623/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77030.0625\nEpoch 114: val_loss did not improve from 93441.00000\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77047.7812 - val_loss: 93485.7500\nEpoch 115/300\n\u001b[1m625/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70111.8359\nEpoch 115: val_loss did not improve from 93441.00000\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70166.3672 - val_loss: 93499.0234\nEpoch 116/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76131.1484\nEpoch 116: val_loss improved from 93441.00000 to 93101.46875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76144.5078 - val_loss: 93101.4688\nEpoch 117/300\n\u001b[1m625/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79629.5000\nEpoch 117: val_loss did not improve from 93101.46875\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79606.8125 - val_loss: 93209.9609\nEpoch 118/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79576.3203\nEpoch 118: val_loss did not improve from 93101.46875\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79547.1250 - val_loss: 93169.4688\nEpoch 119/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84805.1172\nEpoch 119: val_loss did not improve from 93101.46875\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84447.8125 - val_loss: 93107.5312\nEpoch 120/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73849.2812\nEpoch 120: val_loss did not improve from 93101.46875\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73914.7969 - val_loss: 93250.8906\nEpoch 121/300\n\u001b[1m596/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81341.5078\nEpoch 121: val_loss improved from 93101.46875 to 93013.63281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81124.8516 - val_loss: 93013.6328\nEpoch 122/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73980.7656\nEpoch 122: val_loss improved from 93013.63281 to 92855.72656, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74122.2266 - val_loss: 92855.7266\nEpoch 123/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83047.1328\nEpoch 123: val_loss did not improve from 92855.72656\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82826.8125 - val_loss: 92939.5391\nEpoch 124/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73849.7422\nEpoch 124: val_loss improved from 92855.72656 to 92740.35938, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73938.0781 - val_loss: 92740.3594\nEpoch 125/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75912.9062\nEpoch 125: val_loss improved from 92740.35938 to 92609.06250, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75851.8828 - val_loss: 92609.0625\nEpoch 126/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74948.3594\nEpoch 126: val_loss improved from 92609.06250 to 92582.78125, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75008.1016 - val_loss: 92582.7812\nEpoch 127/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73701.1094\nEpoch 127: val_loss improved from 92582.78125 to 92502.01562, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73765.5000 - val_loss: 92502.0156\nEpoch 128/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67858.1172\nEpoch 128: val_loss did not improve from 92502.01562\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68185.7031 - val_loss: 92610.8750\nEpoch 129/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79458.5391\nEpoch 129: val_loss did not improve from 92502.01562\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79345.6250 - val_loss: 92637.7422\nEpoch 130/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78680.5156\nEpoch 130: val_loss did not improve from 92502.01562\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78608.4844 - val_loss: 92534.5859\nEpoch 131/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76245.0234\nEpoch 131: val_loss improved from 92502.01562 to 92285.67969, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76247.7109 - val_loss: 92285.6797\nEpoch 132/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73700.6094\nEpoch 132: val_loss did not improve from 92285.67969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73776.1484 - val_loss: 92367.0938\nEpoch 133/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70293.9922\nEpoch 133: val_loss did not improve from 92285.67969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70321.0938 - val_loss: 92340.7109\nEpoch 134/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74411.3125\nEpoch 134: val_loss did not improve from 92285.67969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74488.0312 - val_loss: 92469.6484\nEpoch 135/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68879.8125\nEpoch 135: val_loss improved from 92285.67969 to 92278.30469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69180.4844 - val_loss: 92278.3047\nEpoch 136/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75593.4531\nEpoch 136: val_loss improved from 92278.30469 to 92152.67969, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75606.8438 - val_loss: 92152.6797\nEpoch 137/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72689.3125\nEpoch 137: val_loss did not improve from 92152.67969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72758.3828 - val_loss: 92266.4922\nEpoch 138/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81229.0703\nEpoch 138: val_loss improved from 92152.67969 to 91897.88281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81033.5078 - val_loss: 91897.8828\nEpoch 139/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71790.3672\nEpoch 139: val_loss did not improve from 91897.88281\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71945.3828 - val_loss: 92128.9297\nEpoch 140/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76008.3750\nEpoch 140: val_loss did not improve from 91897.88281\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76019.7344 - val_loss: 92011.7969\nEpoch 141/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74241.6484\nEpoch 141: val_loss improved from 91897.88281 to 91783.80469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74300.9375 - val_loss: 91783.8047\nEpoch 142/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66430.0469\nEpoch 142: val_loss improved from 91783.80469 to 91779.80469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66716.7031 - val_loss: 91779.8047\nEpoch 143/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72491.0391\nEpoch 143: val_loss did not improve from 91779.80469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72609.2266 - val_loss: 91976.0312\nEpoch 144/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74154.4766\nEpoch 144: val_loss improved from 91779.80469 to 91742.46875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74224.3906 - val_loss: 91742.4688\nEpoch 145/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75337.2188\nEpoch 145: val_loss did not improve from 91742.46875\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75323.0312 - val_loss: 91899.3047\nEpoch 146/300\n\u001b[1m614/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81969.0938\nEpoch 146: val_loss improved from 91742.46875 to 91678.39062, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81785.7266 - val_loss: 91678.3906\nEpoch 147/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77445.6953\nEpoch 147: val_loss improved from 91678.39062 to 91587.73438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77374.4297 - val_loss: 91587.7344\nEpoch 148/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74833.3828\nEpoch 148: val_loss improved from 91587.73438 to 91461.98438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74895.2344 - val_loss: 91461.9844\nEpoch 149/300\n\u001b[1m596/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75145.7969\nEpoch 149: val_loss did not improve from 91461.98438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75187.0547 - val_loss: 91541.5781\nEpoch 150/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72258.0234\nEpoch 150: val_loss improved from 91461.98438 to 91410.32031, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72330.3203 - val_loss: 91410.3203\nEpoch 151/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75926.8906\nEpoch 151: val_loss did not improve from 91410.32031\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75886.7734 - val_loss: 91551.5547\nEpoch 152/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66540.7109\nEpoch 152: val_loss improved from 91410.32031 to 91346.57812, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66845.1406 - val_loss: 91346.5781\nEpoch 153/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72535.0781\nEpoch 153: val_loss did not improve from 91346.57812\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72634.0938 - val_loss: 91451.8438\nEpoch 154/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80069.4219\nEpoch 154: val_loss did not improve from 91346.57812\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79864.6484 - val_loss: 91477.7500\nEpoch 155/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66257.0078\nEpoch 155: val_loss improved from 91346.57812 to 91237.27344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66549.2422 - val_loss: 91237.2734\nEpoch 156/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79486.4453\nEpoch 156: val_loss improved from 91237.27344 to 91236.55469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79291.4062 - val_loss: 91236.5547\nEpoch 157/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90475.5938\nEpoch 157: val_loss improved from 91236.55469 to 91185.64062, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90185.7031 - val_loss: 91185.6406\nEpoch 158/300\n\u001b[1m615/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75164.5469\nEpoch 158: val_loss did not improve from 91185.64062\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75157.3438 - val_loss: 91268.2344\nEpoch 159/300\n\u001b[1m618/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77420.5781\nEpoch 159: val_loss improved from 91185.64062 to 91136.84375, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77379.0234 - val_loss: 91136.8438\nEpoch 160/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69056.6484\nEpoch 160: val_loss did not improve from 91136.84375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69159.6719 - val_loss: 91364.0781\nEpoch 161/300\n\u001b[1m597/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78985.2344\nEpoch 161: val_loss improved from 91136.84375 to 91092.78125, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78760.0859 - val_loss: 91092.7812\nEpoch 162/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73133.9609\nEpoch 162: val_loss improved from 91092.78125 to 90902.18750, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73140.5078 - val_loss: 90902.1875\nEpoch 163/300\n\u001b[1m617/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75555.9609\nEpoch 163: val_loss did not improve from 90902.18750\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75525.7188 - val_loss: 91130.2188\nEpoch 164/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78429.5312\nEpoch 164: val_loss did not improve from 90902.18750\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78390.6641 - val_loss: 90915.5391\nEpoch 165/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72656.2422\nEpoch 165: val_loss did not improve from 90902.18750\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72708.6562 - val_loss: 91050.5312\nEpoch 166/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69326.1406\nEpoch 166: val_loss did not improve from 90902.18750\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69526.7812 - val_loss: 91010.4531\nEpoch 167/300\n\u001b[1m614/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67280.0625\nEpoch 167: val_loss improved from 90902.18750 to 90752.36719, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67477.4375 - val_loss: 90752.3672\nEpoch 168/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79517.1094\nEpoch 168: val_loss improved from 90752.36719 to 90579.39062, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79293.3203 - val_loss: 90579.3906\nEpoch 169/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88946.9062\nEpoch 169: val_loss did not improve from 90579.39062\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88460.0156 - val_loss: 90796.6172\nEpoch 170/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70255.1875\nEpoch 170: val_loss did not improve from 90579.39062\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70409.3828 - val_loss: 90685.7969\nEpoch 171/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69343.5703\nEpoch 171: val_loss did not improve from 90579.39062\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69535.9609 - val_loss: 90816.2969\nEpoch 172/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76581.6406\nEpoch 172: val_loss did not improve from 90579.39062\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76514.3672 - val_loss: 90637.9219\nEpoch 173/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80039.6172\nEpoch 173: val_loss improved from 90579.39062 to 90311.02344, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79799.4766 - val_loss: 90311.0234\nEpoch 174/300\n\u001b[1m621/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71474.1797\nEpoch 174: val_loss did not improve from 90311.02344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71510.7812 - val_loss: 90498.7422\nEpoch 175/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72636.5859\nEpoch 175: val_loss did not improve from 90311.02344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72702.2031 - val_loss: 90574.5859\nEpoch 176/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74113.8984\nEpoch 176: val_loss did not improve from 90311.02344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74118.9062 - val_loss: 90555.4688\nEpoch 177/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73345.6641\nEpoch 177: val_loss did not improve from 90311.02344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73361.9844 - val_loss: 90366.3750\nEpoch 178/300\n\u001b[1m616/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70007.7891\nEpoch 178: val_loss did not improve from 90311.02344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70107.2266 - val_loss: 90349.0391\nEpoch 179/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71164.3828\nEpoch 179: val_loss did not improve from 90311.02344\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71278.3359 - val_loss: 90373.6250\nEpoch 180/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77618.7422\nEpoch 180: val_loss improved from 90311.02344 to 90288.86719, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77575.3438 - val_loss: 90288.8672\nEpoch 181/300\n\u001b[1m593/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66012.7500\nEpoch 181: val_loss did not improve from 90288.86719\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66393.0078 - val_loss: 90294.0859\nEpoch 182/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70512.0312\nEpoch 182: val_loss improved from 90288.86719 to 90149.05469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70628.2891 - val_loss: 90149.0547\nEpoch 183/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70428.4688\nEpoch 183: val_loss improved from 90149.05469 to 90125.92969, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70514.8047 - val_loss: 90125.9297\nEpoch 184/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73573.2422\nEpoch 184: val_loss did not improve from 90125.92969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73573.9062 - val_loss: 90397.7031\nEpoch 185/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66246.2734\nEpoch 185: val_loss did not improve from 90125.92969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66531.1016 - val_loss: 90301.0234\nEpoch 186/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78236.4219\nEpoch 186: val_loss did not improve from 90125.92969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77985.3047 - val_loss: 90259.2969\nEpoch 187/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74158.2656\nEpoch 187: val_loss did not improve from 90125.92969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74122.3203 - val_loss: 90324.3438\nEpoch 188/300\n\u001b[1m593/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86325.7969\nEpoch 188: val_loss did not improve from 90125.92969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85570.1641 - val_loss: 90187.2109\nEpoch 189/300\n\u001b[1m594/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67116.0625\nEpoch 189: val_loss improved from 90125.92969 to 90059.11719, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67472.9766 - val_loss: 90059.1172\nEpoch 190/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71963.2656\nEpoch 190: val_loss improved from 90059.11719 to 90044.00000, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72011.3359 - val_loss: 90044.0000\nEpoch 191/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74404.0938\nEpoch 191: val_loss improved from 90044.00000 to 89901.03125, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74363.8438 - val_loss: 89901.0312\nEpoch 192/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66895.6641\nEpoch 192: val_loss did not improve from 89901.03125\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67138.2500 - val_loss: 89988.2578\nEpoch 193/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74864.5078\nEpoch 193: val_loss improved from 89901.03125 to 89841.85938, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74846.3125 - val_loss: 89841.8594\nEpoch 194/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74431.2500\nEpoch 194: val_loss did not improve from 89841.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74370.1875 - val_loss: 90075.7031\nEpoch 195/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69043.1172\nEpoch 195: val_loss did not improve from 89841.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69218.2109 - val_loss: 89998.4609\nEpoch 196/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76798.2500\nEpoch 196: val_loss did not improve from 89841.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76648.8438 - val_loss: 90164.6406\nEpoch 197/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67363.1719\nEpoch 197: val_loss did not improve from 89841.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67576.1172 - val_loss: 89977.3281\nEpoch 198/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67730.0625\nEpoch 198: val_loss improved from 89841.85938 to 89768.17969, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67976.4609 - val_loss: 89768.1797\nEpoch 199/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74441.9844\nEpoch 199: val_loss did not improve from 89768.17969\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74375.4297 - val_loss: 89839.7188\nEpoch 200/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68158.3203\nEpoch 200: val_loss improved from 89768.17969 to 89694.39062, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68437.0469 - val_loss: 89694.3906\nEpoch 201/300\n\u001b[1m625/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73855.4766\nEpoch 201: val_loss improved from 89694.39062 to 89613.90625, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73833.8359 - val_loss: 89613.9062\nEpoch 202/300\n\u001b[1m621/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76470.3047\nEpoch 202: val_loss did not improve from 89613.90625\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76411.0859 - val_loss: 89685.3984\nEpoch 203/300\n\u001b[1m614/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67785.3906\nEpoch 203: val_loss did not improve from 89613.90625\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67928.7812 - val_loss: 89748.8125\nEpoch 204/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76072.1016\nEpoch 204: val_loss improved from 89613.90625 to 89599.14844, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75947.8125 - val_loss: 89599.1484\nEpoch 205/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68766.3438\nEpoch 205: val_loss did not improve from 89599.14844\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68895.4766 - val_loss: 89649.7812\nEpoch 206/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70825.8594\nEpoch 206: val_loss improved from 89599.14844 to 89553.53906, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70929.1406 - val_loss: 89553.5391\nEpoch 207/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77310.8359\nEpoch 207: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77135.4375 - val_loss: 89909.1406\nEpoch 208/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75649.9688\nEpoch 208: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75504.8281 - val_loss: 89854.7812\nEpoch 209/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69244.2891\nEpoch 209: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69331.7031 - val_loss: 89882.7891\nEpoch 210/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76905.0078\nEpoch 210: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76733.8672 - val_loss: 89792.3359\nEpoch 211/300\n\u001b[1m629/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66400.1719\nEpoch 211: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66416.8828 - val_loss: 89662.5391\nEpoch 212/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74320.4062\nEpoch 212: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74255.3281 - val_loss: 89594.0312\nEpoch 213/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65276.9141\nEpoch 213: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65496.6797 - val_loss: 89930.8672\nEpoch 214/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83408.1484\nEpoch 214: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83010.3594 - val_loss: 89682.1406\nEpoch 215/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68868.2188\nEpoch 215: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68997.0312 - val_loss: 89649.1875\nEpoch 216/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70916.3828\nEpoch 216: val_loss did not improve from 89553.53906\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70948.3203 - val_loss: 89739.6406\nEpoch 217/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65363.5117\nEpoch 217: val_loss improved from 89553.53906 to 89413.38281, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65586.3047 - val_loss: 89413.3828\nEpoch 218/300\n\u001b[1m613/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69740.8359\nEpoch 218: val_loss improved from 89413.38281 to 89410.71094, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69799.7734 - val_loss: 89410.7109\nEpoch 219/300\n\u001b[1m624/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70103.3906\nEpoch 219: val_loss did not improve from 89410.71094\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70122.9766 - val_loss: 89482.8672\nEpoch 220/300\n\u001b[1m620/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68908.4375\nEpoch 220: val_loss did not improve from 89410.71094\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68953.5938 - val_loss: 89506.0703\nEpoch 221/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70806.4609\nEpoch 221: val_loss did not improve from 89410.71094\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70850.4766 - val_loss: 89606.8281\nEpoch 222/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64269.7891\nEpoch 222: val_loss did not improve from 89410.71094\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64565.9375 - val_loss: 89565.6562\nEpoch 223/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71933.6016\nEpoch 223: val_loss improved from 89410.71094 to 89379.05469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71917.0938 - val_loss: 89379.0547\nEpoch 224/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74975.0156\nEpoch 224: val_loss did not improve from 89379.05469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74841.0234 - val_loss: 89452.4453\nEpoch 225/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68465.6484\nEpoch 225: val_loss did not improve from 89379.05469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68606.7734 - val_loss: 89406.4531\nEpoch 226/300\n\u001b[1m598/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79767.1016\nEpoch 226: val_loss improved from 89379.05469 to 89343.03906, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79359.5156 - val_loss: 89343.0391\nEpoch 227/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65143.8203\nEpoch 227: val_loss improved from 89343.03906 to 89193.55469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65430.3359 - val_loss: 89193.5547\nEpoch 228/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68073.1016\nEpoch 228: val_loss did not improve from 89193.55469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68148.8516 - val_loss: 89299.4219\nEpoch 229/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79175.7109\nEpoch 229: val_loss did not improve from 89193.55469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78861.1641 - val_loss: 89389.8203\nEpoch 230/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69447.1641\nEpoch 230: val_loss did not improve from 89193.55469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69550.4531 - val_loss: 89324.1406\nEpoch 231/300\n\u001b[1m616/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73745.6641\nEpoch 231: val_loss did not improve from 89193.55469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73691.0625 - val_loss: 89374.0156\nEpoch 232/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68983.4219\nEpoch 232: val_loss improved from 89193.55469 to 89082.85938, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69086.7969 - val_loss: 89082.8594\nEpoch 233/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76225.6797\nEpoch 233: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76064.1016 - val_loss: 89205.4219\nEpoch 234/300\n\u001b[1m618/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71269.1406\nEpoch 234: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71269.3984 - val_loss: 89216.8047\nEpoch 235/300\n\u001b[1m621/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77477.8281\nEpoch 235: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77375.7812 - val_loss: 89325.1484\nEpoch 236/300\n\u001b[1m622/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64230.4375\nEpoch 236: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64331.0078 - val_loss: 89216.1719\nEpoch 237/300\n\u001b[1m617/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68747.5703\nEpoch 237: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68789.0938 - val_loss: 89526.8516\nEpoch 238/300\n\u001b[1m626/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70191.2344\nEpoch 238: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70201.5391 - val_loss: 89489.6484\nEpoch 239/300\n\u001b[1m593/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67809.3828\nEpoch 239: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67879.5000 - val_loss: 89274.3125\nEpoch 240/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69661.1797\nEpoch 240: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69686.0234 - val_loss: 89307.8906\nEpoch 241/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70115.9297\nEpoch 241: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70142.5859 - val_loss: 89421.1250\nEpoch 242/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77663.6016\nEpoch 242: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77359.5938 - val_loss: 89287.0234\nEpoch 243/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71999.0000\nEpoch 243: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71978.9062 - val_loss: 89212.0391\nEpoch 244/300\n\u001b[1m594/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75155.3516\nEpoch 244: val_loss did not improve from 89082.85938\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74913.1797 - val_loss: 89265.0938\nEpoch 245/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67794.5312\nEpoch 245: val_loss improved from 89082.85938 to 88989.61719, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67908.1094 - val_loss: 88989.6172\nEpoch 246/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65516.4180\nEpoch 246: val_loss did not improve from 88989.61719\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65680.8594 - val_loss: 89026.0469\nEpoch 247/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74406.6484\nEpoch 247: val_loss did not improve from 88989.61719\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74258.2734 - val_loss: 89023.9141\nEpoch 248/300\n\u001b[1m602/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75132.3906\nEpoch 248: val_loss did not improve from 88989.61719\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74943.3125 - val_loss: 89187.5078\nEpoch 249/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69261.9219\nEpoch 249: val_loss did not improve from 88989.61719\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69304.3750 - val_loss: 89133.1406\nEpoch 250/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76507.1094\nEpoch 250: val_loss did not improve from 88989.61719\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76281.9531 - val_loss: 89121.2188\nEpoch 251/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65336.4844\nEpoch 251: val_loss improved from 88989.61719 to 88962.09375, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65536.2031 - val_loss: 88962.0938\nEpoch 252/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64080.6992\nEpoch 252: val_loss improved from 88962.09375 to 88895.41406, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64349.4648 - val_loss: 88895.4141\nEpoch 253/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62831.1055\nEpoch 253: val_loss did not improve from 88895.41406\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63106.1211 - val_loss: 88985.6641\nEpoch 254/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70093.3125\nEpoch 254: val_loss improved from 88895.41406 to 88862.24219, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70105.6875 - val_loss: 88862.2422\nEpoch 255/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77685.8828\nEpoch 255: val_loss did not improve from 88862.24219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77436.5391 - val_loss: 88872.4531\nEpoch 256/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73285.0391\nEpoch 256: val_loss did not improve from 88862.24219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73209.8516 - val_loss: 88910.5781\nEpoch 257/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73721.2578\nEpoch 257: val_loss did not improve from 88862.24219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73600.0312 - val_loss: 88993.5078\nEpoch 258/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85220.4219\nEpoch 258: val_loss did not improve from 88862.24219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84622.8594 - val_loss: 88953.4375\nEpoch 259/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66998.0938\nEpoch 259: val_loss did not improve from 88862.24219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67150.9375 - val_loss: 88957.5078\nEpoch 260/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65461.2812\nEpoch 260: val_loss improved from 88862.24219 to 88524.73438, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65610.8516 - val_loss: 88524.7344\nEpoch 261/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65417.0000\nEpoch 261: val_loss did not improve from 88524.73438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65644.8203 - val_loss: 88630.5312\nEpoch 262/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69886.6953\nEpoch 262: val_loss did not improve from 88524.73438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69885.4531 - val_loss: 88690.9766\nEpoch 263/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75766.5938\nEpoch 263: val_loss did not improve from 88524.73438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75578.7891 - val_loss: 88768.2422\nEpoch 264/300\n\u001b[1m603/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71151.3203\nEpoch 264: val_loss did not improve from 88524.73438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71111.6719 - val_loss: 88743.4531\nEpoch 265/300\n\u001b[1m614/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65429.6875\nEpoch 265: val_loss did not improve from 88524.73438\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65546.9609 - val_loss: 88594.9609\nEpoch 266/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73018.5000\nEpoch 266: val_loss improved from 88524.73438 to 88512.49219, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72928.7578 - val_loss: 88512.4922\nEpoch 267/300\n\u001b[1m619/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72593.7266\nEpoch 267: val_loss did not improve from 88512.49219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72530.3516 - val_loss: 88914.2969\nEpoch 268/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66248.9922\nEpoch 268: val_loss did not improve from 88512.49219\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66421.2109 - val_loss: 88594.2969\nEpoch 269/300\n\u001b[1m599/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69967.3203\nEpoch 269: val_loss improved from 88512.49219 to 88506.96875, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69975.9531 - val_loss: 88506.9688\nEpoch 270/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72870.2031\nEpoch 270: val_loss improved from 88506.96875 to 88480.49219, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72698.7031 - val_loss: 88480.4922\nEpoch 271/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74866.6016\nEpoch 271: val_loss improved from 88480.49219 to 88431.30469, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74659.7578 - val_loss: 88431.3047\nEpoch 272/300\n\u001b[1m610/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65195.6250\nEpoch 272: val_loss did not improve from 88431.30469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65361.9805 - val_loss: 88443.5547\nEpoch 273/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67750.8516\nEpoch 273: val_loss did not improve from 88431.30469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67841.9062 - val_loss: 88566.6328\nEpoch 274/300\n\u001b[1m611/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65997.8281\nEpoch 274: val_loss did not improve from 88431.30469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66127.2500 - val_loss: 88511.3750\nEpoch 275/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64055.2656\nEpoch 275: val_loss did not improve from 88431.30469\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64294.6289 - val_loss: 88554.7344\nEpoch 276/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64879.9688\nEpoch 276: val_loss improved from 88431.30469 to 88189.59375, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65123.8242 - val_loss: 88189.5938\nEpoch 277/300\n\u001b[1m616/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73456.0312\nEpoch 277: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73369.6953 - val_loss: 88238.0000\nEpoch 278/300\n\u001b[1m601/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65502.6406\nEpoch 278: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65730.5391 - val_loss: 88365.3516\nEpoch 279/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65021.4766\nEpoch 279: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65167.2656 - val_loss: 88328.0391\nEpoch 280/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69912.0000\nEpoch 280: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69879.9453 - val_loss: 88298.3672\nEpoch 281/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75019.7188\nEpoch 281: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74802.2422 - val_loss: 88583.3203\nEpoch 282/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71133.1250\nEpoch 282: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71085.2266 - val_loss: 88218.6172\nEpoch 283/300\n\u001b[1m607/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70902.0625\nEpoch 283: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70844.5625 - val_loss: 88298.4375\nEpoch 284/300\n\u001b[1m614/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68042.3516\nEpoch 284: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68092.3750 - val_loss: 88410.2266\nEpoch 285/300\n\u001b[1m623/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63743.1953\nEpoch 285: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63819.3359 - val_loss: 88193.1719\nEpoch 286/300\n\u001b[1m609/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68967.5625\nEpoch 286: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69002.7500 - val_loss: 88410.8516\nEpoch 287/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74754.1406\nEpoch 287: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74583.9375 - val_loss: 88212.2266\nEpoch 288/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64895.5664\nEpoch 288: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65084.3477 - val_loss: 88255.9766\nEpoch 289/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66431.2422\nEpoch 289: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66586.4297 - val_loss: 88355.8359\nEpoch 290/300\n\u001b[1m605/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67043.6484\nEpoch 290: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67138.6953 - val_loss: 88420.8672\nEpoch 291/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67580.1250\nEpoch 291: val_loss did not improve from 88189.59375\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67643.2109 - val_loss: 88205.3281\nEpoch 292/300\n\u001b[1m606/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76494.4062\nEpoch 292: val_loss improved from 88189.59375 to 88183.46094, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76214.5391 - val_loss: 88183.4609\nEpoch 293/300\n\u001b[1m608/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68521.8828\nEpoch 293: val_loss did not improve from 88183.46094\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68525.0547 - val_loss: 88253.3984\nEpoch 294/300\n\u001b[1m604/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63570.1641\nEpoch 294: val_loss improved from 88183.46094 to 88152.19531, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63758.8516 - val_loss: 88152.1953\nEpoch 295/300\n\u001b[1m593/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65751.5078\nEpoch 295: val_loss did not improve from 88152.19531\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65997.7266 - val_loss: 88259.8359\nEpoch 296/300\n\u001b[1m594/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64011.3438\nEpoch 296: val_loss improved from 88152.19531 to 87896.57812, saving model to training_1/chess_1.weights.h5\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64323.5195 - val_loss: 87896.5781\nEpoch 297/300\n\u001b[1m628/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68551.1484\nEpoch 297: val_loss did not improve from 87896.57812\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68554.0469 - val_loss: 88084.5000\nEpoch 298/300\n\u001b[1m612/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71555.3828\nEpoch 298: val_loss did not improve from 87896.57812\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71461.8359 - val_loss: 88080.9062\nEpoch 299/300\n\u001b[1m600/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73424.5156\nEpoch 299: val_loss did not improve from 87896.57812\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73224.0000 - val_loss: 88065.0078\nEpoch 300/300\n\u001b[1m621/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66622.0547\nEpoch 300: val_loss did not improve from 87896.57812\n\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66654.1953 - val_loss: 88125.7109\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"midgame_model = gen_train_eval_model(midgame_df, 2)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T12:18:04.063573Z","iopub.execute_input":"2024-07-29T12:18:04.064485Z","iopub.status.idle":"2024-07-29T12:22:17.653007Z","shell.execute_reply.started":"2024-07-29T12:18:04.064431Z","shell.execute_reply":"2024-07-29T12:22:17.652151Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":286,"outputs":[{"name":"stdout","text":"Epoch 1/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167143.6875\nEpoch 1: val_loss improved from inf to 162371.71875, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 167146.9219 - val_loss: 162371.7188\nEpoch 2/300\n\u001b[1m401/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 160441.6250\nEpoch 2: val_loss improved from 162371.71875 to 154369.10938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160376.6250 - val_loss: 154369.1094\nEpoch 3/300\n\u001b[1m393/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 160547.7500\nEpoch 3: val_loss improved from 154369.10938 to 150732.06250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159991.4219 - val_loss: 150732.0625\nEpoch 4/300\n\u001b[1m400/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 153815.1094\nEpoch 4: val_loss improved from 150732.06250 to 147581.89062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153489.1875 - val_loss: 147581.8906\nEpoch 5/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 145670.9375\nEpoch 5: val_loss improved from 147581.89062 to 144429.14062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145656.2500 - val_loss: 144429.1406\nEpoch 6/300\n\u001b[1m397/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137857.9219\nEpoch 6: val_loss improved from 144429.14062 to 141350.39062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138072.7969 - val_loss: 141350.3906\nEpoch 7/300\n\u001b[1m401/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137898.6250\nEpoch 7: val_loss improved from 141350.39062 to 138348.40625, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137899.9688 - val_loss: 138348.4062\nEpoch 8/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137323.8281\nEpoch 8: val_loss improved from 138348.40625 to 135366.07812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137316.6094 - val_loss: 135366.0781\nEpoch 9/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129659.1406\nEpoch 9: val_loss improved from 135366.07812 to 132405.82812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129781.9531 - val_loss: 132405.8281\nEpoch 10/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 126242.2578\nEpoch 10: val_loss improved from 132405.82812 to 129498.44531, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126267.7422 - val_loss: 129498.4453\nEpoch 11/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 126406.2031\nEpoch 11: val_loss improved from 129498.44531 to 126847.23438, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126384.4375 - val_loss: 126847.2344\nEpoch 12/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120037.6875\nEpoch 12: val_loss improved from 126847.23438 to 123865.28125, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120059.6172 - val_loss: 123865.2812\nEpoch 13/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116820.5312\nEpoch 13: val_loss improved from 123865.28125 to 121252.86719, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116895.0781 - val_loss: 121252.8672\nEpoch 14/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116629.2031\nEpoch 14: val_loss improved from 121252.86719 to 119000.16406, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116706.1719 - val_loss: 119000.1641\nEpoch 15/300\n\u001b[1m392/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112499.5391\nEpoch 15: val_loss improved from 119000.16406 to 116419.82812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112595.9219 - val_loss: 116419.8281\nEpoch 16/300\n\u001b[1m388/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108412.7266\nEpoch 16: val_loss improved from 116419.82812 to 114233.36719, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108688.8516 - val_loss: 114233.3672\nEpoch 17/300\n\u001b[1m407/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108938.4375\nEpoch 17: val_loss improved from 114233.36719 to 112358.35938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108957.3984 - val_loss: 112358.3594\nEpoch 18/300\n\u001b[1m395/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110406.9922\nEpoch 18: val_loss improved from 112358.35938 to 110096.19531, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110210.0547 - val_loss: 110096.1953\nEpoch 19/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107976.9219\nEpoch 19: val_loss improved from 110096.19531 to 108293.85938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107956.4609 - val_loss: 108293.8594\nEpoch 20/300\n\u001b[1m386/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106391.3281\nEpoch 20: val_loss improved from 108293.85938 to 106316.74219, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106105.8203 - val_loss: 106316.7422\nEpoch 21/300\n\u001b[1m393/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103287.0938\nEpoch 21: val_loss improved from 106316.74219 to 104731.50000, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103196.1953 - val_loss: 104731.5000\nEpoch 22/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101414.4766\nEpoch 22: val_loss improved from 104731.50000 to 102894.74219, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101407.9531 - val_loss: 102894.7422\nEpoch 23/300\n\u001b[1m393/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101004.5781\nEpoch 23: val_loss improved from 102894.74219 to 101884.32031, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100830.9141 - val_loss: 101884.3203\nEpoch 24/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 100235.8906\nEpoch 24: val_loss improved from 101884.32031 to 100184.41406, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100048.5078 - val_loss: 100184.4141\nEpoch 25/300\n\u001b[1m388/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101693.6328\nEpoch 25: val_loss improved from 100184.41406 to 98999.82812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101270.1797 - val_loss: 98999.8281\nEpoch 26/300\n\u001b[1m392/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98527.1484\nEpoch 26: val_loss improved from 98999.82812 to 97942.05469, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98246.8281 - val_loss: 97942.0547\nEpoch 27/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94524.6016\nEpoch 27: val_loss improved from 97942.05469 to 96702.74219, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94517.7891 - val_loss: 96702.7422\nEpoch 28/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97408.8516\nEpoch 28: val_loss improved from 96702.74219 to 95606.01562, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97037.6953 - val_loss: 95606.0156\nEpoch 29/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91195.3750\nEpoch 29: val_loss improved from 95606.01562 to 94544.06250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91195.0234 - val_loss: 94544.0625\nEpoch 30/300\n\u001b[1m408/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96838.8281\nEpoch 30: val_loss improved from 94544.06250 to 93837.64844, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96605.3359 - val_loss: 93837.6484\nEpoch 31/300\n\u001b[1m388/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88618.3828\nEpoch 31: val_loss improved from 93837.64844 to 92885.30469, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88716.7422 - val_loss: 92885.3047\nEpoch 32/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87458.7500\nEpoch 32: val_loss improved from 92885.30469 to 92032.60938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87589.4453 - val_loss: 92032.6094\nEpoch 33/300\n\u001b[1m388/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90229.9297\nEpoch 33: val_loss improved from 92032.60938 to 91346.08594, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90039.2422 - val_loss: 91346.0859\nEpoch 34/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89983.9453\nEpoch 34: val_loss improved from 91346.08594 to 90288.37500, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89769.9141 - val_loss: 90288.3750\nEpoch 35/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85209.2500\nEpoch 35: val_loss improved from 90288.37500 to 89605.77344, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85211.4062 - val_loss: 89605.7734\nEpoch 36/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87490.6484\nEpoch 36: val_loss improved from 89605.77344 to 89111.10938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87473.9766 - val_loss: 89111.1094\nEpoch 37/300\n\u001b[1m390/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82888.7188\nEpoch 37: val_loss improved from 89111.10938 to 88343.77344, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83003.2422 - val_loss: 88343.7734\nEpoch 38/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83820.8516\nEpoch 38: val_loss improved from 88343.77344 to 87953.12500, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83909.2500 - val_loss: 87953.1250\nEpoch 39/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81492.1875\nEpoch 39: val_loss improved from 87953.12500 to 87090.68750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81499.1016 - val_loss: 87090.6875\nEpoch 40/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82237.2734\nEpoch 40: val_loss did not improve from 87090.68750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82345.1484 - val_loss: 87494.7344\nEpoch 41/300\n\u001b[1m392/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81277.4844\nEpoch 41: val_loss improved from 87090.68750 to 86230.10156, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81359.8594 - val_loss: 86230.1016\nEpoch 42/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81456.5156\nEpoch 42: val_loss improved from 86230.10156 to 85669.72656, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81472.1328 - val_loss: 85669.7266\nEpoch 43/300\n\u001b[1m394/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80464.2188\nEpoch 43: val_loss improved from 85669.72656 to 85239.59375, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80604.3516 - val_loss: 85239.5938\nEpoch 44/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77874.1719\nEpoch 44: val_loss improved from 85239.59375 to 84729.67969, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77919.3438 - val_loss: 84729.6797\nEpoch 45/300\n\u001b[1m392/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78913.2031\nEpoch 45: val_loss improved from 84729.67969 to 84257.48438, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79028.7109 - val_loss: 84257.4844\nEpoch 46/300\n\u001b[1m390/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80636.7500\nEpoch 46: val_loss improved from 84257.48438 to 83643.82031, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80581.1250 - val_loss: 83643.8203\nEpoch 47/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79903.1016\nEpoch 47: val_loss did not improve from 83643.82031\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79893.7734 - val_loss: 83739.9141\nEpoch 48/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75140.5547\nEpoch 48: val_loss improved from 83643.82031 to 83260.82812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75203.1250 - val_loss: 83260.8281\nEpoch 49/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80845.2188\nEpoch 49: val_loss improved from 83260.82812 to 82617.86719, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80777.8750 - val_loss: 82617.8672\nEpoch 50/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80425.0469\nEpoch 50: val_loss improved from 82617.86719 to 82266.16406, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80366.3750 - val_loss: 82266.1641\nEpoch 51/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81731.3672\nEpoch 51: val_loss improved from 82266.16406 to 81906.27344, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81627.6172 - val_loss: 81906.2734\nEpoch 52/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78444.0312\nEpoch 52: val_loss did not improve from 81906.27344\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78423.9453 - val_loss: 82005.1250\nEpoch 53/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74656.7891\nEpoch 53: val_loss improved from 81906.27344 to 81483.06250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74719.2344 - val_loss: 81483.0625\nEpoch 54/300\n\u001b[1m399/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76592.7031\nEpoch 54: val_loss improved from 81483.06250 to 81297.32812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76621.8359 - val_loss: 81297.3281\nEpoch 55/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74626.0859\nEpoch 55: val_loss improved from 81297.32812 to 80777.74219, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74646.9609 - val_loss: 80777.7422\nEpoch 56/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76457.0000\nEpoch 56: val_loss improved from 80777.74219 to 80433.58594, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76457.7891 - val_loss: 80433.5859\nEpoch 57/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77086.1328\nEpoch 57: val_loss improved from 80433.58594 to 80132.52344, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77060.9844 - val_loss: 80132.5234\nEpoch 58/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74639.3594\nEpoch 58: val_loss improved from 80132.52344 to 79834.07031, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74654.7578 - val_loss: 79834.0703\nEpoch 59/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76229.9062\nEpoch 59: val_loss improved from 79834.07031 to 79419.80469, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76223.9219 - val_loss: 79419.8047\nEpoch 60/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75482.7109\nEpoch 60: val_loss improved from 79419.80469 to 78980.13281, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75464.5625 - val_loss: 78980.1328\nEpoch 61/300\n\u001b[1m408/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73763.0781\nEpoch 61: val_loss improved from 78980.13281 to 78746.21094, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73795.1172 - val_loss: 78746.2109\nEpoch 62/300\n\u001b[1m410/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75848.4062\nEpoch 62: val_loss improved from 78746.21094 to 78637.34375, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75768.0859 - val_loss: 78637.3438\nEpoch 63/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74625.8672\nEpoch 63: val_loss improved from 78637.34375 to 78305.03906, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74624.6328 - val_loss: 78305.0391\nEpoch 64/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71914.6328\nEpoch 64: val_loss improved from 78305.03906 to 78007.30469, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71950.1719 - val_loss: 78007.3047\nEpoch 65/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71484.7188\nEpoch 65: val_loss did not improve from 78007.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71536.8047 - val_loss: 78244.5469\nEpoch 66/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71397.9688\nEpoch 66: val_loss improved from 78007.30469 to 77976.43750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71431.8047 - val_loss: 77976.4375\nEpoch 67/300\n\u001b[1m395/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75333.4375\nEpoch 67: val_loss improved from 77976.43750 to 77639.07031, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75145.3125 - val_loss: 77639.0703\nEpoch 68/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70413.8203\nEpoch 68: val_loss did not improve from 77639.07031\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70444.2500 - val_loss: 77654.4766\nEpoch 69/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70083.0078\nEpoch 69: val_loss improved from 77639.07031 to 77143.13281, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70135.9531 - val_loss: 77143.1328\nEpoch 70/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70728.8203\nEpoch 70: val_loss improved from 77143.13281 to 77048.10938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70743.2266 - val_loss: 77048.1094\nEpoch 71/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70441.9844\nEpoch 71: val_loss improved from 77048.10938 to 76912.93750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70458.2812 - val_loss: 76912.9375\nEpoch 72/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70675.4531\nEpoch 72: val_loss improved from 76912.93750 to 76543.97656, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70687.4688 - val_loss: 76543.9766\nEpoch 73/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72342.9609\nEpoch 73: val_loss improved from 76543.97656 to 76406.06250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72308.8984 - val_loss: 76406.0625\nEpoch 74/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70512.8438\nEpoch 74: val_loss improved from 76406.06250 to 76224.35156, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70522.9141 - val_loss: 76224.3516\nEpoch 75/300\n\u001b[1m388/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73927.0391\nEpoch 75: val_loss improved from 76224.35156 to 75985.20312, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73592.0391 - val_loss: 75985.2031\nEpoch 76/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71271.1953\nEpoch 76: val_loss improved from 75985.20312 to 75861.64844, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71268.7500 - val_loss: 75861.6484\nEpoch 77/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 70796.7656\nEpoch 77: val_loss did not improve from 75861.64844\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70787.3438 - val_loss: 75901.1484\nEpoch 78/300\n\u001b[1m398/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71430.7109\nEpoch 78: val_loss improved from 75861.64844 to 75607.00781, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71359.8750 - val_loss: 75607.0078\nEpoch 79/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68690.5547\nEpoch 79: val_loss improved from 75607.00781 to 75547.37500, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68707.2656 - val_loss: 75547.3750\nEpoch 80/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69961.8516\nEpoch 80: val_loss improved from 75547.37500 to 75458.64062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69950.8906 - val_loss: 75458.6406\nEpoch 81/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67285.6719\nEpoch 81: val_loss improved from 75458.64062 to 74875.78906, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67335.5234 - val_loss: 74875.7891\nEpoch 82/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69935.4766\nEpoch 82: val_loss improved from 74875.78906 to 74847.57812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69929.5234 - val_loss: 74847.5781\nEpoch 83/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69537.4062\nEpoch 83: val_loss did not improve from 74847.57812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69534.2812 - val_loss: 74933.3516\nEpoch 84/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67236.8906\nEpoch 84: val_loss improved from 74847.57812 to 74560.25000, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67260.9141 - val_loss: 74560.2500\nEpoch 85/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68399.2969\nEpoch 85: val_loss improved from 74560.25000 to 74446.47656, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68409.8516 - val_loss: 74446.4766\nEpoch 86/300\n\u001b[1m402/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73397.5547\nEpoch 86: val_loss improved from 74446.47656 to 74108.42188, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73183.4453 - val_loss: 74108.4219\nEpoch 87/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69726.9375\nEpoch 87: val_loss did not improve from 74108.42188\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69715.8438 - val_loss: 74367.7734\nEpoch 88/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67499.9609\nEpoch 88: val_loss improved from 74108.42188 to 74094.69531, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67496.2422 - val_loss: 74094.6953\nEpoch 89/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66746.0312\nEpoch 89: val_loss improved from 74094.69531 to 73716.31250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66766.9062 - val_loss: 73716.3125\nEpoch 90/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66563.5078\nEpoch 90: val_loss improved from 73716.31250 to 73702.54688, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66623.1875 - val_loss: 73702.5469\nEpoch 91/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66735.3125\nEpoch 91: val_loss did not improve from 73702.54688\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66740.6875 - val_loss: 73829.2578\nEpoch 92/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65429.2500\nEpoch 92: val_loss improved from 73702.54688 to 73342.34375, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65468.4258 - val_loss: 73342.3438\nEpoch 93/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68391.8281\nEpoch 93: val_loss improved from 73342.34375 to 72949.82031, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68381.1953 - val_loss: 72949.8203\nEpoch 94/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66838.7891\nEpoch 94: val_loss did not improve from 72949.82031\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66864.9609 - val_loss: 73231.8672\nEpoch 95/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65919.0469\nEpoch 95: val_loss did not improve from 72949.82031\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65941.2656 - val_loss: 73011.2422\nEpoch 96/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66457.2422\nEpoch 96: val_loss did not improve from 72949.82031\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66461.1250 - val_loss: 73308.2500\nEpoch 97/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68633.3750\nEpoch 97: val_loss improved from 72949.82031 to 72603.43750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68622.8047 - val_loss: 72603.4375\nEpoch 98/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67475.3594\nEpoch 98: val_loss did not improve from 72603.43750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67398.5078 - val_loss: 72714.1641\nEpoch 99/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65544.8203\nEpoch 99: val_loss did not improve from 72603.43750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65603.5781 - val_loss: 72723.7578\nEpoch 100/300\n\u001b[1m387/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65200.1484\nEpoch 100: val_loss improved from 72603.43750 to 72354.14062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65357.3867 - val_loss: 72354.1406\nEpoch 101/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67145.0078\nEpoch 101: val_loss improved from 72354.14062 to 72114.59375, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67055.2969 - val_loss: 72114.5938\nEpoch 102/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64993.8906\nEpoch 102: val_loss did not improve from 72114.59375\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64996.4062 - val_loss: 72259.5703\nEpoch 103/300\n\u001b[1m386/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68027.7656\nEpoch 103: val_loss did not improve from 72114.59375\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67821.9062 - val_loss: 72167.1406\nEpoch 104/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67742.2891\nEpoch 104: val_loss improved from 72114.59375 to 71989.03906, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67739.3984 - val_loss: 71989.0391\nEpoch 105/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65363.7578\nEpoch 105: val_loss improved from 71989.03906 to 71593.18750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65447.9062 - val_loss: 71593.1875\nEpoch 106/300\n\u001b[1m387/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63457.3828\nEpoch 106: val_loss improved from 71593.18750 to 71459.92188, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63605.9922 - val_loss: 71459.9219\nEpoch 107/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63967.3906\nEpoch 107: val_loss did not improve from 71459.92188\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63993.7617 - val_loss: 71513.7734\nEpoch 108/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62956.5820\nEpoch 108: val_loss did not improve from 71459.92188\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62980.4609 - val_loss: 71714.3438\nEpoch 109/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63675.0586\nEpoch 109: val_loss improved from 71459.92188 to 71191.32812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63692.4023 - val_loss: 71191.3281\nEpoch 110/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64533.3867\nEpoch 110: val_loss improved from 71191.32812 to 71190.39062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64535.1250 - val_loss: 71190.3906\nEpoch 111/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62015.5898\nEpoch 111: val_loss did not improve from 71190.39062\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62049.5156 - val_loss: 71401.4375\nEpoch 112/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63051.8750\nEpoch 112: val_loss improved from 71190.39062 to 71006.87500, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63067.8320 - val_loss: 71006.8750\nEpoch 113/300\n\u001b[1m407/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62407.9531\nEpoch 113: val_loss improved from 71006.87500 to 70944.90625, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62523.5625 - val_loss: 70944.9062\nEpoch 114/300\n\u001b[1m394/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63192.3750\nEpoch 114: val_loss improved from 70944.90625 to 70860.12500, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63261.1797 - val_loss: 70860.1250\nEpoch 115/300\n\u001b[1m392/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64618.5352\nEpoch 115: val_loss improved from 70860.12500 to 70522.07812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64614.5898 - val_loss: 70522.0781\nEpoch 116/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65937.9922\nEpoch 116: val_loss did not improve from 70522.07812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65890.7891 - val_loss: 70670.3281\nEpoch 117/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62602.7422\nEpoch 117: val_loss did not improve from 70522.07812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62650.3633 - val_loss: 70735.3516\nEpoch 118/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62137.3867\nEpoch 118: val_loss did not improve from 70522.07812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62148.5742 - val_loss: 70557.5781\nEpoch 119/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62069.0547\nEpoch 119: val_loss did not improve from 70522.07812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62094.5977 - val_loss: 70704.0781\nEpoch 120/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63880.0234\nEpoch 120: val_loss improved from 70522.07812 to 70452.57812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63877.9531 - val_loss: 70452.5781\nEpoch 121/300\n\u001b[1m408/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61399.9883\nEpoch 121: val_loss did not improve from 70452.57812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61478.5508 - val_loss: 70500.7344\nEpoch 122/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61894.3867\nEpoch 122: val_loss improved from 70452.57812 to 70162.22656, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61921.3359 - val_loss: 70162.2266\nEpoch 123/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63264.0664\nEpoch 123: val_loss improved from 70162.22656 to 70028.03125, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63274.2305 - val_loss: 70028.0312\nEpoch 124/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59761.0352\nEpoch 124: val_loss improved from 70028.03125 to 69911.45312, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59864.2734 - val_loss: 69911.4531\nEpoch 125/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63641.2344\nEpoch 125: val_loss did not improve from 69911.45312\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63645.9375 - val_loss: 70040.6094\nEpoch 126/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64530.3086\nEpoch 126: val_loss did not improve from 69911.45312\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64499.5156 - val_loss: 70058.2109\nEpoch 127/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65971.0078\nEpoch 127: val_loss did not improve from 69911.45312\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65941.6406 - val_loss: 69971.3359\nEpoch 128/300\n\u001b[1m387/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68453.8125\nEpoch 128: val_loss did not improve from 69911.45312\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68053.6172 - val_loss: 69928.0469\nEpoch 129/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61374.1523\nEpoch 129: val_loss improved from 69911.45312 to 69629.75000, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61392.5820 - val_loss: 69629.7500\nEpoch 130/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60916.1367\nEpoch 130: val_loss did not improve from 69629.75000\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60919.7109 - val_loss: 69956.5156\nEpoch 131/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63802.7891\nEpoch 131: val_loss improved from 69629.75000 to 69599.81250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63797.5078 - val_loss: 69599.8125\nEpoch 132/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61503.1680\nEpoch 132: val_loss improved from 69599.81250 to 69570.81250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61518.5898 - val_loss: 69570.8125\nEpoch 133/300\n\u001b[1m403/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62679.9102\nEpoch 133: val_loss improved from 69570.81250 to 69412.36719, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62698.2070 - val_loss: 69412.3672\nEpoch 134/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60846.6445\nEpoch 134: val_loss improved from 69412.36719 to 69382.10938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60873.3633 - val_loss: 69382.1094\nEpoch 135/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59861.6367\nEpoch 135: val_loss did not improve from 69382.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59900.4336 - val_loss: 69568.8672\nEpoch 136/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60559.8789\nEpoch 136: val_loss improved from 69382.10938 to 69088.28906, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60581.5938 - val_loss: 69088.2891\nEpoch 137/300\n\u001b[1m410/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59347.3516\nEpoch 137: val_loss did not improve from 69088.28906\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59425.7930 - val_loss: 69369.3125\nEpoch 138/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61745.5625\nEpoch 138: val_loss did not improve from 69088.28906\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61747.6133 - val_loss: 69163.9844\nEpoch 139/300\n\u001b[1m406/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63073.8281\nEpoch 139: val_loss did not improve from 69088.28906\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63023.7695 - val_loss: 69196.6016\nEpoch 140/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60713.9102\nEpoch 140: val_loss did not improve from 69088.28906\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60733.5547 - val_loss: 69309.1719\nEpoch 141/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59202.6328\nEpoch 141: val_loss improved from 69088.28906 to 69027.39062, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59274.7344 - val_loss: 69027.3906\nEpoch 142/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62716.4961\nEpoch 142: val_loss improved from 69027.39062 to 68865.93750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62693.0938 - val_loss: 68865.9375\nEpoch 143/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62808.0391\nEpoch 143: val_loss did not improve from 68865.93750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62762.1680 - val_loss: 69053.0234\nEpoch 144/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59858.3984\nEpoch 144: val_loss did not improve from 68865.93750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59904.1719 - val_loss: 68961.3594\nEpoch 145/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62269.8945\nEpoch 145: val_loss improved from 68865.93750 to 68835.89844, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62253.1406 - val_loss: 68835.8984\nEpoch 146/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59709.3203\nEpoch 146: val_loss improved from 68835.89844 to 68407.66406, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59722.2930 - val_loss: 68407.6641\nEpoch 147/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62975.6953\nEpoch 147: val_loss did not improve from 68407.66406\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62968.3125 - val_loss: 68684.8359\nEpoch 148/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59472.6992\nEpoch 148: val_loss did not improve from 68407.66406\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59493.1328 - val_loss: 68625.6562\nEpoch 149/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61509.5391\nEpoch 149: val_loss did not improve from 68407.66406\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61500.3867 - val_loss: 68512.2031\nEpoch 150/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60376.6680\nEpoch 150: val_loss did not improve from 68407.66406\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60390.9062 - val_loss: 68493.5078\nEpoch 151/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58872.4492\nEpoch 151: val_loss did not improve from 68407.66406\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58884.2695 - val_loss: 68462.6719\nEpoch 152/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61376.7422\nEpoch 152: val_loss improved from 68407.66406 to 68248.63281, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61376.7188 - val_loss: 68248.6328\nEpoch 153/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58266.4766\nEpoch 153: val_loss did not improve from 68248.63281\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58324.9023 - val_loss: 68385.6484\nEpoch 154/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60881.1484\nEpoch 154: val_loss did not improve from 68248.63281\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60874.7852 - val_loss: 68794.1562\nEpoch 155/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60909.2461\nEpoch 155: val_loss did not improve from 68248.63281\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60902.0625 - val_loss: 68466.6797\nEpoch 156/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61497.5703\nEpoch 156: val_loss did not improve from 68248.63281\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61474.1289 - val_loss: 68373.4375\nEpoch 157/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61257.6680\nEpoch 157: val_loss improved from 68248.63281 to 68180.69531, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61229.7344 - val_loss: 68180.6953\nEpoch 158/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59654.3867\nEpoch 158: val_loss did not improve from 68180.69531\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59661.9375 - val_loss: 68264.9141\nEpoch 159/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59792.5273\nEpoch 159: val_loss did not improve from 68180.69531\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59787.3203 - val_loss: 68240.8047\nEpoch 160/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59394.5234\nEpoch 160: val_loss improved from 68180.69531 to 68145.00000, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59432.8711 - val_loss: 68145.0000\nEpoch 161/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62202.3398\nEpoch 161: val_loss did not improve from 68145.00000\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62178.1758 - val_loss: 68160.4219\nEpoch 162/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58611.4609\nEpoch 162: val_loss improved from 68145.00000 to 68066.23438, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58626.7422 - val_loss: 68066.2344\nEpoch 163/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58925.2578\nEpoch 163: val_loss did not improve from 68066.23438\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58941.7891 - val_loss: 68165.0312\nEpoch 164/300\n\u001b[1m396/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60926.1523\nEpoch 164: val_loss improved from 68066.23438 to 67941.53125, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60853.3438 - val_loss: 67941.5312\nEpoch 165/300\n\u001b[1m408/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59141.4219\nEpoch 165: val_loss improved from 67941.53125 to 67803.46875, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59134.5156 - val_loss: 67803.4688\nEpoch 166/300\n\u001b[1m409/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58816.9883\nEpoch 166: val_loss did not improve from 67803.46875\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58835.7930 - val_loss: 67960.3828\nEpoch 167/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58137.8750\nEpoch 167: val_loss did not improve from 67803.46875\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58183.3125 - val_loss: 67807.5781\nEpoch 168/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57398.5000\nEpoch 168: val_loss improved from 67803.46875 to 67760.29688, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57465.4531 - val_loss: 67760.2969\nEpoch 169/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57897.3750\nEpoch 169: val_loss did not improve from 67760.29688\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57927.9883 - val_loss: 67852.4453\nEpoch 170/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56684.2695\nEpoch 170: val_loss did not improve from 67760.29688\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56750.0977 - val_loss: 67871.2578\nEpoch 171/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57382.9922\nEpoch 171: val_loss improved from 67760.29688 to 67709.41406, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57404.6094 - val_loss: 67709.4141\nEpoch 172/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59939.7617\nEpoch 172: val_loss improved from 67709.41406 to 67495.33594, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59935.2109 - val_loss: 67495.3359\nEpoch 173/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59658.3320\nEpoch 173: val_loss did not improve from 67495.33594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59650.6406 - val_loss: 67507.8047\nEpoch 174/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56789.0391\nEpoch 174: val_loss did not improve from 67495.33594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56845.8711 - val_loss: 67521.7188\nEpoch 175/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58677.1445\nEpoch 175: val_loss did not improve from 67495.33594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58681.4375 - val_loss: 67544.5547\nEpoch 176/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56772.7148\nEpoch 176: val_loss did not improve from 67495.33594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56794.1484 - val_loss: 67537.6641\nEpoch 177/300\n\u001b[1m410/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59532.0195\nEpoch 177: val_loss improved from 67495.33594 to 67381.18750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59504.2812 - val_loss: 67381.1875\nEpoch 178/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55299.9414\nEpoch 178: val_loss did not improve from 67381.18750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55343.9844 - val_loss: 67449.7188\nEpoch 179/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56782.2539\nEpoch 179: val_loss improved from 67381.18750 to 67271.38281, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56800.9648 - val_loss: 67271.3828\nEpoch 180/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58338.8945\nEpoch 180: val_loss improved from 67271.38281 to 67152.68750, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58319.1758 - val_loss: 67152.6875\nEpoch 181/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58692.6523\nEpoch 181: val_loss did not improve from 67152.68750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58684.0352 - val_loss: 67284.7656\nEpoch 182/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59435.4336\nEpoch 182: val_loss did not improve from 67152.68750\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59403.9023 - val_loss: 67212.5547\nEpoch 183/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57112.9531\nEpoch 183: val_loss improved from 67152.68750 to 67136.26562, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57153.2578 - val_loss: 67136.2656\nEpoch 184/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57096.6719\nEpoch 184: val_loss improved from 67136.26562 to 67001.62500, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57123.6875 - val_loss: 67001.6250\nEpoch 185/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58788.3203\nEpoch 185: val_loss did not improve from 67001.62500\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58778.1523 - val_loss: 67031.6172\nEpoch 186/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58473.9219\nEpoch 186: val_loss did not improve from 67001.62500\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58470.9180 - val_loss: 67114.9219\nEpoch 187/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58576.1562\nEpoch 187: val_loss did not improve from 67001.62500\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58559.0352 - val_loss: 67084.8281\nEpoch 188/300\n\u001b[1m388/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56726.6836\nEpoch 188: val_loss improved from 67001.62500 to 66740.81250, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56809.9609 - val_loss: 66740.8125\nEpoch 189/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57886.7656\nEpoch 189: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57844.9883 - val_loss: 66951.3672\nEpoch 190/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56468.5977\nEpoch 190: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56499.9141 - val_loss: 66878.2891\nEpoch 191/300\n\u001b[1m409/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58760.0820\nEpoch 191: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58736.0664 - val_loss: 67270.9062\nEpoch 192/300\n\u001b[1m395/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58979.8672\nEpoch 192: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58905.0156 - val_loss: 66806.0938\nEpoch 193/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55501.3984\nEpoch 193: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55555.5312 - val_loss: 66748.3516\nEpoch 194/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56956.7852\nEpoch 194: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56959.4961 - val_loss: 66882.1250\nEpoch 195/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56427.4453\nEpoch 195: val_loss did not improve from 66740.81250\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56435.7422 - val_loss: 66952.9375\nEpoch 196/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56417.0859\nEpoch 196: val_loss improved from 66740.81250 to 66731.25000, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56537.5352 - val_loss: 66731.2500\nEpoch 197/300\n\u001b[1m389/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53631.8164\nEpoch 197: val_loss improved from 66731.25000 to 66721.51562, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53884.2188 - val_loss: 66721.5156\nEpoch 198/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55919.8438\nEpoch 198: val_loss improved from 66721.51562 to 66394.63281, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55922.0039 - val_loss: 66394.6328\nEpoch 199/300\n\u001b[1m390/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56743.8711\nEpoch 199: val_loss did not improve from 66394.63281\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56816.9414 - val_loss: 66683.4609\nEpoch 200/300\n\u001b[1m394/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56149.6328\nEpoch 200: val_loss improved from 66394.63281 to 66394.30469, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56237.5703 - val_loss: 66394.3047\nEpoch 201/300\n\u001b[1m403/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57129.7188\nEpoch 201: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57163.8281 - val_loss: 66480.4766\nEpoch 202/300\n\u001b[1m387/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56746.8633\nEpoch 202: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56829.2500 - val_loss: 66402.3828\nEpoch 203/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54821.2383\nEpoch 203: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54868.3242 - val_loss: 66658.9844\nEpoch 204/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58089.9492\nEpoch 204: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58080.4062 - val_loss: 66617.3594\nEpoch 205/300\n\u001b[1m384/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57335.1758\nEpoch 205: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57306.9219 - val_loss: 66635.8750\nEpoch 206/300\n\u001b[1m386/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58224.2812\nEpoch 206: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58054.8750 - val_loss: 66640.0391\nEpoch 207/300\n\u001b[1m403/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55068.3555\nEpoch 207: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55131.9922 - val_loss: 66606.0078\nEpoch 208/300\n\u001b[1m391/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55401.1484\nEpoch 208: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55469.0547 - val_loss: 66494.0156\nEpoch 209/300\n\u001b[1m409/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57011.3086\nEpoch 209: val_loss did not improve from 66394.30469\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57027.9688 - val_loss: 66528.1562\nEpoch 210/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56123.8398\nEpoch 210: val_loss improved from 66394.30469 to 66268.22656, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56129.1797 - val_loss: 66268.2266\nEpoch 211/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54011.1289\nEpoch 211: val_loss improved from 66268.22656 to 66177.39844, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54079.7305 - val_loss: 66177.3984\nEpoch 212/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54705.2617\nEpoch 212: val_loss improved from 66177.39844 to 65951.59375, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54765.0586 - val_loss: 65951.5938\nEpoch 213/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55273.0195\nEpoch 213: val_loss did not improve from 65951.59375\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55291.4766 - val_loss: 66117.2109\nEpoch 214/300\n\u001b[1m399/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55863.3047\nEpoch 214: val_loss did not improve from 65951.59375\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55890.7969 - val_loss: 66031.9844\nEpoch 215/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55898.4219\nEpoch 215: val_loss improved from 65951.59375 to 65686.22656, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55892.2383 - val_loss: 65686.2266\nEpoch 216/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55486.5977\nEpoch 216: val_loss did not improve from 65686.22656\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55504.1055 - val_loss: 65831.8750\nEpoch 217/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55331.1836\nEpoch 217: val_loss did not improve from 65686.22656\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55355.2969 - val_loss: 65786.7812\nEpoch 218/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57459.1055\nEpoch 218: val_loss did not improve from 65686.22656\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57453.2070 - val_loss: 66024.4062\nEpoch 219/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55867.9492\nEpoch 219: val_loss did not improve from 65686.22656\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55874.5586 - val_loss: 66142.6484\nEpoch 220/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60162.0586\nEpoch 220: val_loss did not improve from 65686.22656\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60153.1016 - val_loss: 65722.6016\nEpoch 221/300\n\u001b[1m386/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56421.8164\nEpoch 221: val_loss improved from 65686.22656 to 65655.10156, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56454.5273 - val_loss: 65655.1016\nEpoch 222/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53774.5000\nEpoch 222: val_loss improved from 65655.10156 to 65587.78125, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53814.6523 - val_loss: 65587.7812\nEpoch 223/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55139.0508\nEpoch 223: val_loss did not improve from 65587.78125\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55153.1680 - val_loss: 65605.0156\nEpoch 224/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53683.3516\nEpoch 224: val_loss did not improve from 65587.78125\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53694.1680 - val_loss: 65715.8438\nEpoch 225/300\n\u001b[1m390/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55219.4492\nEpoch 225: val_loss did not improve from 65587.78125\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55328.0469 - val_loss: 65612.0000\nEpoch 226/300\n\u001b[1m402/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52954.0273\nEpoch 226: val_loss did not improve from 65587.78125\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53056.8984 - val_loss: 65633.0234\nEpoch 227/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56319.5859\nEpoch 227: val_loss did not improve from 65587.78125\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56308.3789 - val_loss: 65592.5547\nEpoch 228/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54675.9961\nEpoch 228: val_loss improved from 65587.78125 to 65400.08984, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54673.1836 - val_loss: 65400.0898\nEpoch 229/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53855.9492\nEpoch 229: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53893.9180 - val_loss: 65412.2188\nEpoch 230/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54427.9297\nEpoch 230: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54447.0625 - val_loss: 65671.2109\nEpoch 231/300\n\u001b[1m394/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56161.3555\nEpoch 231: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56073.3086 - val_loss: 65408.4297\nEpoch 232/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52684.1797\nEpoch 232: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52730.5859 - val_loss: 65507.1406\nEpoch 233/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54026.8242\nEpoch 233: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54041.7383 - val_loss: 65858.7109\nEpoch 234/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56072.4922\nEpoch 234: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56053.0820 - val_loss: 65659.6094\nEpoch 235/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53692.4258\nEpoch 235: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53742.8164 - val_loss: 65605.3906\nEpoch 236/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54655.4219\nEpoch 236: val_loss did not improve from 65400.08984\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54658.0430 - val_loss: 65631.8047\nEpoch 237/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55382.1992\nEpoch 237: val_loss improved from 65400.08984 to 65344.57422, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55381.6250 - val_loss: 65344.5742\nEpoch 238/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55770.5234\nEpoch 238: val_loss improved from 65344.57422 to 65280.99219, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55770.3789 - val_loss: 65280.9922\nEpoch 239/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52190.8398\nEpoch 239: val_loss improved from 65280.99219 to 65238.29688, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52250.9258 - val_loss: 65238.2969\nEpoch 240/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53939.3047\nEpoch 240: val_loss did not improve from 65238.29688\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53954.9648 - val_loss: 65316.9414\nEpoch 241/300\n\u001b[1m407/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52754.5703\nEpoch 241: val_loss did not improve from 65238.29688\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52805.3281 - val_loss: 65282.6289\nEpoch 242/300\n\u001b[1m403/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52520.5898\nEpoch 242: val_loss improved from 65238.29688 to 65176.07812, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52633.0391 - val_loss: 65176.0781\nEpoch 243/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57281.2656\nEpoch 243: val_loss did not improve from 65176.07812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57251.5273 - val_loss: 65610.4219\nEpoch 244/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55296.0430\nEpoch 244: val_loss did not improve from 65176.07812\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55297.1445 - val_loss: 65341.7539\nEpoch 245/300\n\u001b[1m420/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53408.1328\nEpoch 245: val_loss improved from 65176.07812 to 65120.10938, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53417.8398 - val_loss: 65120.1094\nEpoch 246/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55006.1875\nEpoch 246: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54992.1016 - val_loss: 65191.2812\nEpoch 247/300\n\u001b[1m408/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53617.0664\nEpoch 247: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53653.0703 - val_loss: 65170.6367\nEpoch 248/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54188.2109\nEpoch 248: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54207.7109 - val_loss: 65156.6328\nEpoch 249/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57387.8242\nEpoch 249: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57374.7422 - val_loss: 65205.0820\nEpoch 250/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53245.8984\nEpoch 250: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53292.6133 - val_loss: 65126.4336\nEpoch 251/300\n\u001b[1m396/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55178.0742\nEpoch 251: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55158.7539 - val_loss: 65340.1992\nEpoch 252/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53901.0781\nEpoch 252: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53912.5391 - val_loss: 65361.3359\nEpoch 253/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57648.7500\nEpoch 253: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57634.5938 - val_loss: 65135.3555\nEpoch 254/300\n\u001b[1m422/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54279.2695\nEpoch 254: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54285.6523 - val_loss: 65140.9297\nEpoch 255/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55961.0234\nEpoch 255: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55937.1641 - val_loss: 65346.4258\nEpoch 256/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53255.1484\nEpoch 256: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53288.9375 - val_loss: 65482.9492\nEpoch 257/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57287.5000\nEpoch 257: val_loss did not improve from 65120.10938\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57233.3320 - val_loss: 65313.0117\nEpoch 258/300\n\u001b[1m413/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56138.0156\nEpoch 258: val_loss improved from 65120.10938 to 64944.08203, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56070.7617 - val_loss: 64944.0820\nEpoch 259/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53466.3672\nEpoch 259: val_loss improved from 64944.08203 to 64890.58594, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53480.2109 - val_loss: 64890.5859\nEpoch 260/300\n\u001b[1m414/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53617.4883\nEpoch 260: val_loss did not improve from 64890.58594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53636.0977 - val_loss: 64963.3867\nEpoch 261/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52394.4453\nEpoch 261: val_loss did not improve from 64890.58594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52413.7500 - val_loss: 64995.7969\nEpoch 262/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52291.6484\nEpoch 262: val_loss did not improve from 64890.58594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52318.6836 - val_loss: 64893.3438\nEpoch 263/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53336.9414\nEpoch 263: val_loss did not improve from 64890.58594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53332.5430 - val_loss: 64944.6992\nEpoch 264/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52844.3750\nEpoch 264: val_loss did not improve from 64890.58594\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52880.3633 - val_loss: 64931.4062\nEpoch 265/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53695.7344\nEpoch 265: val_loss improved from 64890.58594 to 64725.26562, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53694.1250 - val_loss: 64725.2656\nEpoch 266/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54550.7070\nEpoch 266: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54543.5586 - val_loss: 64739.3398\nEpoch 267/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53590.9492\nEpoch 267: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53599.0000 - val_loss: 65074.6680\nEpoch 268/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52617.1914\nEpoch 268: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52646.7773 - val_loss: 64933.6719\nEpoch 269/300\n\u001b[1m401/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52706.4961\nEpoch 269: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52743.3984 - val_loss: 65041.7461\nEpoch 270/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53683.4688\nEpoch 270: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53691.4766 - val_loss: 64827.6211\nEpoch 271/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56864.1250\nEpoch 271: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56822.9102 - val_loss: 64915.4688\nEpoch 272/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55473.6680\nEpoch 272: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55419.2305 - val_loss: 65000.2422\nEpoch 273/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51407.6953\nEpoch 273: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51463.0820 - val_loss: 64730.2969\nEpoch 274/300\n\u001b[1m417/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50953.0742\nEpoch 274: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51010.1992 - val_loss: 64845.8672\nEpoch 275/300\n\u001b[1m390/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51065.5898\nEpoch 275: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51318.5977 - val_loss: 64926.0547\nEpoch 276/300\n\u001b[1m421/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52990.4922\nEpoch 276: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52997.1406 - val_loss: 64830.0352\nEpoch 277/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52649.3438\nEpoch 277: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52678.3008 - val_loss: 64832.8906\nEpoch 278/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54634.9961\nEpoch 278: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54607.2617 - val_loss: 64847.3203\nEpoch 279/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51881.3281\nEpoch 279: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51912.9883 - val_loss: 64925.6133\nEpoch 280/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51404.0898\nEpoch 280: val_loss did not improve from 64725.26562\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51432.1992 - val_loss: 64919.3359\nEpoch 281/300\n\u001b[1m412/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56060.5781\nEpoch 281: val_loss improved from 64725.26562 to 64684.55078, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55970.3555 - val_loss: 64684.5508\nEpoch 282/300\n\u001b[1m409/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51751.5586\nEpoch 282: val_loss improved from 64684.55078 to 64584.39844, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51795.9688 - val_loss: 64584.3984\nEpoch 283/300\n\u001b[1m419/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51022.1680\nEpoch 283: val_loss did not improve from 64584.39844\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51057.4961 - val_loss: 64895.0000\nEpoch 284/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53365.9141\nEpoch 284: val_loss did not improve from 64584.39844\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53358.4570 - val_loss: 64718.4336\nEpoch 285/300\n\u001b[1m409/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49448.3672\nEpoch 285: val_loss improved from 64584.39844 to 64484.50391, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49546.7891 - val_loss: 64484.5039\nEpoch 286/300\n\u001b[1m410/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54032.6992\nEpoch 286: val_loss did not improve from 64484.50391\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54029.3047 - val_loss: 64579.8516\nEpoch 287/300\n\u001b[1m411/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52175.2852\nEpoch 287: val_loss did not improve from 64484.50391\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52186.0664 - val_loss: 64829.1641\nEpoch 288/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52717.1836\nEpoch 288: val_loss did not improve from 64484.50391\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52736.6367 - val_loss: 64691.2461\nEpoch 289/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53143.3516\nEpoch 289: val_loss did not improve from 64484.50391\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53129.0781 - val_loss: 64785.1211\nEpoch 290/300\n\u001b[1m406/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53666.1680\nEpoch 290: val_loss improved from 64484.50391 to 64456.74219, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53651.4258 - val_loss: 64456.7422\nEpoch 291/300\n\u001b[1m418/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50088.6367\nEpoch 291: val_loss did not improve from 64456.74219\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50132.3906 - val_loss: 64523.3086\nEpoch 292/300\n\u001b[1m416/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51382.6445\nEpoch 292: val_loss did not improve from 64456.74219\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51402.6602 - val_loss: 64664.7539\nEpoch 293/300\n\u001b[1m415/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51205.4180\nEpoch 293: val_loss did not improve from 64456.74219\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51243.0703 - val_loss: 64718.6797\nEpoch 294/300\n\u001b[1m423/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51309.0820\nEpoch 294: val_loss did not improve from 64456.74219\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51314.5195 - val_loss: 64461.4062\nEpoch 295/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51004.7852\nEpoch 295: val_loss improved from 64456.74219 to 64417.93359, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51007.7461 - val_loss: 64417.9336\nEpoch 296/300\n\u001b[1m387/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53267.0898\nEpoch 296: val_loss improved from 64417.93359 to 64401.22266, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53209.8320 - val_loss: 64401.2227\nEpoch 297/300\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50953.9336\nEpoch 297: val_loss improved from 64401.22266 to 64349.40625, saving model to training_1/chess_2.weights.h5\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50957.3750 - val_loss: 64349.4062\nEpoch 298/300\n\u001b[1m387/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52845.8320\nEpoch 298: val_loss did not improve from 64349.40625\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52805.5156 - val_loss: 64361.4531\nEpoch 299/300\n\u001b[1m390/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51066.6406\nEpoch 299: val_loss did not improve from 64349.40625\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51276.1680 - val_loss: 64458.0352\nEpoch 300/300\n\u001b[1m402/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51772.0742\nEpoch 300: val_loss did not improve from 64349.40625\n\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51846.8828 - val_loss: 64507.8516\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAG0CAYAAADehEiZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACGzklEQVR4nOzdd3hUVfrA8e+5M5PeAyEJCTWEUEMRUIooNgQWRSz8xAaKBevaV7FjYV1d+8oquJZVwAoisAoqiCDSO4QWUggkIb1ncs/vjyEDI0EmkDAp7+d5fMzce+6dc99MkpdTldZaI4QQQgjRDBmeroAQQgghhKdIIiSEEEKIZksSISGEEEI0W5IICSGEEKLZkkRICCGEEM2WJEJCCCGEaLYkERJCCCFEsyWJkBBCCCGaLUmEhBBCCNFsSSIkhGgSnn76aZRS/Pzzz56uSoOglOK888477fucd955KKVOv0JCNFCSCAlxhimlmsQflnbt2jmfRSmFzWYjPDycHj16cP311/P5559TUVHh6Wp6zLGxcee///znP56ushDNkpK9xoQ4s6qToMb+o9euXTv279/PvffeS0hICKZpUlBQwM6dO/nll18oLi6mU6dOfPLJJ/Tv37/e65OdnU12djZt2rTBz8+v3t/vZJ5++unjjr322mvk5+c7Y3asyy+/nF69etXZ++/YsQM/Pz/atGlzWvdJSUmhpKSEhISEOqqZEA2LJEJCnGFNLRHat28f7dq1czmXn5/PE088wZtvvklwcDC//fab/CHlz2MmhPAM6RoTogErLy/npZdeokePHvj5+REUFMSQIUOYM2dOjeXnzZvHBRdcQFRUFN7e3kRHRzN06FDeeecdl3J79+7l1ltvJS4uDl9fX8LCwujRowe33347hw8fPu16BwcH88Ybb3DDDTeQn5/Po48+6nL+z8ad/Oc//6mxq6hdu3a0a9eOgoIC7r//ftq1a4fNZnO2vJxojFD1WJns7GxuvfVWZ2y6devGBx98UGMdysvLefrpp+nQoQPe3t60b9+eKVOmUF5eXmdjb45VHY+KigqeffZZOnfujLe3NzfddBPgSCxffvllhg0bRkxMDF5eXrRs2ZLRo0ezcuXKGu9ZUz2PjdEXX3xB//798fPzIywsjHHjxpGenn7Cuh3r559/RinF008/zYYNGxg5ciQhISH4+fkxdOhQVqxYUWOdMjIymDBhAhEREfj6+tKrVy8+/PBDl/sJcaZZPV0BIUTNKioquOSSS1i6dCkJCQnceeedlJSU8MUXX3DNNdewYcMGXnjhBWf5f//739x2221ERkbyl7/8hRYtWpCZmcmmTZv44IMPmDx5MuD4Y9SvXz8KCgoYMWIEY8eOpaysjH379vHxxx9z1113ER4eXifP8OSTT/LRRx8xf/58CgoKCAoKOq37VVRUMGzYMHJycrj44osJCgqiffv2J70uLy+PQYMG4eXlxZVXXkl5eTmff/45EydOxDAMbrzxRmdZrTVjx47lu+++o1OnTtx1111UVlbyn//8h61bt55W/U9m7NixrF69mksvvZTLL7+ciIgIALZv387jjz/Oueeey8iRIwkNDSUlJYV58+axcOFCvv32W4YPH+72+7zzzjvMmzeP0aNHM3ToUFatWsXs2bPZuHEjGzZswNvb2637rFmzhr///e+cc8453HLLLaSkpPDll19ywQUXsGHDBjp37uwsm5mZyTnnnMP+/fs599xzGThwIAcPHmTy5MlcfPHFtQuUEHVJCyHOKEC786P3wgsvaEBfeumlurKy0nn80KFDum3bthrQv/76q/N4nz59tJeXlz506NBx98rKynJ+/cYbb2hAv/baa8eVKyoq0iUlJW49R3Ud9u3b96flYmJiNKB//PFH57GhQ4eeMAYffPCBBvQHH3xQ4/tdcMEFuqio6LjrnnrqKQ3on376yeV4dbxvvvlmbbfbnce3bt2qLRaL7tKli0v5jz76SAN6yJAhury83Hk8NzdXd+7cWQN66NChf/rMJ3KimFXHo0ePHi7fq2p5eXk1Hk9NTdVRUVE6ISHhuHM11bM6RoGBgXrTpk0u5/7v//5PA3r27Nk11u1YP/30kzOuf/w+vfvuuxrQd9xxh8vxiRMnakA//PDDLsc3bNigvby8NKCfeuqp455DiPomXWNCNFAzZ85EKcWrr76K1Xq08TYiIoInnngCgPfff9/lGqvVis1mO+5eLVq0OO6Yr6/vccf8/f1rPH46WrduDUBWVlad3O+VV17B39+/Vtf4+fnx6quvYrFYnMe6du3KoEGD2L59O0VFRc7jH374IQBTp07Fy8vLeTwkJMQZ9/ry3HPP1fi9Cg4OrvF4TEwMV155JTt27CAlJcXt97nnnnvo0aOHy7FJkyYB8Pvvv7t9n0GDBjm776pNnDgRq9Xqcp+Kigo+++wzgoODmTJlikv5xMREbrjhBrffU4i6JomQEA1QYWEhu3fvJjo6usZBxsOGDQNg/fr1zmPjx4+npKSErl278te//pVvvvmmxuRj9OjRBAQEcOeddzJ27Fj+/e9/s3Xr1nobvF1937pYMsDHx4eePXvW+rpOnTrV2C0XGxsLQG5urvPY+vXrMQyDgQMHHld+8ODBtX7v2viz2XW//vorV199NbGxsXh7ezun3b/55psANY7vOZGzzjrruGM1xeJU7mOz2WjVqpXLfXbu3ElpaSk9e/YkMDDwuGvqO65C/BkZIyREA5Sfnw9AVFRUjeerj+fl5TmP3X///bRo0YJ33nmHN954g9deew2lFEOHDuXll192/tFq27Ytv//+O08//TSLFi3iq6++Ahx/CB988EHuueeeOn2WAwcOANCyZcvTvldERMQpJVR/nKperbqlraqqynksPz+fsLAwl1a4aq1atar1e9dGZGRkjce//vprrrzySnx8fLjooovo2LEj/v7+GIbBzz//zNKlSykvL3f7fWqKR02xOJX7VN/rjzGFE8evvuMqxJ+RREiIBig4OBiAgwcP1ng+IyPDpVy1G264gRtuuIG8vDxWrFjB119/zcyZM7nkkkvYsWOHMxnp0qULs2fPxm63s3HjRhYvXsybb77Jvffei7+/PzfffHOdPMfu3btJS0vDarXSt29f53HDcDRG2+324xKOY5O7PzoTC1EGBQWRk5NTY90OHTpUr+99oud74okn8PLyYs2aNXTp0sXl3G233cbSpUvrtV6nq7o17kTxq++4CvFnpGtMiAYoMDCQjh07kp6ezq5du447/9NPPwHQp0+fGq8PCQlhxIgRvPfee9x0003k5OSwbNmy48pVJyiPPPIIn332GQDffPNNnT3Hs88+C8Bf/vIXly6R0NBQAFJTU4+7Zs2aNXX2/qeid+/emKZZ4xTw5cuXe6BGjoSya9euxyVBpml6rE61kZCQgK+vL5s2baKwsPC4843hGUTTJYmQEA3UxIkT0Vrz0EMPuXQzZGdn89xzzznLVPvpp59qHOeTmZkJ4Fxtee3atc6uimNV/6u8LlZlLigo4J577uHjjz8mJCSEl156yeV89ViY9957z+X4kiVLnAmZp1QP3J0yZYrLFiH5+fnOuJ9p7dq1Y9euXc5uRnCMvXr66afZtm2bR+pUG15eXlxzzTXk5+czdepUl3MbN27ko48+8lDNhJCuMSE85o+zbY71zjvv8OCDD7Jw4ULmzp1LYmIiI0aMoKSkhM8//5zMzEwefvhhl0GmY8aMISAggLPPPpt27dqhteaXX35h9erV9O3blwsvvBCAjz/+mOnTpzN48GA6duxIaGgoe/bs4dtvv8Xb25v77ruvVs/x2muvERISgtbaucXGsmXLKC4uJj4+nk8++YT4+HiXayZMmMDLL7/Miy++yMaNG+natStJSUksXLiQMWPG8OWXX9aqDnXphhtuYNasWSxatIju3bszevRoKisr+fLLL+nXrx87d+50du2dKX/961+5/fbb6d27N2PHjsVms/Hrr7+ybds2/vKXv/Dtt9+e0fqcipdeeokff/yRv//976xatYqBAweSkZHBnDlzGDFiBN98880Zj6sQIImQEB5TPU27Jq+99hp+fn788MMPvPrqq3z66ae8+eabWK1WEhMTee211/i///s/l2teeukl/ve//7Fu3ToWLFiAj48Pbdu2Zdq0adxxxx3OafX/93//R3l5OStWrGDt2rWUlpbSunVrxo0bxwMPPED37t1r9Ryvv/464OhmCwwMpHXr1owZM4bLLruM0aNHu0xBrxYREcHSpUt56KGHWLZsGUuXLuWss87ihx9+YN++fR5NhJRSfP3117zwwgt8/PHHvPnmm0RFRXHjjTcyefJkvvnmm9NeGLK2brvtNry9vXnttdf48MMP8fX1ZciQIXzwwQd8+eWXjSIRatWqFStWrOCxxx5jwYIFrFq1is6dO/POO+/g7+/vkbgKAbLXmBBCuO2HH37g4osv5tFHH+XFF1/0dHWajMcff5wXXniBRYsWcckll3i6OqKZkURICCH+4MCBA0RHR7scO3z4MBdffDHr1q1j1apVf7rmj6hZTXHdvHkzAwcOxMvLi/T0dHx8fDxUO9FcSdeYEEL8wf3338/GjRsZOHAgLVu2JC0tjYULF5KTk8Ntt90mSdApOuuss4iLi6N79+74+/uza9cuvvvuO0zTZPr06ZIECY+QREgIIf7giiuu4NChQ3z77bfk5eXh4+NDt27duPnmm+tsjaXm6LbbbuObb77hs88+o7CwkJCQEC655BIefPBBzjvvPE9XTzRT0jUmhBBCiGZL5ioKIYQQotmSREgIIYQQzZYkQkIIIYRotiQREkIIIUSzJbPG3JCbm4vdbq/z+7Zs2ZKsrKw6v29TJLGqHYmX+yRWtSPxcp/Eyn11HSur1erc3PmkZevsXZswu91OZWVlnd5TKeW8t0zc+3MSq9qReLlPYlU7Ei/3Sazc5+lYSdeYEEIIIZotSYSEEEII0WxJIiSEEEKIZksSISGEEEI0WzJYWgghRLNVXl5OeXl5vdy7tLSUioqKerl3U3OqsfL29sbb2/u03lsSISGEEM1ScXExSikCAwOdM5fqks1mq/MZx03VqcRKa01paSnFxcX4+/uf8ntL15gQQohmyW634+fnVy9JkKh/Sin8/PxOe50/SYSEEEI0S5IANQ2n+32UREgIIYQQzZYkQkIIIYRotiQREkIIIZqpAQMG8N5773n8Hp4ks8aEEEKIRuLKK6+ka9euPPvss3VyvwULFuDn51cn92qsJBHyAF1RjjnvM3IM0GNuACUNc0IIIeqG1pqqqiqs1pP/iQ8PDz8DNWrY5C+wJygD/b+vKF74FZSVero2QgghcCQQurzszP/n5o7r9913HytXrmTGjBm0bt2a1q1bk5qayooVK2jdujU//vgjw4cPp3379vz+++8kJyczYcIEEhMT6dSpEyNGjGDZsmUu9/xjt1br1q359NNPufnmm+nYsSODBg3i+++/r1Uc09PTmTBhAp06daJz587cdtttZGVlOc9v3bqVK6+8kvj4eDp37szw4cPZsGEDAGlpadx444107dqVuLg4zj//fJYsWVKr968taRHyAGWzgdUKdjuUloDvqS8EJYQQoo5UlGPedXWd3c7d9aqNt+aAt89Jyz377LPs3buXhIQEHnzwQcDRopOamgrACy+8wJNPPkmbNm0IDg7mwIEDDBs2jEceeQQvLy+++OILJkyYwLJly2jduvUJ3+fVV19lypQpTJkyhQ8++IC77rqLVatWERoaetI6mqbJhAkT8Pf358svv8Rut/P4449zxx138MUXXwBw9913061bN1566SUMw2Dr1q3O1qvHHnuMyspKvvzyS/z8/EhKSjqtxRLdIYmQp/j4QVGBtAgJIYRwS1BQEF5eXvj4+BAREXHc+Yceeohzzz3X+To0NJRu3bo5Xz/88MMsWrSI77//ngkTJpzwfa6++mouv/xyAB599FFmzJjBhg0bOP/8809ax+XLl7Njxw5WrlzpTLZef/11zj//fDZs2ECvXr1IT0/n9ttvJy4uDoAOHTo4V5Y+cOAAI0aMoEuXLgC0bdv25IE5TZIIeYqvvyMRKin2dE2EEEIAeHk7WmfqiNvbRnid3l5Z1Xr27Onyuri4mFdeeYUlS5aQmZmJ3W6nrKyM9PT0P71PdRIC4OfnR2BgINnZ2W7VYdeuXURHR7u0OMXHxxMcHMyuXbvo1asXt956Kw899BBffvklQ4YMYdSoUXTq1AmAiRMn8re//Y2lS5cyZMgQRowYQdeuXd0NwSmRMUKe4usLgC4r8XBFhBBCgGOFYuXtc+b/q6MVrv84++vZZ59l0aJFPProo3z11Vd8//33JCQknHRzU5vNdlxcTNOskzoCPPDAA/z4449ccMEF/Prrr5x//vl89913AFx77bWsWLGCsWPHsmPHDkaMGMHMmTPr7L1rIomQp/gc+cCWSteYEEII99hsNreTkjVr1nDVVVdx6aWX0qVLFyIiIkhLS6vX+nXq1IkDBw64tDolJSWRn59PfHy881jHjh259dZb+eyzz7j00kuZNWuW81zr1q254YYbeP/997ntttv49NNP67XOkgh5iPI7MvhLWoSEEEK4KTY2lvXr15OamkpOTs6fJkXt27dn4cKFbNmyha1bt3LnnXfWactOTYYMGUJCQgJ33303mzdvZv369dx7772cc845JCYmUlpayuOPP86KFStIS0tj9erVbNy40dk19uSTT/Lzzz+TkpLC5s2b+fXXX51jieqLJEKe4uPoGqNUxggJIYRwz2233YZhGJx33nn06NHjT8f7PPXUUwQHB3PZZZdx0003Oa+pT0opPvjgA4KDg7niiisYN24cbdq04V//+hcAFouF3Nxc7r33XoYMGcLtt9/O+eefz8MPPww4Zp09/vjjnHfeeYwfP54OHTrwwgsv1G+dtbsLGDRjWVlZ7g14qwXz03fRPy1AjboG47LxdXrvpkYpRVRUFBkZGW6vt9GcSbzcJ7GqnaYWr4KCAoKCgurt/m4PlhanFauavo82m42WLVu6db20CHlK9RghmT4vhBBCeIwkQh6ifI8kQjJ9XgghhPAYSYQ8pToRksHSQgghhMdIIuQpMn1eCCGE8DhJhDzlyP5isqCiEEII4TmSCHmI8pXp80IIIYSnSSLkKb7SNSaEEEJ4miRCnuIrK0sLIYQQniaJkAeUVFZx/29FTB7wMFUVFeiqKk9XSQghhGiWJBHyAG+LwZ78Sg76tqDY6iOLKgohhDhjBgwYwHvvvXfC8/fddx8TJ048gzXyLEmEPMBiKHxtjtAXWf2ke0wIIYTwEEmEPCTAyxH6YqsvlEoiJIQQQniCtbYXbNu2jXnz5rFv3z5yc3N58MEH6d+/v0uZtLQ0/vvf/7Jt2zZM0yQmJoYHHniAFi1aAFBRUcFHH33EihUrqKysJDExkVtuuYWQkBDnPbKzs3nvvffYunUrPj4+DB06lGuvvRaLxeIss3XrVj766CNSU1MJDw9n7NixnHfeeS51WbRoEd9++y15eXm0bduWiRMnEhcXV9vHrnP+NgtZ2B1dY5IICSGEx2mtKa+qu81kqzCptJsnLedtUSilTlruk08+4dVXX2XNmjUYxtF2jAkTJhAaGsqrr75KcnIyzzzzDOvWraOkpIROnTrx6KOPcu65557yc5SXlzN16lTmzp1LUVERPXv25Omnn6ZXr14A5OXlMWXKFJYuXUpJSQmRkZHcc889XHPNNVRUVPDMM8+wYMEC8vPzadGiBddffz133333KdenrtU6ESovL6ddu3YMGzaMf/zjH8edP3jwIE8++STDhg3j6quvxtfXl7S0NGw2m7PMhx9+yLp167j//vvx8/NjxowZvPLKKzz33HMAmKbJiy++SEhICFOnTiU3N5e33noLi8XCtddeC0BmZiYvvfQSF110EXfffTdbtmzh3XffJSQkxPnNWbFiBR999BGTJk2iU6dOfPfddzz//PO89tprBAcHn0q86kyAlyOhk64xIYRoGMqrNNfMTjrj7zv7mnh8rCdPhEaNGsUTTzzBr7/+ypAhQwDIzc3l559/5qOPPgKguLiYYcOG8cgjj+Dl5cUXX3zBhAkTWLZsGa1btz6l+j3//PMsWLCA1157jZiYGN555x3Gjx/P8uXLCQ0N5eWXXyYpKYlPPvmEsLAw9u3bR1lZGQAzZ87k+++/591336V169YcOHCAAwcOnFI96kutE6HevXvTu3fvE56fNWsWvXv35rrrrnMei4yMdH5dUlLCjz/+yL333kv37t0BmDx5Mn/9619JSkoiPj6ejRs3kpaWxhNPPEFISAjt2rXjmmuu4b///S9XX301VquV77//noiICG644QYAYmJi2LFjB999950zEZo/fz4XXHAB559/PgCTJk1i3bp1/PTTT1x++eW1ffQ6FeB9pGvM5osuLeHkPwJCCCGas5CQEM4//3y++eYbZyL03XffERYWxqBBgwDo1q0b3bp1c17z8MMPs2jRIr7//nsmTJhQ6/csKSnho48+4p///CfDhg0D4OWXX+bss89m1qxZ3HHHHaSnp9O9e3cSExMBiI2NdV6fnp5O+/bt6d+/P0opYmJiTvn560utE6E/Y5om69atY/To0Tz//PPs27ePiIgILr/8cmf32d69e6mqqqJHjx7O61q3bk2LFi2ciVBSUhJt2rRx6Srr1asX77//PqmpqbRv355du3a53AMgMTGR//znPwDY7Xb27t3rkvAYhkGPHj1ISqo546+srKSystL5WimF75EVoN1ptqyNAC9H6Iusvqiykjq/f1NSHRuJkXskXu6TWNVOU4+Xt0Ux+5r4OrufzWqj0l550nLeFvfjOWbMGB5++GFeeOEFvL29+frrrxk9erSzq6y4uJhXXnmFJUuWkJmZid1up6ysjPT09FN6huTkZCorK+nXr5/zmM1mo1evXuzatQuAG264gUmTJrF582aGDh3KJZdc4ix/9dVXM27cOIYMGcL555/PhRdeyNChQ0+pLn/mdD6TdZoIFRQUUFZWxty5c7nmmmsYP348GzZs4JVXXuGpp56ia9eu5OXlYbVa8ff3d7k2ODiYvLw8wNHfeGwSVH2++lz1///YvRUcHExpaSkVFRUUFRVhmuZx9wkJCTlhs9zXX3/NF1984Xzdvn17pk2bRsuWLWsZiZOLCCkC8ii2+hBosxIUFVXn79HUHNuyKE5O4uU+iVXtNJV4lZaWugzbAPCq4/fwsXnX6f1GjBjBQw89xM8//0zv3r1ZtWoVU6dOdT7H1KlTWbp0KU8//TTt27fHx8eHm2++maqqKmcZpRQWi+W4Z69mGAZKKWw2G1arI02wWq0u5ZVSGIaBzWbjkksuYd26dSxevJilS5cybtw4JkyYwDPPPEOfPn1Yu3YtS5YsYdmyZdx+++2ce+65zJw587j3PVF9TsbLy4uo0/gbWuctQgBnnXUWo0aNAqBdu3bs3LmT77//nq5du9bl29W5MWPGOOsNRzPMrKws7HZ7nb6Xsjv6T4utfhRkHqI4I6NO79+UKKWIjIzk4MGDaF13AxmbKomX+yRWtdPU4lVRUeHSC1DXbDZbnd/fYrFw6aWX8sUXX7Bnzx46duxIly5dnO/z+++/c9VVV3HxxRcDjhai1NRUqqqqnGW01i6v/8g0TbTWVFZWEhMTg5eXFytXrnQmwJWVlaxfv55JkyY57xEcHMzYsWMZO3Ys/fr1Y+rUqUyZMgUAHx8fRo4cyciRI7n00ksZP348mZmZhIaG1kmsKioqyPjD31Cr1ep2I0adJkJBQUFYLJbj+gBbt27Nzp07AUeLjN1up7i42KVVKD8/39l6ExISwu7du13ukZ+f7zxX/f/qY8eW8fX1xcvLi6CgIAzDcLYgVauptamazWY7YUZa1z/0/l7V6wj5QnFuk/ilUt+01hKnWpB4uU9iVTsSL88aM2YMN910Ezt37uSKK65wOde+fXsWLlzIRRddhFKKl19+2dlIcSr8/Py4/vrrmTp1KiEhIbRu3Zp33nmHsrIyxo0bBzjGDPXs2ZP4+HgqKipYvHgxnTp1AmD69Om0atWK7t27o5Ri/vz5RERE1PmEpdP5PNZpImS1WunYseNxXU8ZGRnOqfMdOnTAYrGwefNmzj77bAAOHDhAdnY28fGOvtn4+Hi++uor8vPzncHatGkTvr6+ziSrU6dOrF+/3uV9Nm3a5LyH1WqlQ4cObNmyxTk+yTRNtmzZwvDhw+vysU+Jv80xa6zY5gvFKR6ujRBCiMZi8ODBhISEsGfPHsaMGeNy7qmnnuL+++/nsssuIywsjDvvvJOioqLTer/HHnsMrTX33HMPxcXF9OzZk//+97/ORgWbzcaLL75IamoqPj4+DBgwgHfeeQeAgIAA3nnnHfbt24fFYiExMZGPP/7YZfq/p9U6ESorK+PgwYPO15mZmSQnJxMQEECLFi0YPXo0//znP+nSpQvdu3dnw4YNrF27lqeffhpwZJfDhg3jo48+IiAgAD8/P2bOnEl8fLwziUlMTCQmJoa33nqL8ePHk5eXx6xZs7jkkkucLTYXX3wx//vf//jkk084//zz2bJlCytXruTRRx911m3UqFG8/fbbdOjQgbi4OBYsWEB5eflxaw15wrELKuqiAg/XRgghRGNhGAbr1q2r8VxsbCyff/65y7GbbrrJ5fWqVav+9P6vvfaay2sfHx+ee+455xI3f3Tfffdx33331Xhu/PjxjB8//k/fz9OUrmV70tatW3nmmWeOOz506FDuvPNOAH788Ue++eYbDh8+THR0NFdffbXLiPPqBRV//fVX7HZ7jQsqZmVl8f7777N161a8vb0ZOnQo48ePP25BxQ8//JC0tLQ/XVBx3rx55OXl0a5dOyZMmOBssnNXVlZWnffz7sgu5ZH/7adV6WH+lfE5lideq9P7NyVKKaKiosjIyJDmeDdIvNwnsaqdphavgoICgoKC6u3+9TFGqKk6nVjV9H202WxujxGqdSLUHNVHIpRWUMGd3+4loLKEj7a/hWXa8SPohUNT++Vb3yRe7pNY1U5Ti5ckQg2HJxOhhtNJ18z426q7xnwwCwubxC8VIYQQorGRRMhDArwdXXxaGZSaCirKPVwjIYQQovmRRMhDvCwG3taj22wgA6aFEEKIM04SIQ8K8D66zYYkQkIIceadzho7wvPq4vsniZAHBfk4EqFiqy8U5p+ktBBCiLrk5+dHYWGhJEONlGmaFBYW4ufnd1r3qdMFFUXtBHo71kSqXkuoaW5jKIQQDVP1vpenu+DgiXh5eVFRUVEv925qTjVW/v7+zv3QTpUkQh5U3SIkXWNCCOEZVqu1XqbQN7WlBuqTp2MlXWMe5BwjZPOFwkIP10YIIYRofiQR8qAgH0fXWIm0CAkhhBAeIYmQB4X4ORKhXK9AdJEMlhZCCCHONEmEPCgmxBeAg77h0iIkhBBCeIAkQh4UeyQRyvBtAYWSCAkhhBBnmiRCHhQb6lj7IMc7mLKSUg/XRgghhGh+JBHyoGBfG4E2x+pBGaY3Whb1EkIIIc4oSYQ8LCrQC4CD3qFQXD+LegkhhBCiZpIIeVh0sDcAGX4tICfLw7URQgghmhdJhDysukUow7cFZB/ycG2EEEKI5kUSIQ+LPiYR0oclERJCCCHOJEmEPKw6ETrg2wKyMz1cGyGEEKJ5kUTIw6KCHIlQnncQJdmHPVwbIYQQonmRRMjDArwshFgdu+2mFds9XBshhBCieZFEqAFoE+jYhT6lworW2sO1EUIIIZoPSYQagDYtAgBI9ZY9x4QQQogzSRKhBqBNqGPPsRT/SBkwLYQQQpxBkgg1AG2CHQOmU/1aoWUtISGEEOKMkUSoAYgNcawufdgnhOIsWV1aCCGEOFMkEWoAArwshKsKAFIPF3u4NkIIIUTzIYlQAxHr7dh5PqVIptALIYQQZ4okQg1E9TihlAqbh2sihBBCNB+SCDUQsRHBAKRagtD2Sg/XRgghhGgeJBFqINpGhQKOmWMyhV4IIYQ4MyQRaiCqZ47legdRmJHh4doIIYQQzYMkQg2En81CC7MEgJSDuR6ujRBCCNE8SCLUgLSxlgOQklvm4ZoIIYQQzYMkQg1IG3/HtyOlxMMVEUIIIZoJSYQakDZhfgCkmj4erokQQgjRPEgi1IC0iQ4HIMUWijarPFwbIYQQoumTRKgBiYlpCUCBVwD5B2UKvRBCCFHfJBFqQHy9bLSqyAcgJVU2XxVCCCHqmyRCDUwsjk1XU7IKPFwTIYQQoumTRKiBaePtGBuUUiibrwohhBD1TRKhBiY2yLHpamqF1cM1EUIIIZo+SYQamLatHJuvpqgAtNYero0QQgjRtEki1MDExERgaJMiiw85JbILvRBCCFGfJBFqYLxatqJV6WEAUg8c9nBthBBCiKZNEqEGRlmtxNqPTKHPyPFwbYQQQoimTRKhBqiNxbHp6v7cUg/XRAghhGjaaj01adu2bcybN499+/aRm5vLgw8+SP/+/Wss++9//5vFixdz4403MnLkSOfxoqIiZs6cydq1a1FKMWDAACZMmICPz9E9tvbv38+MGTPYs2cPQUFBDB8+nMsuu8zl/itXrmT27NlkZWURGRnJ+PHj6dOnj/O81po5c+awZMkSiouLSUhI4JZbbiEqKqq2j31GVW++mloig6WFEEKI+lTrFqHy8nLatWvHzTff/Kflfv/9d3bt2kVoaOhx59544w1SU1OZMmUKjz76KNu3b2f69OnO8yUlJUydOpUWLVrw0ksvcd111/H555+zePFiZ5mdO3fy+uuvM2zYMKZNm0a/fv14+eWXSUlJcZaZO3cuCxcuZNKkSbzwwgt4e3vz/PPPU1FRUdvHPqPahPkCkFrlIzPHhBBCiHpU60Sod+/ejBs37oStQAA5OTnMnDmTe+65B6vVtdEpLS2NDRs2cPvtt9OpUycSEhKYOHEiK1asICfHMSZm+fLl2O12Jk+eTGxsLIMGDeLSSy9l/vz5zvssWLCAXr16MXr0aGJiYhg3bhwdOnRg0aJFgKM1aMGCBVxxxRX069ePtm3bctddd5Gbm8vq1atr+9hnVOvWERi6ihJl43CpLKwohBBC1Jc6X7XPNE3efPNNRo8eTWxs7HHnk5KS8Pf3p2PHjs5jPXr0QCnF7t276d+/P0lJSXTp0sUliUpMTGTu3LkUFRUREBBAUlISo0aNcrl3YmKiM8nJzMwkLy+Pnj17Os/7+fkRFxdHUlISgwYNOq5ulZWVVFYenbKulMLX19f5dV2qvl9N9/WKaUPUb9tI929FSk4ZLf296vS9G5s/i5U4nsTLfRKr2pF4uU9i5T5Px6rOE6G5c+disVi49NJLazyfl5dHUFCQyzGLxUJAQAB5eXnOMhERES5lQkJCnOeqywYHB7uUCQ4OdrlH9bETlfmjr7/+mi+++ML5un379kybNo2WLVue6HFPW2Rk5HHHdKtWtClbSrp/Kw4XlBEV1bne3r8xqSlW4sQkXu6TWNWOxMt9Eiv3eSpWdZoI7d27lwULFjBt2rRGmQWPGTPGpZWp+hmysrKw2+u2i0opRWRkJAcPHqxxHFCsUcZKYPu+DDIyIo6/QTNyslgJVxIv90msakfi5T6JlfvqI1ZWq9XtRow6TYS2b99OQUEBkydPdh4zTZOPPvqIBQsW8PbbbxMSEkJBgevO6lVVVRQVFTlbfUJCQo5rtal+fWyZ/Px8lzL5+fku56uPHTtgOz8/n3bt2tVYf5vNhs1mq/FcfX2QtdY13ruNnyMJSym0yw/RESeKlaiZxMt9EqvakXi5T2LlPk/Fqk4ToXPPPZcePXq4HHv++ec599xzOf/88wGIj4+nuLiYvXv30qFDBwC2bNmC1pq4uDhnmc8++wy73e4cJ7Rp0yaio6MJCAhwltm8ebPLtPxNmzbRqVMnACIiIggJCWHz5s3OxKekpITdu3dz8cUX1+Vj14s24X5QBKl2L0ytMRphC5sQQgjR0NV61lhZWRnJyckkJycDjkHJycnJZGdnExgYSJs2bVz+s1qthISEEB0dDUBMTAy9evVi+vTp7N69mx07djBz5kwGDhxIWFgYAIMHD8ZqtfLuu++SmprKihUrWLhwoUu31YgRI9i4cSPffvst6enpzJkzhz179jB8+HDA0dQ2YsQIvvrqK9asWUNKSgpvvfUWoaGh9OvX73TjVu+iW0dgNe2UKStZxbLnmBBCCFEfat0itGfPHp555hnn648++giAoUOHcuedd7p1j3vuuYcZM2bw7LPPOhdUnDhxovO8n58fU6ZMYcaMGTz66KMEBgYyduxYLrzwQmeZzp07c8899zBr1iw+++wzoqKieOihh2jTpo2zzGWXXUZ5eTnTp0+npKSEhIQEHnvsMby8Gv4sLGtUDK3X7mF/QDTJueW0Cmj4dRZCCCEaG6Wl8/KksrKyXKbV1wWlFFFRUWRkZNTYJ6orK3n1zS9Y1qo34+P9uLpfmxru0jycLFbClcTLfRKr2pF4uU9i5b76iJXNZnN7sLTsNdZAKZuNthQBsD+r0MO1EUIIIZomSYQasLZHZo4lF1Z5uCZCCCFE0ySJUAPWNtwPgAN2G5VVpodrI4QQQjQ9kgg1YOFREQRUlmCiSM1v2BvFCiGEEI2RJEINmBEVQ5vigwAk55V7uDZCCCFE0yOJUEMWFUPbogwA9mcXebgyQgghRNMjiVADpvwCaGs6tiORmWNCCCFE3ZNEqIFr6xgvLTPHhBBCiHogiVAD17aFPwC5VRYKyiUZEkIIIeqSJEINnG9kNK1KDwOwP6/Mw7URQgghmhZJhBo4dezMsVyZOSaEEELUJUmEGrrIY2aO5ZZ6uDJCCCFE0yKJUEMXGk7bihwAkrOLPVwZIYQQommRRKiBU0rR1s+xG29qYRWm7GIshBBC1BlJhBqB6BbB2MxKyrTiUFGlp6sjhBBCNBmSCDUClqjWxBRnArLVhhBCCFGXJBFqBFRkDO2KjwyYlkRICCGEqDOSCDUGUbG0KXJMod+fK2sJCSGEEHVFEqHGoGUkbUsPAZCcU+LhygghhBBNhyRCjYCyWmnr45gtdrC4inK76eEaCSGEEE2DJEKNREhEGEEVRZgoUvMrPF0dIYQQokmQRKiRMCJjaHtkwHSy7DkmhBBC1AlJhBqLqNije47JzDEhhBCiTkgi1EioyBjaHdlzbJ9sviqEEELUCUmEGouo1nQsTANg7+FS2WpDCCGEqAOSCDUSysePGC8Tm1lJiV3LVhtCCCFEHZBEqBGxRkY5u8f25MiAaSGEEOJ0SSLUiKioWDoUpgOSCAkhhBB1QRKhxiQqhg5FkggJIYQQdUUSoUZERbVxaRHSMmBaCCGEOC2SCDUm0W1oU3wQq2mnqMIks1gGTAshhBCnQxKhRkQFBmELCKB1SSYA+2VhRSGEEOK0SCLU2ETF0vbICtOSCAkhhBCnRxKhRkZFt6FNkSRCQgghRF2QRKixiZYWISGEEKKuSCLUyKjoNs5d6NMLKqiskpljQgghxKmSRKixiYolvDwfP3spVRrSC6RVSAghhDhVkgg1NoHBqIAg2kj3mBBCCHHaJBFqZJRS0KYjbWXAtBBCCHHaJBFqhFTbjs5xQvtyJRESQgghTpUkQo2QahtHR9lqQwghhDhtkgg1RkdahCxmFfnlVWSX2D1dIyGEEKJRkkSoMQqPwMvXl9iSQwDslp3ohRBCiFMiiVAjpJSCth3pWJgGwJ7DkggJIYQQp0ISoUZKHZsISYuQEEIIcUokEWqkjh0wvVsGTAshhBCnRBKhxqrN0QHTBeVVZBXLgGkhhBCitqy1vWDbtm3MmzePffv2kZuby4MPPkj//v0BsNvtzJo1i/Xr15OZmYmfnx89evTg2muvJSwszHmPoqIiZs6cydq1a1FKMWDAACZMmICPj4+zzP79+5kxYwZ79uwhKCiI4cOHc9lll7nUZeXKlcyePZusrCwiIyMZP348ffr0cZ7XWjNnzhyWLFlCcXExCQkJ3HLLLURFRdU6UA1Oi1Z4+fjQrugAe4Ji2ZFdSkSAzdO1EkIIIRqVWrcIlZeX065dO26++ebjzlVUVLBv3z7Gjh3LtGnTeOCBBzhw4AB///vfXcq98cYbpKamMmXKFB599FG2b9/O9OnTnedLSkqYOnUqLVq04KWXXuK6667j888/Z/Hixc4yO3fu5PXXX2fYsGFMmzaNfv368fLLL5OSkuIsM3fuXBYuXMikSZN44YUX8Pb25vnnn6eioqK2j93gVA+YTihIBmB7VolnKySEEEI0QrVuEerduze9e/eu8Zyfnx9PPPGEy7GJEyfy2GOPkZ2dTYsWLUhLS2PDhg28+OKLdOzY0VnmxRdf5PrrrycsLIzly5djt9uZPHkyVquV2NhYkpOTmT9/PhdeeCEACxYsoFevXowePRqAcePGsXnzZhYtWsStt96K1poFCxZwxRVX0K9fPwDuuusuJk2axOrVqxk0aNBx9a+srKSystL5WimFr6+v8+u6VH2/07mvahtHl7VJfBczhO1ZpXVex4aiLmLVnEi83Cexqh2Jl/skVu7zdKxqnQjVVklJCUop/Pz8AEhKSsLf39+ZBAH06NEDpRS7d++mf//+JCUl0aVLF6zWo9VLTExk7ty5FBUVERAQQFJSEqNGjXJ5r8TERFavXg1AZmYmeXl59OzZ03nez8+PuLg4kpKSakyEvv76a7744gvn6/bt2zNt2jRatmxZN8GoQWRk5ClfW9LrLBJ+/B5w7DkWGNaSAO96/5Z6zOnEqjmSeLlPYlU7Ei/3Sazc56lY1etfzYqKCv773/8yaNAgZyKUl5dHUFCQSzmLxUJAQAB5eXnOMhERES5lQkJCnOeqywYHB7uUCQ4OdrlH9bETlfmjMWPGuCRX1dlpVlYWdnvdDkZWShEZGcnBgwdPecaXDgonrKKQVqWHOeQbzrIt++gdHVCn9WwI6iJWzYnEy30Sq9qReLlPYuW++oiV1Wp1uxGj3hIhu93OP//5TwBuueWW+nqbOmWz2bDZah5wXF8fZK31qSdCLVqBnz8J+ckc8g1na2YJvaL867iGDcfpxKo5kni5T2JVOxIv90ms3OepWNXL9PnqJCg7O5spU6Y4W4PA0bJTUFDgUr6qqoqioiJnq09ISMhxrTbVr48tk5+f71ImPz/f5Xz1sROVaewcA6bjSMhPBmBndqlnKySEEEI0MnWeCFUnQQcPHuSJJ54gMDDQ5Xx8fDzFxcXs3bvXeWzLli1orYmLi3OW2b59u0t31KZNm4iOjiYgIMBZZvPmzS733rRpE506dQIgIiKCkJAQlzIlJSXs3r2b+Pj4un1oD1LtOhF3zArT8i8PIYQQwn21ToTKyspITk4mOTkZcAxKTk5OJjs7G7vdzquvvsrevXu5++67MU2TvLw88vLynElNTEwMvXr1Yvr06ezevZsdO3Ywc+ZMBg4c6FxraPDgwVitVt59911SU1NZsWIFCxcudBm/M2LECDZu3Mi3335Leno6c+bMYc+ePQwfPhxwtJaMGDGCr776ijVr1pCSksJbb71FaGiocxZZU6Dax9Om+CBWXUVRhcmhosqTXySEEEIIAJSuZRPC1q1beeaZZ447PnToUK666iruuuuuGq976qmn6NatG+BYUHHGjBkuCypOnDjxhAsqBgYGMnz4cC6//HKXe65cuZJZs2aRlZVFVFTUCRdUXLx4MSUlJSQkJHDzzTcTHR1dm0cmKyvLZVp9XVBKERUVRUZGxmm14ujcw5gPT+ChPnezJyiWhwZHM7ht0MkvbETqKlbNhcTLfRKr2pF4uU9i5b76iJXNZnN7sHStE6HmqCEnQgBVD93E9JZD+V/rc7iiaxg39o44+UWNiPxCqR2Jl/skVrUj8XKfxMp9nk6EZK+xpqBdJ+dO9LsPy070QgghhLskEWoC1DGJ0J6cMkz514cQQgjhFkmEmgDVtiOxJYfwMu0UV5ocKGz8e6kJIYQQZ4IkQk1BTHus2qRjYSoA2zNlPSEhhBDCHZIINQXBoRAYTJe8fQBsk53ohRBCCLdIItQEKKUgtgNd8x2LVG6TFiEhhBDCLZIINREqtj0J+fsx0BwsquRwiSysKIQQQpyMJEJNRWx7/KrKaVtxGICt0iokhBBCnJQkQk2EatMBgK6HdwGwLVPGCQkhhBAnI4lQU9EqGry86HY4CYCNByUREkIIIU5GEqEmQhkWaBNHj9w9GGgOFFZwqEjWExJCCCH+jCRCTYjqmIB/VRmddR4A6w4Ue7ZCQgghRAMniVATouK6ANA7ewcA6zMkERJCCCH+jCRCTUnHBAB6pawGYNPBEuym7DsmhBBCnIgkQk2ICgyGVq3pUJhOkEVTajfZlS3T6IUQQogTkUSoiVEdEzDQdCEPgO1ZkggJIYQQJyKJUFNzZJxQ51zHdhvbpUVICCGEOCFJhJoYdWScUJfkNQDsyCpFaxknJIQQQtREEqGmJjIG/ALokJuMlwEF5VWkF8p6QkIIIURNJBFqYpRhQMcEbLqKOIujW2yHjBMSQgghaiSJUBNU3T2WUJwGyAasQgghxIlIItQEVS+s2C1tPQAbM4plnJAQQghRA0mEmqJ2ncAw6Ja2AS8DDpfaSc4r93SthBBCiAZHEqEmSHn7QNs4vEw7Pb0d3WJr02W7DSGEEOKPJBFqolTXXgD0zd8FwJoDRR6sjRBCCNEwSSLURFUnQr13LgVgZ3YpheVVHqyREEII0fBIItRUdegM3j5EHE4l1k9hath0SLrHhBBCiGNJItREKasN4rsDkGhmA7Axo8STVRJCCCEaHEmEmjDVNRGAHplbAWkREkIIIf5IEqEmTMV1BaBb0goMBRmFlWQWVXq4VkIIIUTDIYlQUxbTDmxe+BXlEB/k+FZLq5AQQghxlCRCTZiy2qBNBwB6qHwA1mdIIiSEEEJUk0SoiVMdOgPQN8+xntDa9GIqqkxPVkkIIYRoMCQRauKqE6G4vasJ97NSajelVUgIIYQ4QhKhpq69IxEy0pMZGO0HwIr9hZ6skRBCCNFgSCLU1IW1gJAwqKpioOFYT+j39CIqpXtMCCGEkESoqVNKobr0AiB+3xrCfK2UVJpsPiSLKwohhBCSCDUDqudZjv9vXkPfaH8A1h2QcUJCCCGEJELNQdfeYBhwMI0+AY4FFddKIiSEEEJIItQcKD9/OLLKdI+DW7AoOFBYwcHCCg/XTAghhPAsSYSaieruMb8Nv5LQ0heQViEhhBBCEqFmQp01GJSCnZvpE+SYMbYipcDDtRJCCCE8SxKhZkKFR0C3PgAMSVmB1YAtmaVsOiitQkIIIZovSYSaEWPoJQC0WLGQizsEAfDJxmy01p6slhBCCOExkgg1Jz36QXAYFBVwpe0gXhbFzuxStmeVerpmQgghhEdIItSMKIsF1aMvAKG71jMwNhCAVWlFnqyWEEII4THW2l6wbds25s2bx759+8jNzeXBBx+kf//+zvNaa+bMmcOSJUsoLi4mISGBW265haioKGeZoqIiZs6cydq1a1FKMWDAACZMmICPj4+zzP79+5kxYwZ79uwhKCiI4cOHc9lll7nUZeXKlcyePZusrCwiIyMZP348ffr0qVVdmp2uvWD5D+jtG+h/zlX8nFzAqrRCburdEqWUp2snhBBCnFG1bhEqLy+nXbt23HzzzTWenzt3LgsXLmTSpEm88MILeHt78/zzz1NRcXTNmjfeeIPU1FSmTJnCo48+yvbt25k+fbrzfElJCVOnTqVFixa89NJLXHfddXz++ecsXrzYWWbnzp28/vrrDBs2jGnTptGvXz9efvllUlJSalWX5kYlJDpmj6Xvp7dfBVZDkVFYSVpB842JEEKI5qvWiVDv3r0ZN26cSytQNa01CxYs4IorrqBfv360bduWu+66i9zcXFavXg1AWloaGzZs4Pbbb6dTp04kJCQwceJEVqxYQU5ODgDLly/HbrczefJkYmNjGTRoEJdeeinz5893vteCBQvo1asXo0ePJiYmhnHjxtGhQwcWLVrkdl2aIxUYBLEdAPDZtZmerRw70kv3mBBCiOao1l1jfyYzM5O8vDx69uzpPObn50dcXBxJSUkMGjSIpKQk/P396dixo7NMjx49UEqxe/du+vfvT1JSEl26dMFqPVq9xMRE5s6dS1FREQEBASQlJTFq1CiX909MTHQmOe7U5Y8qKyuprKx0vlZK4evr6/y6LlXfzxPdUaprL3TKHtiylgHn9WZdRjHLkgu4slt4g+we82SsGiOJl/skVrUj8XKfxMp9no5VnSZCeXl5AAQHB7scDw4Odp7Ly8sjKCjI5bzFYiEgIMClTEREhEuZkJAQ57nqsid7n5PV5Y++/vprvvjiC+fr9u3bM23aNFq2bHmiRz5tkZGR9XbvEym/6C9kLvoSvW4Fl098gA/WZ7I/r5z0Sh/6tQ074/Vxlydi1ZhJvNwnsaodiZf7JFbu81Ss6jQRauzGjBnj0spUnZ1mZWVht9vr9L2UUkRGRnLw4MEzv45PcDgqoSd6xyZKZk9nWKcxLEjKZeavu4nxij2zdXGDR2PVCEm83Cexqh2Jl/skVu6rj1hZrVa3GzHqNBGqbrXJz88nNDTUeTw/P5927do5yxQUuG7tUFVVRVFRkfP6kJCQ41ptql8fWyY/P9+lTH5+vsv5k9Xlj2w2GzabrcZz9fVB1lp75IdEjboGvWMT+pfvGXnuGBYkwZr0IlLzyogJ9j7j9XGHp2LVWEm83Cexqh2Jl/skVu7zVKzqdB2hiIgIQkJC2Lx5s/NYSUkJu3fvJj4+HoD4+HiKi4vZu3evs8yWLVvQWhMXF+css337dpdWmE2bNhEdHU1AQICzzLHvU12mU6dObtelWYvvDnFdwG4neu1iBsQ44vr5lsMerpgQQghx5tQ6ESorKyM5OZnk5GTAMSg5OTmZ7OxslFKMGDGCr776ijVr1pCSksJbb71FaGgo/fr1AyAmJoZevXoxffp0du/ezY4dO5g5cyYDBw4kLMwxPmXw4MFYrVbeffddUlNTWbFiBQsXLnTpthoxYgQbN27k22+/JT09nTlz5rBnzx6GDx8O4FZdmjOlFGrYXwDQSxdxVUIIAMv2F3BAptILIYRoJpSuZTvU1q1beeaZZ447PnToUO68807nIoaLFy+mpKSEhIQEbr75ZqKjo51li4qKmDFjhsuCihMnTjzhgoqBgYEMHz6cyy+/3OU9V65cyaxZs8jKyiIqKuqECyr+WV3ckZWV5TKbrC4opYiKiiIjI8Njzababsf82y2Ql4O6+X6eL+3ImgPFDOsQzL3nNJxFJxtCrBoTiZf7JFa1I/Fyn8TKffURK5vN5vYYoVonQs1RU02EAMz5s9BzP4W2cey6bSqPfJ+C1VDMHNORYJ+GMZa+ocSqsZB4uU9iVTsSL/dJrNzn6URI9hpr5tTQS8HLG/bvpvPB7XQK98Fuan7YnX/yi4UQQohGThKhZk4FBqOGOsZVmd/NZkSnEAAW7sqlypR/xQghhGjaJBESqIvHgNUGe3YwyDxIkLeF7BI7K1IKPV01IYQQol5JIiRQIWGo3mcDYNuympGdHesufb71MKb0bQshhGjCJBESDj3OAkBvWsOo+FB8rQb788pZnS6bsQohhGi6JBESAKjufUApSNuHf3Hu0VahLYdlxoMQQogmSxIhATgGTdPeseK23rKG0QmheFkUuw6XseFgiYdrJ4QQQtQPSYSEkzqmeyzYx8rwIzPI5mzO9mCthBBCiPojiZBwUj0diRDbN6IrK7i8SxhWQ7Etq5TfUmUGmRBCiKZHEiFxVGwHCA6DinLYuYVwPxujExxjhd78LYOs4rpdXVsIIYTwNEmEhJNSCtWjLwB6y1oAru3Zkk7hPhRVmLzxmywVL4QQommRREi4ODpOaDVaa2wWxQODorEZik0HS1h7oNjDNRRCCCHqjiRCwlXXRLBYIesgbFkHQFSgF6OOTKf/z/pM2XpDCCFEkyGJkHChfPxQfQcBYL49FXP1LwBc2T2cQC+D1PwKFu3K82ANhRBCiLojiZA4jrrpblT/oVBVhf78A7RpEuBl4drElgB8sjGL3FK7h2sphBBCnD5JhMRxlM0LdeNd4O0LudmwLwmAS+JCiAvzoaTS5N9rDsnAaSGEEI2eJEKiRsrLG5XYDwC9bgUAFkNxR/9IDAUrUgqli0wIIUSjJ4mQOCHVdyAAeu0KZ+tPXLgPN/Z2dJG9vzaTlLxyj9VPCCGEOF2SCIkT694XvH3gcCbmc/ehd2wC4LKEMPpG+2M3NbNk+w0hhBCNmCRC4oSUlzfqwtGOXelT92G+9w+03Y5Siht6OVqFVqQUSquQEEKIRksSIfGnjMuvw/jHhxAYDAV5cGTF6XahPpwTG4jGMYtMBk4LIYRojCQREielgkJQ5wwDwFz+g/P4uB7hGApWpRXJwGkhhBCNkiRCwi1q8EWOLzavQeflAI5WoeousvfXZrIhQ7bfEEII0bhIIiTcoqJiIK4rmCb6u9nO45d3CeOc2ADspua5n9NYnVbkwVoKIYQQtSOJkHCbcfl1AOil/0OnpwCOHesfGBTN2UeSoX/8eoBDRRWerKYQQgjhNkmEhNtU5+7Q+2zQJuZ/XkeXOFp/bBaDhwe3pmtLX8rsJm/8dhBTBk8LIYRoBCQRErViXDkB/PwheRfmPx5HlzjGBVkMxT3nROFtUWw5VMLUn9MoKJP9yIQQQjRskgiJWlERURgPvuCYTp+6Dz1/lvNcVKAX954Thc1QrD1QzJM/pmI3pWVICCFEwyWJkKg1FdseY+JfAdA/fofOzHCeG9Q2iH8Mb0ugt4V9ueXMXHuIJ5ekMEdWoBZCCNEASSIkTonq3ge69oYqO+ZXH7qcO3Za/XdJeWw8WMJnm7PJKq70RFWFEEKIE5JESJwy46oJju031q5Ap+x1OXdhx2ASWvgCYDMUpob/yaKLQgghGhhJhMQpUzHtUP2GAGDO+9TlnKEUTw+L5YUL2/DXgVEAfL8nj8oqGTMkhBCi4ZBESJwWNWocKAM2/o5O3uVyztdm0K2VHwNiAwnztZJfVsXnW2WskBBCiIZDEiFxWlRUDGrAUADMeZ/VWMZqKK7t2QKA2ZsPM3d7zhmrnxBCCPFnJBESp0395RowDMc+ZHt21FjmorgQ/q+HIxmauS6Td38/KFPrhRBCeJwkQuK0qYjoo7vTf/kftFlVY7lreoRzfWJLFLBwVx7Tfkmnoso8gzUVQgghXEkiJOqEGnUNeHnDrm3orz/BXPY/dFqyaxmluLJ7OI+e2xqbofg9rYjnfkqjtFKSISGEEJ4hiZCoE6pFK9S1twOgF32J/vhtzDefQ5vHJzlnxwby1LAYfKwGmw6V8OSSFIoqam5FEkIIIeqTJEKizqiBw1BDLnbMIrNYICcL9iXVWLZHK3+euyCWQC+DpMNlTPslHbupqZJxQ0IIIc4gSYREnVFKoa6/E+NfX6L6DARAr195wvLxLXx59oI2jpahgyVcOyeJ8Z/v4ruduWeqykIIIZo5SYREnVJKoSwWVN8jidCqZVS9MuWEU+s7hPnw0OBoDAXlVZpSu8m/1xxituxNJoQQ4gyweroCoonq1gdsXpB3GPIOo3duRvcbgoqKOa7oWa0DeGNke8rtmjXpRXy2OZtPN2XTKsDGee2DPVB5IYQQzYW0CIl6oXx8UX3OcbzwCwCt0f/76oTlY4O9iQv3YVzPFlzZLRyAt1cdZFVq4ZmorhBCiGZKEiFRb9QNd2E8/RbGPU8CoH/7Gb3xd3RhPrqs5ITXjU9sQb/WAVRUaV5Yls7rKw5QVG6nytSYWgZTCyGEqDvSNSbqjfLyhtZtHC8694CdmzHfmup4bRgYdz+J6t7nuOsMpXhkSDSfbsrm6205LNmbz6rpKyirtBMT5M0zw2IJ8ZWPrhBCiNMnLULijDBuewR14WjwD3QcME3Mz6ajKytrLG+zGNzYO4IXL2pDZICNonI7dhOS88p5fHEKWw6VSOuQEEKI0yaJkDgjVGAQxjW3YPzzE4zXP4PgUMjMQC+Z96fXdYnw481RHXjv//ow7ZK2hPtZSSuo4PHFKTy4aD/5ZfYz9ARCCCGaojrvXzBNkzlz5vDLL7+Ql5dHWFgYQ4cOZezYsSilANBaM2fOHJYsWUJxcTEJCQnccsstREVFOe9TVFTEzJkzWbt2LUopBgwYwIQJE/Dx8XGW2b9/PzNmzGDPnj0EBQUxfPhwLrvsMpf6rFy5ktmzZ5OVlUVkZCTjx4+nT5/ju2PEmaGUAj9/1BU3oD94HT33v+j28ajOPU54jbfVoFdUCBmWUl66qC2zt2Tz6/5C9uSU8cTiVJ44P4aW/rYz+BRCCCGaijpvEfrmm2/44YcfuPnmm/nnP//J+PHjmTdvHgsXLnSWmTt3LgsXLmTSpEm88MILeHt78/zzz1NRUeEs88Ybb5CamsqUKVN49NFH2b59O9OnT3eeLykpYerUqbRo0YKXXnqJ6667js8//5zFixc7y+zcuZPXX3+dYcOGMW3aNPr168fLL79MSkpKXT+2qCV19vnQ5xyw2zHffv6Eu9b/UUSAjbvPjuIfl7Yl1NfK/vxy7pq/j7nbc2RVaiGEELVW54lQUlISZ511Fn369CEiIoKzzz6bnj17snv3bsDRGrRgwQKuuOIK+vXrR9u2bbnrrrvIzc1l9erVAKSlpbFhwwZuv/12OnXqREJCAhMnTmTFihXk5OQAsHz5cux2O5MnTyY2NpZBgwZx6aWXMn/+fGddFixYQK9evRg9ejQxMTGMGzeODh06sGjRorp+bFFLyjAwbnkA4rtBaQnmPx7D/O1nt6+PCfLmxYvakNDClzK7ycx1mTywKJltmSeejSaEEEL8UZ13jcXHx7NkyRIOHDhAdHQ0ycnJ7Ny5kxtuuAGAzMxM8vLy6Nmzp/MaPz8/4uLiSEpKYtCgQSQlJeHv70/Hjh2dZXr06IFSit27d9O/f3+SkpLo0qULVuvRR0hMTGTu3LkUFRUREBBAUlISo0aNcqlfYmKiM+H6o8rKSiqPGbyrlMLX19f5dV2qvl9d37cxUV7eqHuewpzxKnr9b+iZ/0TbvDDOGuRa7gSxig7y5qVL2rJ4Tz4frstkX245f/shhaHtgpg8IApfW/McAiefLfdJrGpH4uU+iZX7PB2rOk+ELr/8ckpLS/nrX/+KYRiYpsm4ceMYMmQIAHl5eQAEB7uuGBwcHOw8l5eXR1BQkMt5i8VCQECAS5mIiAiXMiEhIc5z1WX/7H3+6Ouvv+aLL75wvm7fvj3Tpk2jZcuW7j5+rUVGRtbbvRsL/ewb5L79IsWLvsZ8/x+06NwF7/hux5U7UaxujI5mdN+OvLt8L99sOsDS5AIOFJv8Y0wPooN967v6DZZ8ttwnsaodiZf7JFbu81Ss6jwRWrlyJcuXL+eee+4hNjaW5ORk/vOf/xAaGsp5551X129Xp8aMGePSglSdnWZlZWG31+3sJKUUkZGRHDx4EC3TwNFX3Ig6eAC9YRVZs2ZimfSg85y7sbqpRzADIm28uDSNXVlFXPfh7zw4OJreUQFn4hEaDPlsuU9iVTsSL/dJrNxXH7GyWq1uN2LUeSL0ySefcNlllzFokKN7o02bNmRlZfHNN99w3nnnOVtt8vPzCQ0NdV6Xn59Pu3btAEfLTkFBgct9q6qqKCoqcl4fEhJyXMtO9etjy+Tn57uUyc/Pd57/I5vNhs1W8+yj+voga63lhwRAGagRV6E3rEKvX4lZUgxe3iiLxVnEnVgltPDllUvb8cLSdPbklPHUklQSWvjSt7U/faICiAv3+dPrmxL5bLlPYlU7Ei/3Sazc56lY1fkgivLycgzD9baGYTgfLiIigpCQEDZv3uw8X1JSwu7du4mPjwcc44yKi4vZu3evs8yWLVvQWhMXF+css337dpeWmk2bNhEdHU1AQICzzLHvU12mU6dOdfjEos606wSRMVBRgTntEczJY6macgfmj/NPfu0xWvjZePGiNlzaKQSrATuyS/nvxmweWJTM6ysPkFdqx9SarOJKmWkmhBDNXJ0nQn379uWrr75i3bp1ZGZm8vvvvzN//nz69esHOJrARowYwVdffcWaNWtISUnhrbfeIjQ01FkmJiaGXr16MX36dHbv3s2OHTuYOXMmAwcOJCwsDIDBgwdjtVp59913SU1NZcWKFSxcuNCla2vEiBFs3LiRb7/9lvT0dObMmcOePXsYPnx4XT+2qANKKdTAYY4X6fvBNOFQOuan0yldtaxW9/K2GtzeP5L3Lo/j5r4RnB0bgAJ+3FvA5G/3cue3e7nlmz3c890+VqQUyL/YhBCimVK6jv8ClJaWMnv2bH7//Xfy8/MJCwtj0KBBXHnllc4ZXtULKi5evJiSkhISEhK4+eabiY6Odt6nqKiIGTNmuCyoOHHixBMuqBgYGMjw4cO5/PLLXeqzcuVKZs2aRVZWFlFRUae0oGJWVpbLbLK6oJQiKiqKjIwM+SN8DJ17GPOJyeDlhTHxPscmrT8vxAgORT3xmmNF6lO0M7uU6asPsSen7LhzfaP9iQv3oX2IjyNpasQzPeSz5T6JVe1IvNwnsXJffcTKZrO5PUaozhOhpkgSoTNL5+eCtzfKxw9dWYn5/AOQngytojHufRrV8tRnFlSZmqXJBZTbTfrHBLBoVx5fbcvBfkwX2ZXdwrkusUWjTYbks+U+iVXtSLzcJ7Fyn6cTIdnCWzQ46phWH2WzYZn8N3j9aaoOHcCcej/qosvg0AGIbY9x8eW1urfFUAzrcHRJhfGJLRnSLojvd+WRX1bFsv0FfLH1MD/tzScu3Icerfw4r30wgd6WP7mrEEKIxkoSIdHgqVbRRPxjJgeeuBv270bP/a/jxG8/oQcMBQUoCyow6E/vcyJtgr255axWAHSJ8GXG2kwOl9o5nFbEqrQivtqWw+39W9EnKgCbpXG2EgkhhKiZJEKiUbCEt8Ty2D8wf5yP3rQaDqRAfi7692Xo7+aAYWA8+ToqJOy03mdEfCjntQ9if24527NL+WF3PgcKK3hhaTreFkXf1gGc1z6Is6IDsBiSFAkhRGMniZBoNJTFgnHhaLhwNObXn6AXzEF/8wlUlANgfvQWxt1PnPbYHj+bhS4RfnSJ8GNkfCj/3ZjFz8kF5JdVsSKlkBUphUQH2jgnNpCoQC/Kq0z6RAUQHeRVF48phBDiDJJESDRKqnsf9II5ziQIgM1rMN94FmPkVai4rnXyPt5Wg4l9WzGhTwR7c8tZllzA4j15HCis5MttOc5yFpXJ0PbBdAj1JirQi7hwH0J85MdLCCEaOvlNLRqnDp3B1x9Ki8HLCzVqHPqrj2DLWsztGzDumoLq3rfO3k4pRccwHzqG+TCuRwtWpBSwJbOU/DI7ZXaTrZml/Lg3nx+PlPeyKJ44L4aekf51VgchhBB1TxIh0SgpiwW6JsLaFaizhmBceiW6z0DML/4DG37DfHcaxn3PoOK61Pl7+9oMLugYwgUdQ5zHNh0sZn1GMRmFlSTnlZFRWMkLS9O5sls49iOrWPePCWBATGCd10cIIcSpk0RINFrGFTegQ8JRl14JOGaXGbc9hPnmVNi2HvOfT6AuHgOVlahhoxyLMe7cBPHdUdaa95Q7VT0j/Z2tPxVVJs/8lMaWQyV8vDHLWWbxnnzObRfE2TEB9I72x89mwdQao5GuVySEEE2BJEKi0VIR0ahxk1yPWW0Yk/+G+e402LIWPX82AHrPDlTLVuiVP6EuvAx1zc31Vi8vi8HjQ1szb3suh4orMJTCUPDD7nyWJRewLLmAcF8rfaL9WZZcQFy4D+MTW9Itwq/e6iSEEKJmkgiJJkd5+2Dc+Th60RdwINUx3X73NvTubQDoZYvQI69CBZzaukPu8LNZGNezhcuxYR2CWbqvgLUHisgstvPDnnwAtmaW8tgPKYzsHMpfOodSUF5FUnYpPVr50S7Up6bbCyGEqCOSCIkmSVmtqFHjADCXzEfP+rfjhNUGFeXoOTPQQaGoQReiomLOSJ26tPSjS0s/yu0mn285THJeGRd0DGFtehE/7Mnnu525fLcz11nex6p4bGgMiTLgWggh6o0kQqLJU+ePcOxVZpoQ3x39wWvolT8BjtYh49aH6nSG2cl4Ww2u63V0D5xzYgM5OzaQmesyySmx42VR+HtZOFBYwbM/pTGxTwTFlVWk5lXQK8qPVWlF7M8r55EhrekQJi1GQghxOiQREk2eMgzUDXcBoO129NKFkHUQgkIgfT/mG8+hrrkFNWykxzZaPat1AGe1DnC+rqwyeXVFBitSCvn3mkPO48v2Fzi/nvZLOo8PjeFwqZ0qUxMf7kOQrF0khBC1Ir81RbOirFYsf3sZAG2vRH/yDvrXJY6us4wUGHcryur5HwubxeDhwdHM3ZHDxxuyaOFno19MAOsPFNM6yIu9OWUcLKrk7u/2Oa/x9zKY3D+SwW3rb+yTEEI0NZ7/jS+EhyirDW68B6Ji0V9+iF66CJ2WjDF8LPQ8C2V4dsd5pRSXdwnn4rgQvC2GY2+zIz1427NKeHJJKqbWRAd6UWY3ySy28/LyA3y9LQdfnwPsP1xMdKAX3SJ8ObddkAy8FkKIGkgiJJo1pRTqkivQrVpjvv8K7NmB+fbz0D4e1Xcg7NuFuvAvdbZlx6nwsx2fkHVp6ceHY+OwGgovi4Hd1MzZks3X23LYnVMGlAFQUF7KjuxSvtyWw8j4ECb0icBmMQA4WFjB/rxy+rYOwCobyAohmilJhIQAVK8BGE+9gf55IfqX/8G+JPS+JAD0zk0YT7yOCmtxkrucWccmSFZDcW3PloyMD+WX/YW0DAsh3CgnNb+clamFrEor4rukPJanFBIX5kNeWRV7chzJ0tmxATw0uDUVVSa/pRbRws8qW4MIIZoNpbXWnq5EQ5eVlUVlZWWd3lMpRVRUFBkZGci34M+d6VjpvMPob/6Lzs2G3MOQkQpxXTAeeN5l/JDevxsK88/ojDN31BSv1WlFvPFbBgXlVUfLAYaCKg3BPhbKKk3KqxzlL0sIZUi7IKICvQjw8mwXYX2Sn8PakXi5T2LlvvqIlc1mo2XLlicviLQICXEcFRKOuukeAHRmBubUv8Lu7egvPkD7+KIPpqF8/dG/LgatUVdNwLh4jIdr/ef6xQQwc0xHdmaXkVZQTrC3lbhwH1Lzy3lxWTr5ZY4EqYWflewSO3N35DJ3h2NNo1AfC2O7hdM7yp/tWaVkFlcS5G2hRys/9uaWE+Bl0Dc6wDGGSQghGhlJhIT4EyoiCuPGezDffQm95Fvn8WP/zaI//wCzuAiCQ9ErfkRddBnGgKFnvrInYbMYdG/lR/dWR7fyaOlvY8blHTlUXIm3xSA22Ivf04qYtyOH9MJKckvt5JZV8f7azD+9d4S/Fath0DrIi4l9IogO8qrvxxFCiDohiZAQJ6H6DkRd8BdHIhQSjhp8ERw+hOp9Dnr3NvT336AXfO4srz/7NzqxP8rH14O1dl+Qj9Vl/aEBsYEMiA0EoLTS5Od9+Xy0IYuKKk1CS19igrzYn1fOrsOltA/14UBhBZnFdgAOFFaw8WAxiZF+dG3pR7tQb5Jzy8kqqaTKhFYBNiIDbYT5WokP90UDO7NKiQv3wdtqeOLxhRDNnCRCQrhBXX0zqs85ENMe5XfMQOJeA1Dt4zG/+xwK80ApyMtBL12EuqRhd5e5w9dmcGl8KBfHhWA3dY3JSkllFVsPlWIx4JvtOWw8WMLq9GJWpxf/6b1jg71QQEp+BVGBNm7sFUELfyvtQrydM9uKyquo0ppgWShSCFFP5LeLEG5QhgHx3Y8/rhScNRjLWYPRWqN/XYz+8E30D9+gzzkPDmehd26GqipUv8GoiGhHue+/Qe/dgTF0OHTp5bEVrd1lMdQJxwD52Sz0i3Gsit07yp89OeVszSxha2YJqfnlxAZ70zbEG6XgQEEF2SV2UvLLSc2vcN4jo7CSl35JB8DHahAf7ljzaGtmCRZD8deBURSUV5FXWsXANoEEeVvIKKwgraCCbhF+0hUnhDhlkggJUUeUUnD2eejv5kD2Icwpk6H0aKuIXvEjxhOvome9h/51CQDmupWo4WNRY2/0VLXrlFKKuHAf4sJ9uKxL2AnLFZVX8fX2HCqqTEbEhzJ3ew7bskrJLbVTUF7FpkMlzrJVVZppvxxwvv5sc7bLvQwFwzoEc1brAJKyS8kusdM+1JtO4T7Ehfnia5MuNyHEiUkiJEQdUlYbxr1PYb7zomPavVKQOAD27oDMA47kKD8HDAMS+8P639A/fYceNQ7l7e3p6p8xAd4Wrj9m49nb+0cCYGrNnpwy0vIrqKjSdG7hw9wdufy4N58wXyvtQ71Zn1GMqSHU10oLPyu7DpexeE8+i/fkO++3LNnxfz+bwV0DIikor2J3Thlhvo6ut7ah3vjbLPjaLJjHTNddd6CI6asP0SHMh4l9Imjpbzsj8RBCeI4kQkLUMRUZg/HYy+hff0R16oJq0xG9biXmv150JEFe3hi3PwLd+2L+bRIczoQta9Ah4ejVv0BZKWrcpEYz2LouGUrRKdyXTuFHn/2esyMZnRBKdKAX3laDyiqNoXB21W3LLOGnfflszSylTbAXHcJ82JtTTlJ2KYdL7fx9+YETvR0Agd57GNw2gOIKk1+SC9DAwaJKVqUWEhvsTWKkH4mR/mSX2DG1JsDLQtsQb3xtBoaCMF8rFVWaMrspY5mEaITkp1aIeqB8/FAXjDr6us85jplnOzdj3Hg3ql0nx/F+Q9CLvsSc9T7kHT56g1atUZeOrfHe5vxZjm62u59ERcXU63M0BEop2h+zT5rN4jpWqWuEH10j/P54GVWmZua6TObvzCXUx8KwDsEUVlSx+3AZGYWVlNlNNFBYbmdhUp7zumEdgskorGB7VinJeeUk55U711Sqia/VoLzKxNTQo5UfwzoEExlgY2tmCf5eFnpF+tPS30peWRUHiyoot2taBdiICfJq8GPDhGgOJBES4gwxxk067pjqNxi96MujSVD7eMf2Hj9+i75glKO1KC8HveJHdE4WxjW3oL/7HOyVmJ/PxHLPk2f4KRoPi6GYdFYrRsaHEu5nPW7Gm9aaChMyq3yZtz6ZQC+Ds1oH0DXCD601mcWV7M4p45fkQlLzy2kVYMPLosgprSIlrxy7qanSmlK76bzn5kMlbD5mfNOfiQ704oKOwXRt6XvkXmCv0ti1psrUtPS30Snch8oqjfVPBqsLIU6PJEJCeFJsB4iKhYxU1MWXoy6/HvNvt0BeDuZDE6CkyKW4+Y/HwH5ku5fNa9A7N6M69/BAxRuPE80oU0rhY1UMiA2jjXe5y9L+SilaBXjRKsCLQW2CTnjvyipNRmEF/l4Gpobvd+exPqOYQ0WVdI3wpaCsiqTDpdhNsChoFeCFt1WRml/BgcIKPt6Q9ad197IoKqo0/jaDAbGB9GjlR0WVyf68csJ8rUQFehEd6EXbEG9nolRcUUV5lSbAy8DL4pr8ZRZV8vO+fOf2KUIISYSE8CilFMZdU+DAfkgcgFIKdf5I9DefOJIgbx8IDEZ16IxeuwJKj7Q2RERBZgbm7PcxHnvFZQ80cebYLIo2IUcHuY9PbMn4RNf9jUytKa4w8bEq5/pIJZVVrEgpZMmefPLK7FgM5Wj1UY6WH4uC5LxySiodrU3FlSY/7s3nx7351MTPZtDCz+pYYuDIdimGgos6hpAY5cf6A8X42gx+3JtPUYXJvB05/HVgNDHBXiRll5GcV05emZ0erfwY2CbwuARKiKZMNl11g2y66lnNLVa6rBT95YfQshVq6AjnbDJz7n/R82dDYDDG469iPncfFBeiRl2Dcdl4zBVL0GtXYPm/W4nu2dsZL11YgN6+AdUq2rEgpKXpbqJaWw35s2U3NQcLKwj2sZKSV87v6UXsyCrFZlF0DPMhv8xORmElqfnlFFeaLtcaCswTPE51K9OfsRqK89sH0S7Um8V78ukd5c8FHYLJKa0iLjaS35PS+GFPHgC+VoXddNRXKQjwshAb7EVkgBcVVSbdI/yICW4+MyKrNeTPVkMjm64KIVwoH1/U+NuPPz7iarDaUHFdUeEtUePvQP/77+gFn2MW5KN/+R9oTVVRAfqfH6IrytF2O+bLf4OMVMf+aJ17YHnw+TP+TKL2rIZyJhDdWvnRrdXxA8LBMSh8f145hRVVBHhZiAyw4Wcz2HyohH/9fpCSSpMh7YKoMh2DtC/sGMKMtZmsO1BEQXkVbUO86dzCF1+rwbLkAg6X2rGbmh+OWY5gX245X23LOfIqpVbPoXBs+ts53Jd+MQHEBju2aPG1GkQE2DBqGDBeVF7F/vxy2gZ7E+AtibuoX9Ii5AZpEfIsidWJmR+8jl6x5LjjytcfXVYCQaGOKfu+/lBeCqaJ8fRbqNZtznxlG6Cm/tkytUbBCWenaa1dzplaU1RhkpJXzntrDpFXZmd4pxBWphaRXlBOK38vCipMbAaMiA+hVYAX5XbT2bVnak1BeRV7c8rIKbVTpWHLHwaPB3gZFFU4WrCCvC3c1LslLf1tZBRWYrMoftqXz6aDjmuCvS08ODiaHq38jqtnuV3XarHMKlOzNLkAb4uiX0xAvXf/NfXPVl3ydIuQJEJukETIsyRWJ6ZN07Gtx9xPUZ26QmI/9Ix/uhayeWE8/CLmd3NgwyrUpVdiXHGDZyrcwMhn68S01mhwttiYWmMxDCIjIzl48KDb8UrOLWPNgWJ2ZpeyJr0IUzu2UakyNZUn6r/DMe6peoyUt0UREWAj1MexZlNqQTnFFSYR/lbnopiBXhY6hvswMDYQU8OiXbnszS1nYGwgbUO8+XZnLjuzSwHH+7cKsGE1QKG4pFMIF3QIPuHMvJLKKmauzUQDY7uGu72lS4uISA5kZOB1zJIPWjta8PblltMhzIc2wbKMgiRCjYAkQp4lsTq5Y/9lr3duJrxFC3JMhbl1HSq2A6pjAnrNcszpf4ewlhgv/hsqysFuB//AGn8R64pyMCxNeiC2fLZq53TjlV1SSVZxJXFhvigFc7fnMGdLNj5Wg45hPpRWmsSF+zCqcyghPlamrz7ET/vyTzjeqbb8bAZ+NoPsEvtx57wsijBfK6G+VsrsJodL7PhYDSL8reSWVZFe4Ngbz1BwdmwgncJ9yClxDHT3sjgGuheUO177HOlmPFjk+LvRvZUfZ8cEUFBexc/7CsgsPvr3pEOoN3efHUWHsKNrZVXH9s8SpNJKk5xSO1GBNiqqNHbTsdjnsfdoLAmWJEKNgCRCniWxqp0TxUtXlGM+eKNj5pkyQB8ZYBsUgup9NurcS9A/L4SwlqheAzBffQKCQzEe+wfKdvRfwHrfLvD2RkU3/u41+WzVTn3Eq3qLk5rGCoFjiYLskkoOFVWSV2bHZlFEBnjR0s9KSn4FdtOx0nhuqZ1VaY4B5YaC+Ba+9In2Z8mefOymplO4D2O6hhPmayW9oILskkq0hrSCCj7fepjC8qo/rWeor5UOod6sPVD8p+Xc4X1ktuG+XMd6VFYDOh5JhA4VVVJUUYXVMGgb4uVctdzLYtCjlR/9WgeQUVjBJxuzKKow8fcyKD3SctY32h+r4Vie4VBRJV1a+nL+kQVC9+WWU1RRRWywF342C3bTkTxlFVeSW+pI4BJa+jIqPpSW/ja+351H0uEyerTy4+zYAPxsFrTWbMksYVd2GR3DfdAayuwmfaP9nTMiK6s0h0sqsWtN60D3WrskEWoEJBHyLIlV7fxZvMzZ76MXzzv5TSxWqHL8q1ldfh1qwFAoLkJvWeuY2u/rj/H3mY1+GxD5bNVOU42X3XT88c4psZNT6ki2IvxtlNk16QXl5JdXMbRdEOF+NpJzy/h+dx4F5VW09LdhaqisMrGbEOhtobLKJLe0il7R/vylbxzJaQf4YXceaQUV2AxFn2h/zokNxNtqkF9m5+1VB1mVVnTyStbgz2YHng4fq6LMfvTGvlaDs1r7k1bgSKj+KCbIiz7R/uzPK2d7VqlzVmLnFj4MbhtEkLeFAC8Lgd4W/GyObtGDRZWkFVQ4xpKZmucu7yOJUEMmiZBnSaxq58/ipU0Tsg+CzRv8AhwHd2/DnP2+Y5PY9vGQsteRBPkFONYyslig6vh/Laub78c4+7wz8ET1Rz5btSPxcp+7sdJasy+3nENFlZhoIgO8CPaxUFJhkpJfjo/V0Z2XX1bF0uQCUvPL8bIohrQLYmR8KKn5FYT6WiipNFmRUoifzSA22JtgHwuLduWxL7eM2GBv2od6E+BlIS2/giqtMZTCYkC4r41wP0d34A978tmYUYwGAr0Mzm0fzIaMYme3IIDNUCRG+rE/rxybxaC4oor8P7SmeVkcA+ftJm6xGrDi/vNrNfbsZGT6vBCiRsowICLa9WC33hhPvg5ZByGyNezejl79C+riyzE/eA2StoJSEBQCpulYzHHPDvSqn+Hs89CVFbAvCTp0htzD6B++QRfkoTp0Rg37C/rbWaCrHC1LhgW9Z4fj/hf8BdUy0gNREKLhUErRIczHZYwQAH64LNYJcE6bwOOujwt3XBcOXNPDtfwd/Wv38zW4bRCllSYHCiuICrThd2Qg+voDxezKKSM60IuerfwI8T2aOhSVV/HtzhxKKk2iA73o3sqPmCAv8sqqWJCUS3pBBUUVVRRVVFFYXkVJpYlFKcL8rLQN8aaFn40wXytV9dG05SZJhIQQjgHR1Ru4durqmIEGGLc/il7zK6p7H2fSog+mYz5xB2zbgN62AfPzDyBtH3TqCtmZkJvtKLd2BXrZ93Ao3XFfU6PLS9FLF4HW6MwM2StNiAbG12Y4xyuBY+xW39YB9G0dUGP5AG8L/9fz+JaXUF/rcausn4hSCqsHVzOXREgIcUIqMBh1/gjXY5GtnZvDmv88JpHZtc3x/8gYVO+zHZvJVidBgP7fV64337IOnXcYFRLuGIBdWoTq2hudmQHlZajY9vX1WEII4SSJkBCi1owRV2H+91+OKfjt4zEuHI356XSw2jDuewYV1gKzVTR6/mzUyKth3y70skXQqjXGdXdgzv0Udm9Dr/gROnbB/OcTUFWFGjocvfInqKrCePpNR9IlhBD1SBIhIUStqV4DsPQa4HLMmPouoFGGYy0TY9CFMOhCAPTAC1BDLoLW7VA2G+pwJnr3NvTieejvv3EOxtZLFznvp7//GnXDXY690n79AZXYHxUVe0aeTwjRfEgiJISoE8o4cR+/Mgxo1+no676D0HNmQuGR/azadETFd3NM7W/XCZJ3oVf+iO43BPPTd+FgOnr+HNSAoeg921Gt26KGXIxK6Om8p7bbm/Tij0KI+iG/NYQQZ5zy8cX428voPduhrAzVfwgqMBh98RgICcOc9gjs2eFY1BEcU/jLSx3da4BO34/+fRlq1DjIO4zevAbyc1Ejr0aNvhY2/AZxXVFBIZ57SCFEoyCJkBDCI1Rk6+PGAKnQcACMK27AfPsF0BradMC48W70L9+jMw+gEgfAzk3oX5eg589yuV7/7yvHwo8/L3Bc99grKIsFvW4lOnkX6i//h7LZHGUPZ0JIONpux1w8Dzp1Q7XpcGYeXgjRYEgiJIRocFR8dyyvf+p67NiNYs85HzOqDfrLD6FdHMaY6zHnfeYYgP3zAkeZlL3on+ZDQiLmv192LBLp7QOXjkV/8R/0D3OhUzfye/fHnPMBhIRjTH0X5e26FosQommrl0QoJyeHTz75hA0bNlBeXk5kZCSTJ0+mY8eOgGMlzTlz5rBkyRKKi4tJSEjglltuISoqynmPoqIiZs6cydq1a1FKMWDAACZMmICPz9H1Dfbv38+MGTPYs2cPQUFBDB8+nMsuu8ylLitXrmT27NlkZWURGRnJ+PHj6dOnT308thDiDDIuGYMeegl4+6KUwoCjXWkhYZCXg/76Y3TAPOd2IXrBHEc32p4djnK7tlK4a6vj6zzHYpBq1DUnfW9tmqBUo9nUUghxYnWeCBUVFfHEE0/QrVs3HnvsMYKCgsjIyMDf399ZZu7cuSxcuJA777yTiIgIZs+ezfPPP8+rr76Kl5djc8c33niD3NxcpkyZQlVVFe+88w7Tp0/n3nvvBaCkpISpU6fSo0cPJk2aREpKCv/617/w9/fnwgsdM1V27tzJ66+/zrXXXkufPn1Yvnw5L7/8MtOmTaNNm8a/YaQQzZ3y8Tv6IqEn9D4b9iVhPPwS5if/gm3rIScLAgKhZZRjBew9O8DLGzX4IvSP8x3XtmgF2YfQ382hasMqsHmBn79jllp0GyjKRy9f7NicdvBFmC89DMWF0CIS464pMs1fiEaszhOhuXPnEh4ezuTJk53HIiIinF9rrVmwYAFXXHEF/fr1A+Cuu+5i0qRJrF69mkGDBpGWlsaGDRt48cUXna1IEydO5MUXX+T6668nLCyM5cuXY7fbmTx5MlarldjYWJKTk5k/f74zEVqwYAG9evVi9OjRAIwbN47NmzezaNEibr311uPqXllZ6bKnmFIKX19f59d1qfp+8i/Kk5NY1U5zjZdSCuPOx9Fao5RC3fsUevsG9Oa1GGcNBv9Aqqb/HRXTDmPsDaiwlpj+AVh3bcW8+QHs06fB7u2wf7fznnrTapf30Bmp6KQtUJDnOHAoHf35DNT1d6F3bXWswO13dAVec9n/MH9djGXsjaj47jXWu7q+jUFz/WydComV+zwdqzpPhNasWUNiYiKvvvoq27ZtIywsjIsvvtiZnGRmZpKXl0fPnkenvfr5+REXF0dSUhKDBg0iKSkJf39/ZxIE0KNHD5RS7N69m/79+5OUlESXLl2wHjNdNjExkblz51JUVERAQABJSUmMGjXKpX6JiYmsXu36y63a119/zRdffOF83b59e6ZNm+b2xm2nIjJS9lpyl8SqdiReQEwMXHTM74B/f+F6/vYHnV+aL02nImkburwMXVFGVV4u9tS9VO7fg66oAGVQsWOTI1kCwu5/mpzXn0NvWoP51J3okmKUtzcBI68m+IY7KP19OYc/fhu0xnztacIffRHfAeeiq7vpSks59NcbsbaIoOUzr6O8Gs/YJPlsuU9i5T5PxarOE6HMzEx++OEHRo4cyZgxY9izZw8ffPABVquV8847j7y8PACCg4NdrgsODnaey8vLIygoyOW8xWIhICDApcyxLU0AISEhznPVZf/sff5ozJgxLolTdXaalZWF3W53NwRuUUoRGRlZp7vtNlUSq9qReLnvuFhF/KGLq+9g55c66yBMuQOq7Kg+51DQtS9q6KXoH+ejS4rBxxddVkrhVx9TuPhbxxpJWkNoODr3MNnPPYDqNwS98Xdo0xGjV3/MAynYD6SQ/sz9UFYK4REY1012zmxraOSz5T6JlfvqI1ZWq9Vzu8+bpknHjh259tprAUerSkpKCj/88APnnXdeXb9dnbLZbNhO8Auovj7IWmv5IXGTxKp2JF7ucytWLVqhLh+PXvEj6oobHV1ao8ahD6ajIqJQV02AbesxP3zT2XWm+g1BTbgX/dm/HdP/f1/muNeurZj7dh59/w2rnF9X5R7GmPyYW7PXtNaOMVBhLc9ot4J8ttwnsXKfp2JV54lQaGgoMTExLsdiYmJYtcrxg17dapOfn09oaKizTH5+Pu3atXOWKSgocLlHVVUVRUVFzutDQkKOa9mpfn1smfz8fJcy+fn5zvNCCFEbxvCxMHys87UKDMLy12eOFuh1NkaHBNi3C2Lbo8JaOI5ffye064Re/QsqOBS9ainY7eDjixo+Fv3jfFTPfujVvziSqfdeRrVuh162CHXepVBWit74O8aN96A6Hx1rpBd+gf76Y9Tgi+D6yc7tTYQQ7qvzRKhz584cOHDA5diBAwecTVQRERGEhISwefNmZ+JTUlLC7t27ufjiiwGIj4+nuLiYvXv30qGDY4GzLVu2oLUmLi7OWeazzz7Dbrc7xwlt2rSJ6OhoAgICnGU2b97MyJEjnXXZtGkTnTodXepfCCHqkgoKgcR+rseUQp17CZx7CbqyEr1nB2QfQp1zPsbIq2Hk1QDoc4Zh/vNJ2Pi7owsN0PNnO+9jfvkfjOvvRC+Zhxp8sWMBSUAv/wG9eS2UFkPnHhjDRqK69z2ublpr2LkZnbQVQsIwzr0Eba8ETYPtjhOivp14c6BTNHLkSHbt2sVXX33FwYMHWb58OUuWLOGSSy4BHL8QRowYwVdffcWaNWtISUnhrbfeIjQ01DmLLCYmhl69ejF9+nR2797Njh07mDlzJgMHDiQsLAyAwYMHY7Vaeffdd0lNTWXFihUsXLjQZYzPiBEj2LhxI99++y3p6enMmTOHPXv2MHz48Lp+bCGEcIuy2TBue9ixV9qoca7n4rth3HI/KAUWK+qSKyA4FFpGgtUK+5IwX5mC/nUJ5t//BiXFjvMWC+TnQEU5bF6D+fozmJ/9G70vCZ2ZgS4tAUDPmeG4/tvP0B+/jV77K+bU+zEfugm9axt67QrMVUulK0c0K0rXwyd+7dq1fPrppxw8eJCIiAhGjhzpnDUGRxdUXLx4MSUlJSQkJHDzzTcTHR3tLFNUVMSMGTNcFlScOHHiCRdUDAwMZPjw4Vx++eUudVm5ciWzZs0iKyuLqKioU1pQMSsry2VafV1QShEVFUVGRob80jkJiVXtSLzc11BjpffvAW8fVGRrdFUVKIX+6E30r0uOK6sm3Itq0xHycyEgCP3rD+ifFhx/07ZxR5cGiGkPaftAGaDN4+950z0Ygxy/s3VlBVhtjjFOi77EKzQce/e+cPEYlEW64k6koX62GqL6iJXNZnN7sHS9JEJNjSRCniWxqh2Jl/saU6x0WjLmM/eAMjBufRBz7n/B2xfj0b+jrK6jHPTG3zG/m+NoJSougvIy5zn1l/9DXfAXzMdvcywKCUeTJIvVsQq3lxfGI39Hp+xBf/y2ozWqosK1Qon9UYHBUFaKuugyVIfOrnXYvhHz47dRA87DuOxat5/T/P4b9JrlGLc/enSMVSPUmD5bnubpREj2GhNCiEZAxbTDuPMxsNpQ3fti9BmIMmoe3aAS+2NJ7O98rQ9nopd9D15eqEuvRBkG6orr0R+/g7pwNGrsjbBlHXSIx5zxT9i2wbF6tr3SsQRARQUYBsZl4wlqFUne+/90jGOqvv+a5agL/oK6eiLKsKCTtmK+NRUqytHzZ2FGtkb1Pxf9+Uz09k0Ytz6Eioo5rt66IA/99cdgr0Qv/Bw1/g7HcXslGIYMBhf1QhIhIYRoJFSvs49+fYIkqMbrwiNQY65zOWacOxzdvS+EtnBMve81wHH8lgcx33sZtm90XHvucNSFo8HPHyMkjMCoKAr8gzFnvYeKbQ/KQP/2E3rJt+jsQxiXXulMgpx7vn389pENcRcCYL79PMb9z0FwqEv3mv5pgSP5AvTyxeiRV6NX/oye9yl074sx+W/OZQK0WYX+dQkqtj2qnUyAEadOusbcIF1jniWxqh2Jl/skVjXTWqNX/QxFhahho5xJ14nipdf+ivn+q84kBoCOCRj3PYM5fZqjtamazQsqj3SzhbXAuPtJ9K9L0KuXQWmJI4Hy83cMBLfaXO5p3PcMqltvRxL0nzfRK390zH6bNrNWieGZIJ8t93m6a6xhfXKEEEJ4nFIK4+zzMS4c7VaCofoOwnj4JajefDY8wrEopI8vxp2Poy66zHG8W2+MR15yzIIDyMnGfPUJ9OK5jsHeFeXQMhLjxnsc5+2V4BcAnXsAjuUDzIVfYj7/gCMJAsjLgb07jquTzjqIuXgeOnWfW39cdXkZevMax+D0P57TGvPnBZg/zkebx58XjZt0jQkhhDhtqn0njCdeQ69biercw7GeEqCsNtTVN6MvuQICg1CGBcsL/0YX5GI+c+/RVbiHjYKoGFTnnqioGIy/PgMWG3TsDCXFmI/dCqn70Kn7HG9otUFEFBxIQa9dCa1aO2baeXmjM9Iw//EYFOQ5xjHFd8e441FUwNGtm/Sa5Y4vep8DZpVj/aY9O1BX3Ii69OiimQDs2ob+77uO6zb+7lj+4JjNdUXjJomQEEKIOqG8vFFnn1fzueBQ19dBoRgT7nWMJ+rUDXX1zS7jhVTX3kcLB4Wg/u9Wxxij8Jao+O6oswbD7u2Y/3rRsWTAj99CdFuMOx/DfGWKI8EKCXPMmkvagjntEYy/PosKa4neuRlz+t8d9w6PgIAg59ICeulC9LkXozevRfUdhLLZMBd9ebQu2zagv/wQdf2dNT6n1hqyD4FhoI/pmtFpyejvv0GdPxLVvhM6L8cxRkp2p/c4SYSEEEJ4hOreF+PvH4Cf/0nXJDIGXQiDLnQ5prv1AS9vx9gigLR9mFPvdywLEBWL8dCLUJiH+frTcDAd85UpGA+9iPntrCMVMOBwpuM/w3CMXzqcifn03Y4ut7RkOOd82LwGlEJddwf643ccY5pGXuOc3q+Td6E3rELFtsdctRTW/wZARkQU3Pk4WhmYrz4BhfnoretQvQagl/0PdckY1JUT6jKk6LISKCxAtZRd790liZAQQgiPqe5CO6Vrvb1RZw1Gr1gCXXvBtg2OJMjmhXH7I6jAIAgMwnhkmmMl7swMR5JTXAgWK8ZTb8ChdHTmAVRsB/TG39FLvnUkQRxpHapehLLPORjnDqdq1TJI2oKePwuGj0XP+9Sxdxw4lxPAMMAwqMrMgBcedOwrV2V3nCvIQy/7n6P8D3PRgy5yLiWgK8odXXYFeeAfiOo1wLFWk5v0viTMt5+HogJH69eRsVXiz0kiJIQQotFS101GjbgKIqIw33wONq9BXXkTKrrN0TJhLTEemIr52lOQmeE4NnCYIwGJisHZORUShv5xviORCQqF3GzYsQmsNozLxgNgjLwaM2mLY6XtX74/WpEeZ0HqXvDywZj0AKplFJZ3X6Rix2bH+Y4JGGNucLROVVY4xjdlZmB+8YFjfajsTMx/veRY8fsI/ck7qOvvxBh8EdpeibLa0BmpmJ9/gIpu4+iGjGztOL5rm2Oc05EZeeZ/38V48jVHq9f2jWCvgPBWjiUPToPWusl158n0eTfI9HnPkljVjsTLfRKr2mno8dKVFXAw/YR/7LXdjl6/EvbvQV06FuUfeHyZbRvA28exR9vMfwKgrpqIcfHljvNao7+dhf55ARTmOza5vWoiqm1H53mlFEopWoWGkvG/uRDT/mirT0YalJWCj4+jdco0ITIGsg86Wo4Cg1Hd+6DTUyBlD/gFoMbfjv7gNccK4FkHnQPMAbBYUH0Ho3ducsy869YbUvY66hbfDQry4WDa0fI9znJcn5vtmNnXMcG92OblYE79K6pzT4xJD6CzDoJ/QJ0MGvf09HlJhNwgiZBnSaxqR+LlPolV7TSneGm7HfO9l1HePqib7jluVWttmo6B2AGBNbaQuBMrc8WP6M+mOxIjgISeGBPuQ4W1QJtVmE/cCZkHHJvwHnuPmHYQ2gKStrhsn0Lrthh/exm9YRX6/VeOHvcPdLRA7d/tSLyq+flj3HA3dOqCCnIMZtep+zBnvw/FRaioGNSVE1BhLTB/WoD+1DFzTt36MHrmqxDdBuPxV2HdCkdrU3v3F7bUO7dgLvgc48K/YPTsJ1tsCCGEEA2Jslqx3PG3E583DAgMOuF5dxgDh6G7JKJXLHEsORDX5Zj7W1DDr0B/9JYjCYqMQSX0RBfmYVw3GRUQ5EgakndhzpnpaOG5/VFH4jZgKDoyBr13B6BQZ5+H8vVDZ6Q6xieFhKHX/wZ7dmC++5Jjz7r7n4WCXMz3/uHcV06n7UPv34Px0PPobeudddMzX3W0XqXsRf/3X4572rwwHnz+uD3naqK1xvzvvyAjFXPbevTwseg7HjqtWJ4OaRFyg7QIeZbEqnYkXu6TWNWOxMt9dRErXVmJ+cQdjiTnoRdQcV3rrH66uAj91Yforesds+badHS0PpWVQtfeGMNGYn72b8e5tnFwKP1oy9WJBAZjPPA8ZGWgV//i2J6lc3d0QR7mzH+igkJQ10yC/bsd45ksFqiqAi9vIt+eRbaySouQEEIIIRyUzYbx6N+htBgVFVu39/YPQF1/Jzr3MObjtznGIwG0j8e490mUYcFo3Rbz2fucaywREOgYfF09/mjXdtAmBIdBcCik7MF84QHHCuGA/n2ZY8xSfi6kJaMBnbQVfP0ddTiSKGGa2KJjISOjTp/RXbLFhhBCCNFAqZCwOk+CXO4fGu5Y1RvAYsG48W7neCjVohVq5NVHy3bphbriBkeydOM9qP5DHMevmuBYCbxTV2cSRHx3R9K0db1jPabAYGjRytHCdGRmnBo20rE9S/9z6+353CEtQkIIIUQzpkZcBfk50CUR1bqt67lho9BLFzpmq3XvizFwGAy+yHHyxrtRo8ahjuwxZ/z1OfTieaiISFTfQejMA+jli9GpezHG3ghhEejffkJv34hq1wkVGXOmH7VGkggJIYQQzZjy80fdfH/N52w2jPueQW/bgDp76B/OeR3daPdI2WP3aVMR0Y4WpGOvGTYKqlugGghJhIQQQghxQioiChUR5elq1BsZIySEEEKIZksSISGEEEI0W5IICSGEEKLZkkRICCGEEM2WJEJCCCGEaLYkERJCCCFEsyWJkBBCCCGaLUmEhBBCCNFsSSIkhBBCiGZLEiEhhBBCNFuSCAkhhBCi2ZJESAghhBDNliRCQgghhGi2ZPd5N1it9Rem+rx3UyOxqh2Jl/skVrUj8XKfxMp9dRmr2txLaa11nb2zEEIIIUQjIl1jHlJaWsojjzxCaWmpp6vS4Emsakfi5T6JVe1IvNwnsXKfp2MliZCHaK3Zt28f0iB3chKr2pF4uU9iVTsSL/dJrNzn6VhJIiSEEEKIZksSISGEEEI0W5IIeYjNZuPKK6/EZrN5uioNnsSqdiRe7pNY1Y7Ey30SK/d5OlYya0wIIYQQzZa0CAkhhBCi2ZJESAghhBDNliRCQgghhGi2JBESQgghRLMliZAQQgghmi3ZDc5DFi1axLfffkteXh5t27Zl4sSJxMXFebpaHjVnzhy++OILl2PR0dG89tprAFRUVPDRRx+xYsUKKisrSUxM5JZbbiEkJOTMV/YM27ZtG/PmzWPfvn3k5uby4IMP0r9/f+d5rTVz5sxhyZIlFBcXk5CQwC233EJUVJSzTFFRETNnzmTt2rUopRgwYAATJkzAx8fHE49Ur04Wr7fffpulS5e6XJOYmMjjjz/ufN1c4vX111/z+++/k56ejpeXF/Hx8Vx33XVER0c7y7jzs5ednc17773H1q1b8fHxYejQoVx77bVYLBYPPFX9cCdWTz/9NNu2bXO57sILL+TWW291vm4Osfr+++/5/vvvycrKAiAmJoYrr7yS3r17Aw3rMyXT5z1gxYoVvPXWW0yaNIlOnTrx3Xff8dtvv/Haa68RHBzs6ep5zJw5c1i1ahVPPPGE85hhGAQFBQHw3nvvsW7dOu688078/PyYMWMGhmHw3HPPearKZ8z69evZuXMnHTp04B//+Mdxf9i/+eYbvvnmG+68804iIiKYPXs2KSkpvPrqq3h5eQHwwgsvkJuby6233kpVVRXvvPMOHTt25N577/XUY9Wbk8Xr7bffJj8/n8mTJzuPWa1WAgICnK+bS7yef/55Bg0aRMeOHamqquKzzz4jNTWVV1991Zn0nexnzzRNHnroIUJCQrj++uvJzc3lrbfe4oILLuDaa6/15OPVKXdi9fTTTxMVFcU111zjvM7Lyws/Pz+g+cRqzZo1GIZBVFQUWmuWLl3KvHnz+Pvf/05sbGzD+kxpccb97W9/0++//77zdVVVlb711lv1119/7blKNQCzZ8/WDz74YI3niouL9bhx4/TKlSudx9LS0vRVV12ld+7ceaaq2CBcddVVetWqVc7XpmnqSZMm6blz5zqPFRcX62uvvVYvX75ca611amqqvuqqq/Tu3bv/v507CmmqDeMA/m8uym3Z2RxrrbHJ0mUX0xGVUIIRQRBBELQiISqTwIoukm4EJaEgJIhSImpWUiYVXXQhBXXVpOjCoDaDIWttME422Zluy7G581187ODU0ovv2xm+z+9qnHMGz/nzvvIc37NXuubz58+iy+USJycni1e8DObnJYqi2NvbK16/fv2P32E5r3g8Lh45ckT0+XyiKC5v7o2Ojooul0uMxWLSNW/evBFPnDghZjKZotZfTPOzEkVR7OrqEh88ePDH77CalSiK4smTJ8V3796V3Jiid4SKLJvNIhAIwOFwSMcUCgUcDgf8fr+MlZUGnudx9uxZnD9/Hrdu3UI0GgUABAIBzM7OFuS2adMm6PV65nObmJiAIAioq6uTjqlUKlRXV0vZ+P1+qNVqbN68WbrG4XBg1apVGB8fL3rNpWBsbAxnzpzBxYsXce/ePUxPT0vnWM4rlUoBgPTfseXMPb/fD4vFUrCs4XQ68fv3b4TD4eIVX2Tzs8p7//49WlpacOnSJQwODiKdTkvnWMwql8thZGQE6XQadru95MYUvSNUZFNTU8jlcgvea+E4DpFIRJ6iSkRNTQ3a2tpgMpkQi8Xw4sULdHZ24saNGxAEAUqlEmq1uuA769evhyAI8hRcIvL3P39ZdW42giBIS4x5ZWVl0Gg0TObndDrR0NAAg8EAnufx9OlTXLt2DVevXoVCoWA2r1wuh4cPH2LLli2wWCwAsKy5JwjCgr9p+fG4UvNaLCsAaGxshF6vh06nw48fP/DkyRNEIhG0t7cDYCurUCiEjo4OZDIZrF27Fu3t7TCbzQgGgyU1pqgRIiUj/xIdAFitVqkx+vDhg/SeCyH/hd27d0ufLRYLrFYrLly4AJ/PV/CUyhq3241wOIzu7m65Syl5f8pq37590meLxQKtVovu7m7wPA+j0VjsMmVlMpnQ09ODVCqFjx8/oq+vD1euXJG7rAVoaazIKioqpCfOuRbrflmnVqthMpnA8zw4jkM2m0UymSy4Jh6PM59b/v7j8XjB8bnZcByHqampgvOzs7NIJBLM5wcAGzZswLp168DzPAA283K73RgdHUVXVxcqKyul48uZexzHLfiblh+PKzGvP2W1mPyvgeeOLVayUiqVMBqNsNlsOH78OKqqqjA8PFxyY4oaoSJTKpWw2Wzwer3SsVwuB6/XC7vdLmNlpWdmZkZqgmw2G8rKyvD161fpfCQSQTQaZT43g8EAjuMKskmlUhgfH5eysdvtSCaTCAQC0jVerxeiKDK/bQMATE5OIpFIQKvVAmArL1EU4Xa78enTJ3R2dsJgMBScX87cs9vtCIVCBc34ly9fUF5eDrPZXJwbKYKlslpMMBgEgIKxxUJWi8nlcshkMiU3pmhpTAYHDx5EX18fbDYbqqurMTw8jHQ6jT179shdmqwGBgawfft26PV6xGIxPHv2DAqFAo2NjVCpVNi7dy8GBgag0WigUqnQ398Pu93ORCOUbwrzJiYmEAwGodFooNfrceDAAbx8+RIbN26EwWDA0NAQtFotduzYAeDfPTycTifu3r2L1tZWZLNZ9Pf3Y9euXdDpdHLd1v/mb3lpNBo8f/4cDQ0N4DgOP3/+xOPHj2E0GlFfXw+Arbzcbjc8Hg8uX76M8vJy6SlcpVJJP/teau7V19fDbDajt7cXzc3NEAQBQ0ND2L9/P1avXi3j3f23lsqK53l4PB5s27YNGo0GoVAIjx49wtatW2G1WgGwk9Xg4CCcTif0ej1mZmbg8XgwNjaGjo6OkhtTtI+QTF6/fo1Xr15BEARUVVXh1KlTqKmpkbssWd28eRPfvn3D9PQ0KioqUFtbi2PHjknr6vkNuEZGRpDNZpnaUNHn8y26tt7U1IRz585JGyq+ffsWqVQKtbW1aGlpKdjoLZFIwO12F2wQePr06RW3QSDw97xaW1vR09OD79+/I5lMQqfToa6uDkePHi0YS6zk5XK5Fj3e1tYmPZwtZ+79+vUL9+/fh8/nw5o1a9DU1ITm5uYVtUngUllFo1Hcvn0b4XAY6XQalZWV2LlzJw4fPiztIwSwkdWdO3fg9XoRi8WgUqlgtVpx6NAh6detpTSmqBEihBBCCLPoHSFCCCGEMIsaIUIIIYQwixohQgghhDCLGiFCCCGEMIsaIUIIIYQwixohQgghhDCLGiFCCCGEMIsaIUIIIYQwixohQgghhDCLGiFCCCGEMIsaIUIIIYQw6x+PBtXqEUGNNQAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"opening_model = gen_train_eval_model(opening_df, 3)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-29T12:22:17.654088Z","iopub.execute_input":"2024-07-29T12:22:17.654342Z","iopub.status.idle":"2024-07-29T12:25:49.683938Z","shell.execute_reply.started":"2024-07-29T12:22:17.654319Z","shell.execute_reply":"2024-07-29T12:25:49.682979Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":287,"outputs":[{"name":"stdout","text":"Epoch 1/300\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 121951.7266\nEpoch 1: val_loss improved from inf to 115007.42188, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 121951.8594 - val_loss: 115007.4219\nEpoch 2/300\n\u001b[1m312/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119866.9531\nEpoch 2: val_loss improved from 115007.42188 to 107075.66406, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119797.7812 - val_loss: 107075.6641\nEpoch 3/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110940.7344\nEpoch 3: val_loss improved from 107075.66406 to 102106.47656, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110836.4375 - val_loss: 102106.4766\nEpoch 4/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107698.2734\nEpoch 4: val_loss improved from 102106.47656 to 99704.14062, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107630.9297 - val_loss: 99704.1406\nEpoch 5/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101743.3750\nEpoch 5: val_loss improved from 99704.14062 to 97511.15625, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101821.1094 - val_loss: 97511.1562\nEpoch 6/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101474.4609\nEpoch 6: val_loss improved from 97511.15625 to 96000.00000, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101472.2344 - val_loss: 96000.0000\nEpoch 7/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99699.0391\nEpoch 7: val_loss improved from 96000.00000 to 94587.02344, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99714.6719 - val_loss: 94587.0234\nEpoch 8/300\n\u001b[1m291/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98536.9766\nEpoch 8: val_loss improved from 94587.02344 to 93527.50000, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98540.9375 - val_loss: 93527.5000\nEpoch 9/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95673.5078\nEpoch 9: val_loss improved from 93527.50000 to 92036.15625, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95750.5469 - val_loss: 92036.1562\nEpoch 10/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96741.0547\nEpoch 10: val_loss improved from 92036.15625 to 91005.07031, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96678.3203 - val_loss: 91005.0703\nEpoch 11/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93445.2578\nEpoch 11: val_loss improved from 91005.07031 to 89950.89844, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93453.8359 - val_loss: 89950.8984\nEpoch 12/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94094.7422\nEpoch 12: val_loss improved from 89950.89844 to 88301.96094, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94035.0625 - val_loss: 88301.9609\nEpoch 13/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90739.9219\nEpoch 13: val_loss improved from 88301.96094 to 87143.14062, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90727.4062 - val_loss: 87143.1406\nEpoch 14/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87387.8984\nEpoch 14: val_loss improved from 87143.14062 to 86223.27344, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87439.7500 - val_loss: 86223.2734\nEpoch 15/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86317.8359\nEpoch 15: val_loss improved from 86223.27344 to 84688.71094, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86362.3984 - val_loss: 84688.7109\nEpoch 16/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87507.7656\nEpoch 16: val_loss improved from 84688.71094 to 83673.39062, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87469.8516 - val_loss: 83673.3906\nEpoch 17/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84745.7812\nEpoch 17: val_loss improved from 83673.39062 to 82389.96094, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84751.8984 - val_loss: 82389.9609\nEpoch 18/300\n\u001b[1m312/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82538.9922\nEpoch 18: val_loss improved from 82389.96094 to 81406.83594, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82561.8828 - val_loss: 81406.8359\nEpoch 19/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82385.6484\nEpoch 19: val_loss improved from 81406.83594 to 80300.07031, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82387.1641 - val_loss: 80300.0703\nEpoch 20/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83248.8594\nEpoch 20: val_loss improved from 80300.07031 to 79248.01562, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83197.0781 - val_loss: 79248.0156\nEpoch 21/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80056.7266\nEpoch 21: val_loss improved from 79248.01562 to 78390.85156, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80068.4219 - val_loss: 78390.8516\nEpoch 22/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76965.2578\nEpoch 22: val_loss improved from 78390.85156 to 77686.69531, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77027.1719 - val_loss: 77686.6953\nEpoch 23/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80059.5781\nEpoch 23: val_loss improved from 77686.69531 to 76766.04688, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79997.6328 - val_loss: 76766.0469\nEpoch 24/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76046.0625\nEpoch 24: val_loss improved from 76766.04688 to 75498.54688, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76116.8906 - val_loss: 75498.5469\nEpoch 25/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73993.3828\nEpoch 25: val_loss improved from 75498.54688 to 74862.56250, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74040.9922 - val_loss: 74862.5625\nEpoch 26/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75422.4531\nEpoch 26: val_loss improved from 74862.56250 to 73763.39062, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75408.6797 - val_loss: 73763.3906\nEpoch 27/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74440.1172\nEpoch 27: val_loss improved from 73763.39062 to 72953.93750, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74415.7500 - val_loss: 72953.9375\nEpoch 28/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 72812.1094\nEpoch 28: val_loss improved from 72953.93750 to 72188.68750, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72812.2422 - val_loss: 72188.6875\nEpoch 29/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71793.5938\nEpoch 29: val_loss improved from 72188.68750 to 71297.68750, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71793.5703 - val_loss: 71297.6875\nEpoch 30/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71576.4844\nEpoch 30: val_loss improved from 71297.68750 to 70387.66406, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71548.7109 - val_loss: 70387.6641\nEpoch 31/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69672.3359\nEpoch 31: val_loss improved from 70387.66406 to 69656.03125, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69703.6719 - val_loss: 69656.0312\nEpoch 32/300\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71543.7969\nEpoch 32: val_loss improved from 69656.03125 to 68949.04688, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71536.3438 - val_loss: 68949.0469\nEpoch 33/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67484.8594\nEpoch 33: val_loss improved from 68949.04688 to 68366.50781, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67574.6953 - val_loss: 68366.5078\nEpoch 34/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68139.7109\nEpoch 34: val_loss improved from 68366.50781 to 67796.31250, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68109.8438 - val_loss: 67796.3125\nEpoch 35/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66212.6797\nEpoch 35: val_loss improved from 67796.31250 to 67068.92188, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66246.6562 - val_loss: 67068.9219\nEpoch 36/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 67076.3125\nEpoch 36: val_loss improved from 67068.92188 to 66308.60156, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67044.4531 - val_loss: 66308.6016\nEpoch 37/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66600.6875\nEpoch 37: val_loss improved from 66308.60156 to 65520.17188, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66553.8984 - val_loss: 65520.1719\nEpoch 38/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64269.3828\nEpoch 38: val_loss did not improve from 65520.17188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64285.2891 - val_loss: 65889.1562\nEpoch 39/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64328.4727\nEpoch 39: val_loss improved from 65520.17188 to 64502.21484, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64327.6172 - val_loss: 64502.2148\nEpoch 40/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62872.7266\nEpoch 40: val_loss improved from 64502.21484 to 63595.51172, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62884.7617 - val_loss: 63595.5117\nEpoch 41/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61487.6094\nEpoch 41: val_loss improved from 63595.51172 to 63557.56250, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61564.5508 - val_loss: 63557.5625\nEpoch 42/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63832.1445\nEpoch 42: val_loss improved from 63557.56250 to 62572.97266, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63779.3086 - val_loss: 62572.9727\nEpoch 43/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61773.2461\nEpoch 43: val_loss improved from 62572.97266 to 62136.31250, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61770.8945 - val_loss: 62136.3125\nEpoch 44/300\n\u001b[1m291/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62460.5000\nEpoch 44: val_loss improved from 62136.31250 to 61694.82812, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62382.0312 - val_loss: 61694.8281\nEpoch 45/300\n\u001b[1m289/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61650.4023\nEpoch 45: val_loss improved from 61694.82812 to 60991.57812, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61598.0508 - val_loss: 60991.5781\nEpoch 46/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60615.9961\nEpoch 46: val_loss improved from 60991.57812 to 60331.89062, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60588.0469 - val_loss: 60331.8906\nEpoch 47/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61008.5117\nEpoch 47: val_loss improved from 60331.89062 to 60271.82031, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 60920.5859 - val_loss: 60271.8203\nEpoch 48/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59514.6406\nEpoch 48: val_loss improved from 60271.82031 to 59603.53125, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59509.4688 - val_loss: 59603.5312\nEpoch 49/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58209.6094\nEpoch 49: val_loss improved from 59603.53125 to 58941.95703, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58211.3828 - val_loss: 58941.9570\nEpoch 50/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58611.6055\nEpoch 50: val_loss improved from 58941.95703 to 58411.63672, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58602.0352 - val_loss: 58411.6367\nEpoch 51/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56465.5273\nEpoch 51: val_loss improved from 58411.63672 to 57998.19531, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56496.0039 - val_loss: 57998.1953\nEpoch 52/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56050.5430\nEpoch 52: val_loss did not improve from 57998.19531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56100.2734 - val_loss: 58276.4609\nEpoch 53/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56244.5273\nEpoch 53: val_loss improved from 57998.19531 to 57545.98438, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56298.4961 - val_loss: 57545.9844\nEpoch 54/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56271.7656\nEpoch 54: val_loss improved from 57545.98438 to 56978.73828, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56274.0508 - val_loss: 56978.7383\nEpoch 55/300\n\u001b[1m286/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54933.1211\nEpoch 55: val_loss improved from 56978.73828 to 56799.85156, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55039.8281 - val_loss: 56799.8516\nEpoch 56/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57337.7852\nEpoch 56: val_loss improved from 56799.85156 to 56313.60156, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 57275.1562 - val_loss: 56313.6016\nEpoch 57/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53816.1055\nEpoch 57: val_loss improved from 56313.60156 to 56135.99219, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53882.0625 - val_loss: 56135.9922\nEpoch 58/300\n\u001b[1m309/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56371.5234\nEpoch 58: val_loss improved from 56135.99219 to 55647.59766, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56321.7031 - val_loss: 55647.5977\nEpoch 59/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53865.3203\nEpoch 59: val_loss improved from 55647.59766 to 55091.53906, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53905.1719 - val_loss: 55091.5391\nEpoch 60/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52022.4961\nEpoch 60: val_loss improved from 55091.53906 to 54683.84766, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52175.4414 - val_loss: 54683.8477\nEpoch 61/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54437.4844\nEpoch 61: val_loss improved from 54683.84766 to 54391.51953, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54421.4297 - val_loss: 54391.5195\nEpoch 62/300\n\u001b[1m287/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53538.4648\nEpoch 62: val_loss improved from 54391.51953 to 54050.76953, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53520.2305 - val_loss: 54050.7695\nEpoch 63/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52845.0781\nEpoch 63: val_loss improved from 54050.76953 to 53928.17188, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52880.3867 - val_loss: 53928.1719\nEpoch 64/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52938.3203\nEpoch 64: val_loss did not improve from 53928.17188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52992.7695 - val_loss: 53963.2891\nEpoch 65/300\n\u001b[1m285/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51939.9375\nEpoch 65: val_loss improved from 53928.17188 to 53176.13281, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52056.0273 - val_loss: 53176.1328\nEpoch 66/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52052.0078\nEpoch 66: val_loss improved from 53176.13281 to 52770.48828, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52071.0039 - val_loss: 52770.4883\nEpoch 67/300\n\u001b[1m292/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51288.6719\nEpoch 67: val_loss improved from 52770.48828 to 52605.70703, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51376.0391 - val_loss: 52605.7070\nEpoch 68/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50056.8867\nEpoch 68: val_loss improved from 52605.70703 to 52214.55859, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50130.7188 - val_loss: 52214.5586\nEpoch 69/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49322.6523\nEpoch 69: val_loss improved from 52214.55859 to 52059.44531, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49470.3750 - val_loss: 52059.4453\nEpoch 70/300\n\u001b[1m286/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50837.9453\nEpoch 70: val_loss improved from 52059.44531 to 51578.83984, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50790.4023 - val_loss: 51578.8398\nEpoch 71/300\n\u001b[1m288/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48523.5000\nEpoch 71: val_loss improved from 51578.83984 to 51469.86719, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48645.2578 - val_loss: 51469.8672\nEpoch 72/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50710.2109\nEpoch 72: val_loss improved from 51469.86719 to 51328.61719, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50699.7070 - val_loss: 51328.6172\nEpoch 73/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50620.8438\nEpoch 73: val_loss improved from 51328.61719 to 51283.80078, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50569.1055 - val_loss: 51283.8008\nEpoch 74/300\n\u001b[1m289/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50154.9766\nEpoch 74: val_loss improved from 51283.80078 to 50646.26953, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50114.5352 - val_loss: 50646.2695\nEpoch 75/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48706.0039\nEpoch 75: val_loss did not improve from 50646.26953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48720.7109 - val_loss: 51374.3594\nEpoch 76/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48697.7344\nEpoch 76: val_loss improved from 50646.26953 to 50437.33594, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48787.4141 - val_loss: 50437.3359\nEpoch 77/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50651.2969\nEpoch 77: val_loss improved from 50437.33594 to 50028.29297, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50549.8906 - val_loss: 50028.2930\nEpoch 78/300\n\u001b[1m287/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49077.8359\nEpoch 78: val_loss improved from 50028.29297 to 49937.70703, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49027.4336 - val_loss: 49937.7070\nEpoch 79/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46891.1211\nEpoch 79: val_loss improved from 49937.70703 to 49907.22656, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47021.1484 - val_loss: 49907.2266\nEpoch 80/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47823.4180\nEpoch 80: val_loss improved from 49907.22656 to 49316.95312, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47821.5664 - val_loss: 49316.9531\nEpoch 81/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47765.7266\nEpoch 81: val_loss did not improve from 49316.95312\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47747.7891 - val_loss: 49320.9531\nEpoch 82/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47809.8594\nEpoch 82: val_loss improved from 49316.95312 to 48910.13281, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47789.0820 - val_loss: 48910.1328\nEpoch 83/300\n\u001b[1m315/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46359.4727\nEpoch 83: val_loss improved from 48910.13281 to 48555.07031, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 46365.9297 - val_loss: 48555.0703\nEpoch 84/300\n\u001b[1m292/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48033.0078\nEpoch 84: val_loss did not improve from 48555.07031\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47998.8359 - val_loss: 48651.6523\nEpoch 85/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47293.2695\nEpoch 85: val_loss improved from 48555.07031 to 48426.09766, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47269.6914 - val_loss: 48426.0977\nEpoch 86/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46003.9492\nEpoch 86: val_loss did not improve from 48426.09766\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 46050.9180 - val_loss: 49300.2109\nEpoch 87/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48051.2734\nEpoch 87: val_loss improved from 48426.09766 to 47937.88672, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47983.5859 - val_loss: 47937.8867\nEpoch 88/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47058.0625\nEpoch 88: val_loss improved from 47937.88672 to 47785.86719, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47020.3555 - val_loss: 47785.8672\nEpoch 89/300\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 46409.0938\nEpoch 89: val_loss did not improve from 47785.86719\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 46407.3555 - val_loss: 47814.9961\nEpoch 90/300\n\u001b[1m313/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44688.3984\nEpoch 90: val_loss improved from 47785.86719 to 47660.22266, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44700.2344 - val_loss: 47660.2227\nEpoch 91/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45469.9336\nEpoch 91: val_loss improved from 47660.22266 to 47568.82812, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45485.3750 - val_loss: 47568.8281\nEpoch 92/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44256.0938\nEpoch 92: val_loss improved from 47568.82812 to 47186.53906, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44335.8008 - val_loss: 47186.5391\nEpoch 93/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45415.5273\nEpoch 93: val_loss improved from 47186.53906 to 46957.05859, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45399.5391 - val_loss: 46957.0586\nEpoch 94/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45910.2852\nEpoch 94: val_loss improved from 46957.05859 to 46833.65234, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45901.6641 - val_loss: 46833.6523\nEpoch 95/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47509.8477\nEpoch 95: val_loss improved from 46833.65234 to 46592.73438, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47404.0469 - val_loss: 46592.7344\nEpoch 96/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44017.7656\nEpoch 96: val_loss did not improve from 46592.73438\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44048.7617 - val_loss: 46801.3906\nEpoch 97/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44386.7031\nEpoch 97: val_loss improved from 46592.73438 to 46470.60156, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44432.7344 - val_loss: 46470.6016\nEpoch 98/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45003.0586\nEpoch 98: val_loss did not improve from 46470.60156\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44980.4922 - val_loss: 46483.1953\nEpoch 99/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45690.2891\nEpoch 99: val_loss improved from 46470.60156 to 46081.59375, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45612.2656 - val_loss: 46081.5938\nEpoch 100/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45276.9141\nEpoch 100: val_loss improved from 46081.59375 to 45953.97266, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45250.3438 - val_loss: 45953.9727\nEpoch 101/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45574.2070\nEpoch 101: val_loss improved from 45953.97266 to 45808.43359, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45514.9883 - val_loss: 45808.4336\nEpoch 102/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43224.2109\nEpoch 102: val_loss improved from 45808.43359 to 45607.16406, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43262.1992 - val_loss: 45607.1641\nEpoch 103/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43002.2461\nEpoch 103: val_loss did not improve from 45607.16406\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43022.0117 - val_loss: 45702.2148\nEpoch 104/300\n\u001b[1m289/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43084.4531\nEpoch 104: val_loss improved from 45607.16406 to 45587.37891, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43122.1445 - val_loss: 45587.3789\nEpoch 105/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43120.4844\nEpoch 105: val_loss did not improve from 45587.37891\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43125.7773 - val_loss: 45763.6758\nEpoch 106/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42459.1016\nEpoch 106: val_loss improved from 45587.37891 to 45149.05469, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42475.4141 - val_loss: 45149.0547\nEpoch 107/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42468.7383\nEpoch 107: val_loss did not improve from 45149.05469\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42479.9531 - val_loss: 45182.2773\nEpoch 108/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42490.1797\nEpoch 108: val_loss improved from 45149.05469 to 44702.53906, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42500.1602 - val_loss: 44702.5391\nEpoch 109/300\n\u001b[1m309/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 42389.9844\nEpoch 109: val_loss did not improve from 44702.53906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42411.7383 - val_loss: 44891.7578\nEpoch 110/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40981.6094\nEpoch 110: val_loss did not improve from 44702.53906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41046.8438 - val_loss: 45696.0625\nEpoch 111/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41785.9883\nEpoch 111: val_loss improved from 44702.53906 to 44586.32031, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41800.0586 - val_loss: 44586.3203\nEpoch 112/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41775.4688\nEpoch 112: val_loss improved from 44586.32031 to 44353.92969, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41785.8086 - val_loss: 44353.9297\nEpoch 113/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43150.0977\nEpoch 113: val_loss did not improve from 44353.92969\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43068.1719 - val_loss: 44745.7969\nEpoch 114/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41265.2383\nEpoch 114: val_loss did not improve from 44353.92969\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41335.2539 - val_loss: 44483.5117\nEpoch 115/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41747.7188\nEpoch 115: val_loss did not improve from 44353.92969\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41741.2031 - val_loss: 44893.2695\nEpoch 116/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41550.1133\nEpoch 116: val_loss improved from 44353.92969 to 43944.44531, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41546.2773 - val_loss: 43944.4453\nEpoch 117/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41984.3711\nEpoch 117: val_loss did not improve from 43944.44531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41956.4727 - val_loss: 44181.7148\nEpoch 118/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41330.7227\nEpoch 118: val_loss did not improve from 43944.44531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41330.2500 - val_loss: 44958.0586\nEpoch 119/300\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39820.8086\nEpoch 119: val_loss did not improve from 43944.44531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39826.5625 - val_loss: 44013.1641\nEpoch 120/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41512.1172\nEpoch 120: val_loss improved from 43944.44531 to 43741.92188, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41514.2539 - val_loss: 43741.9219\nEpoch 121/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40403.9023\nEpoch 121: val_loss did not improve from 43741.92188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40480.7266 - val_loss: 44131.8867\nEpoch 122/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41248.3281\nEpoch 122: val_loss improved from 43741.92188 to 43554.23047, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41282.3984 - val_loss: 43554.2305\nEpoch 123/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39672.8477\nEpoch 123: val_loss improved from 43554.23047 to 43411.48438, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39735.0391 - val_loss: 43411.4844\nEpoch 124/300\n\u001b[1m292/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40216.8320\nEpoch 124: val_loss improved from 43411.48438 to 43173.09375, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40248.4336 - val_loss: 43173.0938\nEpoch 125/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40884.2266\nEpoch 125: val_loss did not improve from 43173.09375\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40866.1719 - val_loss: 43291.7656\nEpoch 126/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39382.8945\nEpoch 126: val_loss improved from 43173.09375 to 43058.24219, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39442.0547 - val_loss: 43058.2422\nEpoch 127/300\n\u001b[1m289/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40647.7500\nEpoch 127: val_loss improved from 43058.24219 to 42998.50391, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40620.4336 - val_loss: 42998.5039\nEpoch 128/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40484.3555\nEpoch 128: val_loss did not improve from 42998.50391\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40497.7148 - val_loss: 43065.2188\nEpoch 129/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40207.2578\nEpoch 129: val_loss did not improve from 42998.50391\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40233.8945 - val_loss: 43237.1602\nEpoch 130/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39206.0586\nEpoch 130: val_loss improved from 42998.50391 to 42976.42969, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39243.5391 - val_loss: 42976.4297\nEpoch 131/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38849.3438\nEpoch 131: val_loss improved from 42976.42969 to 42633.26953, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38917.9297 - val_loss: 42633.2695\nEpoch 132/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39547.2695\nEpoch 132: val_loss did not improve from 42633.26953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39560.0898 - val_loss: 42805.3008\nEpoch 133/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40188.6953\nEpoch 133: val_loss did not improve from 42633.26953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40157.0234 - val_loss: 42844.8242\nEpoch 134/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39064.3672\nEpoch 134: val_loss did not improve from 42633.26953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39091.5898 - val_loss: 43275.6953\nEpoch 135/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38081.1797\nEpoch 135: val_loss improved from 42633.26953 to 42505.46484, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38134.6992 - val_loss: 42505.4648\nEpoch 136/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38147.3359\nEpoch 136: val_loss improved from 42505.46484 to 42471.88672, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38228.7773 - val_loss: 42471.8867\nEpoch 137/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38695.4102\nEpoch 137: val_loss improved from 42471.88672 to 42382.60547, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38728.1445 - val_loss: 42382.6055\nEpoch 138/300\n\u001b[1m314/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38563.2305\nEpoch 138: val_loss improved from 42382.60547 to 42364.19922, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38570.3594 - val_loss: 42364.1992\nEpoch 139/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39031.5273\nEpoch 139: val_loss improved from 42364.19922 to 42033.11719, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39036.9375 - val_loss: 42033.1172\nEpoch 140/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39814.4961\nEpoch 140: val_loss did not improve from 42033.11719\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39763.9844 - val_loss: 42109.8398\nEpoch 141/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38617.6680\nEpoch 141: val_loss did not improve from 42033.11719\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38626.4297 - val_loss: 42651.4414\nEpoch 142/300\n\u001b[1m283/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38155.3789\nEpoch 142: val_loss improved from 42033.11719 to 41996.22656, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38231.3359 - val_loss: 41996.2266\nEpoch 143/300\n\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40100.8867\nEpoch 143: val_loss did not improve from 41996.22656\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40023.9688 - val_loss: 42290.1953\nEpoch 144/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38966.7969\nEpoch 144: val_loss improved from 41996.22656 to 41787.72656, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38961.5664 - val_loss: 41787.7266\nEpoch 145/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37146.5977\nEpoch 145: val_loss did not improve from 41787.72656\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37214.7539 - val_loss: 41917.2266\nEpoch 146/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37914.1367\nEpoch 146: val_loss did not improve from 41787.72656\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37968.7734 - val_loss: 42461.3984\nEpoch 147/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37808.8984\nEpoch 147: val_loss improved from 41787.72656 to 41743.81250, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37810.3867 - val_loss: 41743.8125\nEpoch 148/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38257.4219\nEpoch 148: val_loss improved from 41743.81250 to 41501.20312, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38267.6484 - val_loss: 41501.2031\nEpoch 149/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38661.5898\nEpoch 149: val_loss did not improve from 41501.20312\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38659.4883 - val_loss: 41552.1328\nEpoch 150/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37870.2773\nEpoch 150: val_loss did not improve from 41501.20312\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37896.7734 - val_loss: 41599.9570\nEpoch 151/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37600.7656\nEpoch 151: val_loss improved from 41501.20312 to 41216.79297, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37594.9453 - val_loss: 41216.7930\nEpoch 152/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37819.7422\nEpoch 152: val_loss did not improve from 41216.79297\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37836.1680 - val_loss: 41634.9570\nEpoch 153/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38353.6289\nEpoch 153: val_loss did not improve from 41216.79297\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38328.2500 - val_loss: 41253.7773\nEpoch 154/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37106.5859\nEpoch 154: val_loss did not improve from 41216.79297\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37159.3477 - val_loss: 41352.7500\nEpoch 155/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35456.3047\nEpoch 155: val_loss did not improve from 41216.79297\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35610.0312 - val_loss: 41568.4961\nEpoch 156/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38714.5078\nEpoch 156: val_loss improved from 41216.79297 to 41215.05859, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38681.4375 - val_loss: 41215.0586\nEpoch 157/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37537.5938\nEpoch 157: val_loss improved from 41215.05859 to 41043.69922, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37535.0039 - val_loss: 41043.6992\nEpoch 158/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37182.1055\nEpoch 158: val_loss did not improve from 41043.69922\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37205.9570 - val_loss: 41082.8516\nEpoch 159/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38520.9570\nEpoch 159: val_loss did not improve from 41043.69922\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38475.5664 - val_loss: 41296.7344\nEpoch 160/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38054.0859\nEpoch 160: val_loss improved from 41043.69922 to 41002.22656, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38028.7617 - val_loss: 41002.2266\nEpoch 161/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37176.6445\nEpoch 161: val_loss improved from 41002.22656 to 40950.46094, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37181.5352 - val_loss: 40950.4609\nEpoch 162/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37010.6875\nEpoch 162: val_loss improved from 40950.46094 to 40701.67188, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37005.8320 - val_loss: 40701.6719\nEpoch 163/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38763.9727\nEpoch 163: val_loss did not improve from 40701.67188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38702.3828 - val_loss: 41064.6172\nEpoch 164/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37584.8320\nEpoch 164: val_loss did not improve from 40701.67188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37600.1953 - val_loss: 40990.5234\nEpoch 165/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36204.6289\nEpoch 165: val_loss did not improve from 40701.67188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36272.8086 - val_loss: 41101.3555\nEpoch 166/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35190.3906\nEpoch 166: val_loss did not improve from 40701.67188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35253.1250 - val_loss: 40975.9727\nEpoch 167/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37429.9219\nEpoch 167: val_loss did not improve from 40701.67188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37395.4023 - val_loss: 40901.4922\nEpoch 168/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35935.9922\nEpoch 168: val_loss did not improve from 40701.67188\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35968.9531 - val_loss: 40940.0391\nEpoch 169/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35661.8203\nEpoch 169: val_loss improved from 40701.67188 to 40371.54688, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35729.4453 - val_loss: 40371.5469\nEpoch 170/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36466.6172\nEpoch 170: val_loss did not improve from 40371.54688\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36471.5625 - val_loss: 40777.5430\nEpoch 171/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36752.7383\nEpoch 171: val_loss did not improve from 40371.54688\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36728.0000 - val_loss: 40553.6367\nEpoch 172/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35448.1602\nEpoch 172: val_loss improved from 40371.54688 to 40335.83203, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35519.7891 - val_loss: 40335.8320\nEpoch 173/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35872.2656\nEpoch 173: val_loss improved from 40335.83203 to 40326.64453, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35878.8359 - val_loss: 40326.6445\nEpoch 174/300\n\u001b[1m284/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36670.4961\nEpoch 174: val_loss did not improve from 40326.64453\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36627.0391 - val_loss: 40818.9102\nEpoch 175/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36252.2070\nEpoch 175: val_loss did not improve from 40326.64453\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36254.2617 - val_loss: 40945.3555\nEpoch 176/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36161.0586\nEpoch 176: val_loss improved from 40326.64453 to 40009.76953, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36166.8008 - val_loss: 40009.7695\nEpoch 177/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36249.4766\nEpoch 177: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36229.4102 - val_loss: 40370.8281\nEpoch 178/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36596.1719\nEpoch 178: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36589.9336 - val_loss: 40085.7617\nEpoch 179/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35574.3281\nEpoch 179: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35617.2891 - val_loss: 40872.6992\nEpoch 180/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35951.4961\nEpoch 180: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35961.6250 - val_loss: 40208.5352\nEpoch 181/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35704.0078\nEpoch 181: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35746.0430 - val_loss: 40133.6133\nEpoch 182/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36112.4141\nEpoch 182: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36086.5352 - val_loss: 40131.2109\nEpoch 183/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37422.0039\nEpoch 183: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37357.6914 - val_loss: 40427.3672\nEpoch 184/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35092.1914\nEpoch 184: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 35163.3203 - val_loss: 40173.9922\nEpoch 185/300\n\u001b[1m284/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33744.3125\nEpoch 185: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33891.7148 - val_loss: 40107.0273\nEpoch 186/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36213.3281\nEpoch 186: val_loss did not improve from 40009.76953\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36195.8984 - val_loss: 40279.2539\nEpoch 187/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35609.1289\nEpoch 187: val_loss improved from 40009.76953 to 39930.56641, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35613.7812 - val_loss: 39930.5664\nEpoch 188/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36769.0547\nEpoch 188: val_loss improved from 39930.56641 to 39726.78906, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36684.6094 - val_loss: 39726.7891\nEpoch 189/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34746.5703\nEpoch 189: val_loss improved from 39726.78906 to 39670.30469, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34810.5938 - val_loss: 39670.3047\nEpoch 190/300\n\u001b[1m285/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35687.8828\nEpoch 190: val_loss improved from 39670.30469 to 39655.76562, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35597.2969 - val_loss: 39655.7656\nEpoch 191/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36336.2148\nEpoch 191: val_loss did not improve from 39655.76562\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36317.9258 - val_loss: 39896.9648\nEpoch 192/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36412.9922\nEpoch 192: val_loss did not improve from 39655.76562\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36365.5039 - val_loss: 39783.5195\nEpoch 193/300\n\u001b[1m315/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34712.4766\nEpoch 193: val_loss did not improve from 39655.76562\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34715.4883 - val_loss: 39795.6992\nEpoch 194/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35492.0156\nEpoch 194: val_loss improved from 39655.76562 to 39524.60938, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35505.5039 - val_loss: 39524.6094\nEpoch 195/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35966.7852\nEpoch 195: val_loss did not improve from 39524.60938\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35951.2852 - val_loss: 39714.4023\nEpoch 196/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34450.4727\nEpoch 196: val_loss improved from 39524.60938 to 39365.91016, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34478.0859 - val_loss: 39365.9102\nEpoch 197/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35120.1445\nEpoch 197: val_loss improved from 39365.91016 to 39288.75391, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35115.6250 - val_loss: 39288.7539\nEpoch 198/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34936.5820\nEpoch 198: val_loss did not improve from 39288.75391\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34940.4766 - val_loss: 39713.7969\nEpoch 199/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34592.9297\nEpoch 199: val_loss did not improve from 39288.75391\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34609.0469 - val_loss: 39442.0312\nEpoch 200/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34537.8438\nEpoch 200: val_loss did not improve from 39288.75391\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34568.9961 - val_loss: 39547.5391\nEpoch 201/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35859.1133\nEpoch 201: val_loss improved from 39288.75391 to 39195.07031, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35816.7148 - val_loss: 39195.0703\nEpoch 202/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34897.5742\nEpoch 202: val_loss did not improve from 39195.07031\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34894.8906 - val_loss: 39239.5469\nEpoch 203/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35259.9688\nEpoch 203: val_loss did not improve from 39195.07031\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35197.8203 - val_loss: 39374.2500\nEpoch 204/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35130.5234\nEpoch 204: val_loss did not improve from 39195.07031\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35143.7031 - val_loss: 39281.4570\nEpoch 205/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34745.0273\nEpoch 205: val_loss improved from 39195.07031 to 39171.33984, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34760.5039 - val_loss: 39171.3398\nEpoch 206/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34942.5234\nEpoch 206: val_loss did not improve from 39171.33984\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34935.3203 - val_loss: 40304.5508\nEpoch 207/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34146.6875\nEpoch 207: val_loss improved from 39171.33984 to 38950.53125, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34150.7305 - val_loss: 38950.5312\nEpoch 208/300\n\u001b[1m313/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34699.4336\nEpoch 208: val_loss did not improve from 38950.53125\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34702.0391 - val_loss: 39058.2930\nEpoch 209/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34796.9453\nEpoch 209: val_loss did not improve from 38950.53125\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34759.7891 - val_loss: 39072.8711\nEpoch 210/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33295.3281\nEpoch 210: val_loss did not improve from 38950.53125\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33347.4492 - val_loss: 39315.2852\nEpoch 211/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34692.1719\nEpoch 211: val_loss did not improve from 38950.53125\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34660.5156 - val_loss: 39034.8398\nEpoch 212/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36195.0859\nEpoch 212: val_loss did not improve from 38950.53125\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36137.6719 - val_loss: 39129.5117\nEpoch 213/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33212.8398\nEpoch 213: val_loss did not improve from 38950.53125\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33269.2695 - val_loss: 39253.8438\nEpoch 214/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33716.6094\nEpoch 214: val_loss improved from 38950.53125 to 38722.41797, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33723.5898 - val_loss: 38722.4180\nEpoch 215/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33700.1445\nEpoch 215: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33730.5000 - val_loss: 39194.1797\nEpoch 216/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34428.3008\nEpoch 216: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34424.8633 - val_loss: 39603.9883\nEpoch 217/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33611.2461\nEpoch 217: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33652.8203 - val_loss: 38963.1641\nEpoch 218/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33859.7812\nEpoch 218: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33876.2109 - val_loss: 39015.6211\nEpoch 219/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33111.4688\nEpoch 219: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33169.6133 - val_loss: 38730.8945\nEpoch 220/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32535.2969\nEpoch 220: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32569.8848 - val_loss: 38918.7344\nEpoch 221/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33533.3398\nEpoch 221: val_loss did not improve from 38722.41797\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33534.7344 - val_loss: 39135.9375\nEpoch 222/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34332.5469\nEpoch 222: val_loss improved from 38722.41797 to 38685.36328, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34350.2852 - val_loss: 38685.3633\nEpoch 223/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33324.4688\nEpoch 223: val_loss did not improve from 38685.36328\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33344.6250 - val_loss: 38692.8281\nEpoch 224/300\n\u001b[1m309/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33435.4492\nEpoch 224: val_loss improved from 38685.36328 to 38562.53906, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33442.4609 - val_loss: 38562.5391\nEpoch 225/300\n\u001b[1m309/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33936.4492\nEpoch 225: val_loss did not improve from 38562.53906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33928.5547 - val_loss: 38678.0742\nEpoch 226/300\n\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33952.1797\nEpoch 226: val_loss did not improve from 38562.53906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33951.4570 - val_loss: 38716.4844\nEpoch 227/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33195.4023\nEpoch 227: val_loss improved from 38562.53906 to 38559.46484, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33202.5117 - val_loss: 38559.4648\nEpoch 228/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33050.7891\nEpoch 228: val_loss did not improve from 38559.46484\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33072.9141 - val_loss: 38925.7461\nEpoch 229/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32617.0781\nEpoch 229: val_loss improved from 38559.46484 to 38505.69531, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32645.9688 - val_loss: 38505.6953\nEpoch 230/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33821.6406\nEpoch 230: val_loss did not improve from 38505.69531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33814.0312 - val_loss: 39358.2305\nEpoch 231/300\n\u001b[1m280/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33254.2578\nEpoch 231: val_loss did not improve from 38505.69531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33305.6523 - val_loss: 38836.4531\nEpoch 232/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33989.4688\nEpoch 232: val_loss did not improve from 38505.69531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33980.0508 - val_loss: 38840.2031\nEpoch 233/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34016.1250\nEpoch 233: val_loss did not improve from 38505.69531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34011.8984 - val_loss: 38983.9727\nEpoch 234/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32883.4414\nEpoch 234: val_loss did not improve from 38505.69531\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32909.8398 - val_loss: 38667.0703\nEpoch 235/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32588.4707\nEpoch 235: val_loss improved from 38505.69531 to 38399.83594, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32632.9922 - val_loss: 38399.8359\nEpoch 236/300\n\u001b[1m292/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33064.8555\nEpoch 236: val_loss did not improve from 38399.83594\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33097.1367 - val_loss: 38495.2383\nEpoch 237/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32716.7617\nEpoch 237: val_loss did not improve from 38399.83594\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32726.6309 - val_loss: 38716.0430\nEpoch 238/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33405.5469\nEpoch 238: val_loss improved from 38399.83594 to 38327.01562, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33396.1094 - val_loss: 38327.0156\nEpoch 239/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33667.9492\nEpoch 239: val_loss did not improve from 38327.01562\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33647.0391 - val_loss: 38613.7305\nEpoch 240/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32061.6836\nEpoch 240: val_loss did not improve from 38327.01562\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32096.6816 - val_loss: 38357.6016\nEpoch 241/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33455.5430\nEpoch 241: val_loss improved from 38327.01562 to 38201.84766, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33437.0664 - val_loss: 38201.8477\nEpoch 242/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34195.8711\nEpoch 242: val_loss did not improve from 38201.84766\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34189.5898 - val_loss: 39001.2695\nEpoch 243/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32767.5645\nEpoch 243: val_loss improved from 38201.84766 to 38160.61719, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32807.3242 - val_loss: 38160.6172\nEpoch 244/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32069.7266\nEpoch 244: val_loss improved from 38160.61719 to 37984.46875, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32107.7344 - val_loss: 37984.4688\nEpoch 245/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32222.3828\nEpoch 245: val_loss did not improve from 37984.46875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32276.4609 - val_loss: 38084.8594\nEpoch 246/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32974.4336\nEpoch 246: val_loss improved from 37984.46875 to 37857.71875, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32958.8750 - val_loss: 37857.7188\nEpoch 247/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32174.0508\nEpoch 247: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32213.1543 - val_loss: 38521.5664\nEpoch 248/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33240.9375\nEpoch 248: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33216.3438 - val_loss: 38392.9141\nEpoch 249/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32294.8320\nEpoch 249: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32292.5293 - val_loss: 38006.4141\nEpoch 250/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31877.0938\nEpoch 250: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31907.6797 - val_loss: 38269.5117\nEpoch 251/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31453.4160\nEpoch 251: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31525.4883 - val_loss: 38409.4531\nEpoch 252/300\n\u001b[1m281/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33314.8203\nEpoch 252: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33263.1875 - val_loss: 38004.5820\nEpoch 253/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33078.3281\nEpoch 253: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33070.5234 - val_loss: 37899.9180\nEpoch 254/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33152.5234\nEpoch 254: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33085.9688 - val_loss: 38685.8047\nEpoch 255/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31680.0566\nEpoch 255: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31717.6465 - val_loss: 38302.2695\nEpoch 256/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32033.1738\nEpoch 256: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32054.8320 - val_loss: 37964.2734\nEpoch 257/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31798.5156\nEpoch 257: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31831.3184 - val_loss: 37928.5430\nEpoch 258/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31238.2969\nEpoch 258: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31290.2227 - val_loss: 37913.6367\nEpoch 259/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32066.5645\nEpoch 259: val_loss did not improve from 37857.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32086.1484 - val_loss: 38081.6211\nEpoch 260/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31705.1230\nEpoch 260: val_loss improved from 37857.71875 to 37778.67578, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31703.8867 - val_loss: 37778.6758\nEpoch 261/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32620.8555\nEpoch 261: val_loss did not improve from 37778.67578\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32564.1836 - val_loss: 38254.2734\nEpoch 262/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32103.2070\nEpoch 262: val_loss did not improve from 37778.67578\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32131.6797 - val_loss: 37946.1406\nEpoch 263/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32147.6289\nEpoch 263: val_loss did not improve from 37778.67578\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32143.4551 - val_loss: 37927.1758\nEpoch 264/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33582.3047\nEpoch 264: val_loss did not improve from 37778.67578\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33527.3516 - val_loss: 38234.9648\nEpoch 265/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31435.8477\nEpoch 265: val_loss improved from 37778.67578 to 37731.54688, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31459.8086 - val_loss: 37731.5469\nEpoch 266/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29968.3945\nEpoch 266: val_loss did not improve from 37731.54688\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30048.0273 - val_loss: 37840.3125\nEpoch 267/300\n\u001b[1m282/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32142.7344\nEpoch 267: val_loss did not improve from 37731.54688\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32151.9609 - val_loss: 38057.0703\nEpoch 268/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32276.8145\nEpoch 268: val_loss did not improve from 37731.54688\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32259.9551 - val_loss: 37922.0586\nEpoch 269/300\n\u001b[1m296/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32769.0586\nEpoch 269: val_loss improved from 37731.54688 to 37677.38281, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32764.8770 - val_loss: 37677.3828\nEpoch 270/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32426.2695\nEpoch 270: val_loss improved from 37677.38281 to 37625.78906, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32397.9980 - val_loss: 37625.7891\nEpoch 271/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32902.8359\nEpoch 271: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32893.6406 - val_loss: 38214.9727\nEpoch 272/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32140.5527\nEpoch 272: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32136.2969 - val_loss: 37759.8906\nEpoch 273/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30291.7051\nEpoch 273: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30358.2969 - val_loss: 37677.8125\nEpoch 274/300\n\u001b[1m294/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31347.9199\nEpoch 274: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31378.1484 - val_loss: 37637.5078\nEpoch 275/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31805.5430\nEpoch 275: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31809.4473 - val_loss: 37664.7305\nEpoch 276/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30050.4180\nEpoch 276: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30130.5586 - val_loss: 37633.0078\nEpoch 277/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32895.2617\nEpoch 277: val_loss did not improve from 37625.78906\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32859.1992 - val_loss: 37737.3477\nEpoch 278/300\n\u001b[1m307/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31930.8711\nEpoch 278: val_loss improved from 37625.78906 to 37375.21875, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31939.6992 - val_loss: 37375.2188\nEpoch 279/300\n\u001b[1m297/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31647.0293\nEpoch 279: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31642.0137 - val_loss: 37520.9766\nEpoch 280/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31506.7812\nEpoch 280: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31535.7031 - val_loss: 37544.7539\nEpoch 281/300\n\u001b[1m293/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31540.1953\nEpoch 281: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31538.5645 - val_loss: 37654.5039\nEpoch 282/300\n\u001b[1m287/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31090.9004\nEpoch 282: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31096.5938 - val_loss: 37739.3477\nEpoch 283/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30928.4316\nEpoch 283: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30940.6387 - val_loss: 37597.6797\nEpoch 284/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31272.9492\nEpoch 284: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31278.3477 - val_loss: 37470.8320\nEpoch 285/300\n\u001b[1m303/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31288.0215\nEpoch 285: val_loss did not improve from 37375.21875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31297.9688 - val_loss: 37842.8164\nEpoch 286/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31309.5664\nEpoch 286: val_loss improved from 37375.21875 to 37367.06641, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31345.3887 - val_loss: 37367.0664\nEpoch 287/300\n\u001b[1m306/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31225.7734\nEpoch 287: val_loss did not improve from 37367.06641\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31246.6641 - val_loss: 37667.7461\nEpoch 288/300\n\u001b[1m295/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32789.7109\nEpoch 288: val_loss did not improve from 37367.06641\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32697.9414 - val_loss: 37829.5469\nEpoch 289/300\n\u001b[1m304/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31768.4141\nEpoch 289: val_loss did not improve from 37367.06641\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31753.8438 - val_loss: 37643.8047\nEpoch 290/300\n\u001b[1m305/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31551.1543\nEpoch 290: val_loss did not improve from 37367.06641\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31577.3477 - val_loss: 37556.3320\nEpoch 291/300\n\u001b[1m299/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30032.3320\nEpoch 291: val_loss did not improve from 37367.06641\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30060.9902 - val_loss: 37372.0234\nEpoch 292/300\n\u001b[1m308/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32093.3008\nEpoch 292: val_loss did not improve from 37367.06641\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32090.4219 - val_loss: 37678.8320\nEpoch 293/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31570.6855\nEpoch 293: val_loss improved from 37367.06641 to 37354.96484, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31547.0039 - val_loss: 37354.9648\nEpoch 294/300\n\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31270.4297\nEpoch 294: val_loss did not improve from 37354.96484\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31290.2832 - val_loss: 37481.0469\nEpoch 295/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30327.0664\nEpoch 295: val_loss did not improve from 37354.96484\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30352.0566 - val_loss: 37411.2109\nEpoch 296/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31669.4688\nEpoch 296: val_loss improved from 37354.96484 to 37238.97656, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31644.0938 - val_loss: 37238.9766\nEpoch 297/300\n\u001b[1m284/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29830.7969\nEpoch 297: val_loss did not improve from 37238.97656\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 29995.0195 - val_loss: 37391.8164\nEpoch 298/300\n\u001b[1m302/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31303.1875\nEpoch 298: val_loss improved from 37238.97656 to 37236.71875, saving model to training_1/chess_3.weights.h5\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31292.1152 - val_loss: 37236.7188\nEpoch 299/300\n\u001b[1m298/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31291.4414\nEpoch 299: val_loss did not improve from 37236.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31293.0000 - val_loss: 37613.5508\nEpoch 300/300\n\u001b[1m301/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29993.0020\nEpoch 300: val_loss did not improve from 37236.71875\n\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30018.8535 - val_loss: 37470.9141\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Updated Policy Function","metadata":{}},{"cell_type":"code","source":"def play_nn_new(fen, show_move_evaluations=False):\n    # We can create a python-chess board instance from the FEN string like this:\n    board = chess.Board(fen=fen)\n\n    material = count_material(fen)\n    if material < 30:\n        model = endgame_model\n    elif material <= 65:\n        model = midgame_model\n    else:\n        model = opening_model\n    \n    moves = []\n    input_vectors = []\n    for move in board.legal_moves:\n        # For each move, we'll make a copy of the board and try that move out\n        candidate_board = board.copy()\n        candidate_board.push(move)\n        moves.append(move)\n        input_vectors.append(encode_board(str(candidate_board)))\n    \n    input_vectors = np.stack(input_vectors)\n    # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n    scores = model.predict(input_vectors, verbose=0)\n    # argmax gives us the index of the highest scoring move\n    if board.turn == chess.BLACK:\n        index_of_best_move = np.argmax(scores)\n    else:\n        # If we're playing as white, we want black's score to be as small as possible, so we take argmax of the negative of our array\n        index_of_best_move = np.argmax(-scores)\n\n    if show_move_evaluations:\n        print(zip(moves, scores))\n        \n    best_move = moves[index_of_best_move]\n\n    # Now we turn our move into a string, return it and call it a day!\n    return str(best_move)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:25:49.686788Z","iopub.execute_input":"2024-07-29T12:25:49.687475Z","iopub.status.idle":"2024-07-29T12:25:49.696319Z","shell.execute_reply.started":"2024-07-29T12:25:49.687414Z","shell.execute_reply":"2024-07-29T12:25:49.695358Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"play_game(play_nn_new)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T09:55:34.272665Z","iopub.execute_input":"2024-07-29T09:55:34.273341Z","iopub.status.idle":"2024-07-29T09:55:46.778271Z","shell.execute_reply.started":"2024-07-29T09:55:34.273312Z","shell.execute_reply":"2024-07-29T09:55:46.776094Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":182,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\nP P P P P P P P\nR N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\"/></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\"/></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\"/></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\"/><path d=\"M34 14l-3 3H14l-3-3\"/><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\"/><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\"/></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\"/><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\"/></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\"/><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\"/></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\"/></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\"/><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\"/></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\"/><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\"/><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\"/></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\"/><circle cx=\"14\" cy=\"9\" r=\"2.75\"/><circle cx=\"22.5\" cy=\"8\" r=\"2.75\"/><circle cx=\"31\" cy=\"9\" r=\"2.75\"/><circle cx=\"39\" cy=\"12\" r=\"2.75\"/></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\"/><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\"/></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\"/><path d=\"M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\"/></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\"/><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\"/><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\"/><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\"/><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\"/><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\"/></svg>"},"metadata":{}},{"output_type":"stream","name":"stdin","text":"Your move:  c2c4\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . P . . . . .\n. . . . . . . .\nP P . P P P P P\nR N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\"/></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\"/></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\"/></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\"/><path d=\"M34 14l-3 3H14l-3-3\"/><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\"/><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\"/></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\"/><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\"/></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\"/><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\"/></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\"/></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\"/><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\"/></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\"/><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\"/><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\"/></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\"/><circle cx=\"14\" cy=\"9\" r=\"2.75\"/><circle cx=\"22.5\" cy=\"8\" r=\"2.75\"/><circle cx=\"31\" cy=\"9\" r=\"2.75\"/><circle cx=\"39\" cy=\"12\" r=\"2.75\"/></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\"/><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\"/></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\"/><path d=\"M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\"/></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\"/><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light lastmove c2\" stroke=\"none\" fill=\"#cdd16a\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light lastmove c4\" stroke=\"none\" fill=\"#cdd16a\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\"/><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\"/><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 195)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\"/><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\"/><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\"/></svg>"},"metadata":{}},{"name":"stdout","text":"AI move: b8c6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r . b q k b n r\np p p p p p p p\n. . n . . . . .\n. . . . . . . .\n. . P . . . . .\n. . . . . . . .\nP P . P P P P P\nR N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\"/></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\"/></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\"/></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\"/><path d=\"M34 14l-3 3H14l-3-3\"/><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\"/><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\"/></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\"/><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\"/></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\"/><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\"/></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\"/></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\"/><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\"/></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\"/><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\"/><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\"/></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\"/><circle cx=\"14\" cy=\"9\" r=\"2.75\"/><circle cx=\"22.5\" cy=\"8\" r=\"2.75\"/><circle cx=\"31\" cy=\"9\" r=\"2.75\"/><circle cx=\"39\" cy=\"12\" r=\"2.75\"/></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\"/><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\"/></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\"/><path d=\"M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\"/></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\"/><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light lastmove c6\" stroke=\"none\" fill=\"#cdd16a\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark lastmove b8\" stroke=\"none\" fill=\"#aaa23b\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\"/><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\"/><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 195)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(105, 105)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\"/><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\"/><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\"/></svg>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplay_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplay_nn_new\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[70], line 14\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(ai_function)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# If it's white's turn, we have the user play\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m board\u001b[38;5;241m.\u001b[39mturn \u001b[38;5;241m==\u001b[39m chess\u001b[38;5;241m.\u001b[39mWHITE:\n\u001b[0;32m---> 14\u001b[0m     user_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYour move: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_move \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}]},{"cell_type":"markdown","source":"# Predict & Submit Ensembled Model","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/train-an-ai-to-play-chess/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:25:49.697386Z","iopub.execute_input":"2024-07-29T12:25:49.697697Z","iopub.status.idle":"2024-07-29T12:25:49.720962Z","shell.execute_reply.started":"2024-07-29T12:25:49.697673Z","shell.execute_reply":"2024-07-29T12:25:49.720001Z"},"trusted":true},"execution_count":289,"outputs":[{"execution_count":289,"output_type":"execute_result","data":{"text/plain":"      id                                              board\n0   7937  r1bqk2r/pp2bpp1/2n1pn1p/2pp4/3P1B2/2P1PN2/PP1N...\n1  20035  2r2k1r/pp2pp1p/1q3npb/1B1N4/8/P4Q1P/1P3PP1/R2R...\n2  71263               3b4/8/5k2/5p2/8/4K3/8/5B2 b - - 2 80\n3  61997      5k2/R7/3r3p/2PP2pP/5pb1/P1K5/6B1/8 w - - 1 61\n4  26510  r3r1k1/pb3p1p/1p1q2p1/3P1p2/3Q1P2/5N2/PP4PP/3R...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>board</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7937</td>\n      <td>r1bqk2r/pp2bpp1/2n1pn1p/2pp4/3P1B2/2P1PN2/PP1N...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20035</td>\n      <td>2r2k1r/pp2pp1p/1q3npb/1B1N4/8/P4Q1P/1P3PP1/R2R...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71263</td>\n      <td>3b4/8/5k2/5p2/8/4K3/8/5B2 b - - 2 80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61997</td>\n      <td>5k2/R7/3r3p/2PP2pP/5pb1/P1K5/6B1/8 w - - 1 61</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26510</td>\n      <td>r3r1k1/pb3p1p/1p1q2p1/3P1p2/3Q1P2/5N2/PP4PP/3R...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df['best_move'] = test_df['board'].apply(play_nn_new)\ntest_df['best_move']","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:25:49.722142Z","iopub.execute_input":"2024-07-29T12:25:49.722405Z","iopub.status.idle":"2024-07-29T12:26:09.236453Z","shell.execute_reply.started":"2024-07-29T12:25:49.722381Z","shell.execute_reply":"2024-07-29T12:26:09.235448Z"},"trusted":true},"execution_count":290,"outputs":[{"execution_count":290,"output_type":"execute_result","data":{"text/plain":"0       f6g4\n1       d5b6\n2       f6g7\n3       c5d6\n4       d6d7\n       ...  \n195     b4b2\n196     c5d5\n197    c7c8q\n198     h2g1\n199     d8d2\nName: best_move, Length: 200, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"submission = test_df[['id', 'best_move']]\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:26:09.237987Z","iopub.execute_input":"2024-07-29T12:26:09.238317Z","iopub.status.idle":"2024-07-29T12:26:09.248399Z","shell.execute_reply.started":"2024-07-29T12:26:09.238289Z","shell.execute_reply":"2024-07-29T12:26:09.247329Z"},"trusted":true},"execution_count":291,"outputs":[{"execution_count":291,"output_type":"execute_result","data":{"text/plain":"      id best_move\n0   7937      f6g4\n1  20035      d5b6\n2  71263      f6g7\n3  61997      c5d6\n4  26510      d6d7","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>best_move</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7937</td>\n      <td>f6g4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20035</td>\n      <td>d5b6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71263</td>\n      <td>f6g7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61997</td>\n      <td>c5d6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26510</td>\n      <td>d6d7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:26:09.249740Z","iopub.execute_input":"2024-07-29T12:26:09.250083Z","iopub.status.idle":"2024-07-29T12:26:09.259429Z","shell.execute_reply.started":"2024-07-29T12:26:09.250055Z","shell.execute_reply":"2024-07-29T12:26:09.258491Z"},"trusted":true},"execution_count":292,"outputs":[]}]}